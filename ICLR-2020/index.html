<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.12.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>ICLR 2020 impressions and paper highlights - Dans World</title>
<meta name="description" content="Having just “visited” my first virtual conference, ICLR 2020, I wanted to talk about my general impression and highlight some papers that stuck out to me from a variety of subfields.">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_GB">
<meta property="og:site_name" content="Dans World">
<meta property="og:title" content="ICLR 2020 impressions and paper highlights">
<meta property="og:url" content="https://dans.world/ICLR-2020/">


  <meta property="og:description" content="Having just “visited” my first virtual conference, ICLR 2020, I wanted to talk about my general impression and highlight some papers that stuck out to me from a variety of subfields.">







  <meta property="article:published_time" content="2019-02-21T00:00:00+01:00">





  

  


<link rel="canonical" href="https://dans.world/ICLR-2020/">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Daniel Stoller",
      "url": "https://dans.world",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Dans World Feed">

<!-- 

 -->

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link rel="stylesheet" href="/assets/css/academicons.css">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    
       <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true,
    }
  });
</script>
<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
    
  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Dans World</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="https://dans.world/research/" >Research</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="https://dans.world/publications/" >Publications</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="https://dans.world/about/" >About</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="https://dans.world/posts/" >Blog</a>
            </li>
          
        </ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="http://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Daniel Stoller</h3>
    
    
      <p class="author__bio" itemprop="description">
        Researcher in Machine Learning and Music Information Retrieval.
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">London, UK</span>
        </li>
      

      

      
        <li>
          <a href="mailto:business@dstoller.net">
            <meta itemprop="email" content="business@dstoller.net" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      

      

      

      
        <li>
          <a href="https://www.linkedin.com/in/daniel-stoller" itemprop="sameAs">
            <i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn
          </a>
        </li>
      

      

      

      

      

      
        <li>
          <a href="https://github.com/f90" itemprop="sameAs">
            <i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

        <li>
    <a href="https://orcid.org/0000-0002-8615-4144" itemprop="sameAs">
      <i class="ai ai-orcid-square ai-fw"></i> ORCID
    </a>
  </li>

  <li>
    <a href="https://scholar.google.co.uk/citations?user=Ozxm6UsAAAAJ" itemprop="sameAs">
      <i class="ai ai-google-scholar-square ai-fw"></i> Google Scholar
    </a>
</li>

  <li>
    <a href="https://qmul.academia.edu/DanielStoller" itemprop="sameAs">
      <i class="ai ai-academia-square ai-fw"></i> Academia.edu
    </a>
</li>
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="ICLR 2020 impressions and paper highlights">
    <meta itemprop="description" content="Having just “visited” my first virtual conference, ICLR 2020, I wanted to talk about my general impression and highlight some papers that stuck out to me from a variety of subfields.">
    <meta itemprop="datePublished" content="February 21, 2019">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">ICLR 2020 impressions and paper highlights
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  10 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>Having just “visited” my first virtual conference, ICLR 2020, I wanted to talk about my general impression and highlight some papers that stuck out to me from a variety of subfields.</p>

<h2 id="general-impressions">General impressions</h2>

<p>I presented our <a href="https://iclr.cc/virtual/poster_Hye1RJHKwB.html">FactorGAN paper</a> at the conference. Like every other paper, we have a quick explainer video, along with an asynchronous chat room to answer questions, and two poster session slots lasting two hours each, where people could spontaneously join into virtual Zoom meetings to discuss the paper.</p>

<p>ICLR organisers did a really good job overall, considering there was so little time to react to the Coronavirus pandemic and to switch from a physical to a virtual conference.
Poster sessions were very useful to get to know some people and discuss specific questions about papers. In my experience, they were surprisingly empty oftentimes, but that in turn allowed everyone to participate more easily. It’s really nice that the explainer videos are permanently available to everyone now, which should really help with disseminating all the latest research efficiently.</p>

<p>However, I found it a bit difficult to get to know people in a more relaxed setting. Just like poster sessions, the socials on offer were mostly focused on a specific topic, such as AI for environmental issues. There was a “VR” application called “ICLR Town”, where people can run around with characters in a 2D top-down view and meet up in this virtual space using webcams. While this suited my needs more, there were barely any people online. Maybe such a virtual meeting space should be promoted more and included as a coffee break into the conference schedule- which only featured poster sessions and talks this time.</p>

<p>Finally, I was surprised that poster sessions were not clearly separated according to topic, which made it quite overwhelming to find relevant papers. But overall it was a nice experience and organisers did the best they could considering the circumstances.</p>

<h2 id="paper-highlights">Paper highlights</h2>

<h3 id="causality">Causality</h3>

<p>Connecting deep learning models operating with differentiable operations and loss functions on the one hand with causal learning dealing with discrete graphs on the other hand, is generally a very interesting research direction. I wanted to highlight two papers here.</p>

<p><a href="https://iclr.cc/virtual/poster_ryxWIgBFPS.html">A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms</a></p>

<p>This paper looks at simple two-dimensional distributions $P(A,B)$. The question is: Does A cause B or B cause A?
A probabilistic model could estimate the joint by decomposing it into $P(A)P(B|A)$ or $P(B)P(B|A)$.
The main idea in this paper: If the model uses the “correct” decomposition that reflects the causal structure, then if the cause changes, adapting the model to this new distribution is fast. Why is that? Let’s assume that A causes B. If we model using the correct decomposition, $P(A)P(B|A)$, and $P(A)$ changes, then $P(B|A)$ stays the same, so only one part of the model needs to be adapted.
If we modelled $P(B)P(B|A)$, then BOTH $P(B)$ and $P(B|A)$ would change.</p>

<p>Authors then construct a clever meta-learning objective - a sum of the likelihood of both model variants on the new distribution after training for a certain number of steps. This sum is weighted with the meta-parameter $\gamma$. After meta-training, $\gamma$ indicates which model, and therefore which causal explanation, is most likely the correct one.</p>

<p>This research seems still in its infancy – two-dimensional distributions are clearly not very practically relevant. But the idea of smoothly interpolating between different generative models using meta-learning might prove valuable in the future in more difficult settings!</p>

<p><a href="https://causalrlworkshop.github.io/program/cldm_21.html">Neural Causal Induction from Interventions</a></p>

<p>In this paper, authors employ a deep learning model to estimate the outcomes of particular interventions, and by observing multiple interventions in a row, to predict the structure of the underlying causal graph that generated the observations.
This paper also makes use of meta-learning, in that in each meta-iteration, a new causal graph is used, with the aim of obtaining a deep learning model that can predict the causal structure between multiple variables even for new, previously unseen distributions.</p>

<p><img src="https://dans.world/assets/img/2020-04-28-ICLR-2020/neural_causal_induction.png" alt="drawing" width="400" /></p>

<p>The structure of the neural network is shown above. At each time step, an intervention is performed on one variable, and the encoder takes the resulting $N$ observed variables plus one that indicates which variable was intervened upon. The output is fed to a sequence model that updates its belief state about the causal graph, given all the information (interventions) we have seen so far. Finally, a graph decoder model is trained to output the correct causal graph.</p>

<p>For more detail on these papers and similar papers, check out the <a href="https://iclr.cc/virtual/workshops_14.html">workshop on causal learning for decision making</a>.</p>

<h3 id="classification-theory">Classification theory</h3>

<p><a href="https://iclr.cc/virtual/poster_Hkxzx0NtDB.html">Your classifier is secretly an energy based model and you should treat it like one
</a></p>

<p>This paper blew me away: Using simple math, it shows very elegantly that a discriminative classifier can also be viewed as an energy-based model, which in turn allows you to detect samples coming from outside the distribution the classifier was originally trained on.</p>

<p>Let’s take a classifier with scalar output $f_{\theta}(x)[y]$ for input $x$ and class index $y$. Class probabilities can be obtained by using the softmax operation, which makes values positive and sum to one over all classes:</p>

<p>$p_{\theta}(y \vert x) = \frac{e^{f_{\theta}(x)[y]}}{\sum_y e^{f_{\theta}(x)[y]}}$.</p>

<p>But the unnormalised outputs can also be used to define an energy based model to define the joint probability over inputs $x$ and labels $y$</p>

<p>$p_{\theta}(x,y) = \frac{e^{f_{\theta}(x)[y]}}{Z(\theta)}$,</p>

<p>where $Z(\theta)$ is the normalising constant that sums up the total energy over the whole $(x,y)$ space.
The cool things is - we can now determine the likelihood of an input $p(x)$, by marginalising out $y$ from the above equation, which results in</p>

<p>$p_{\theta}(x) = \frac{\sum_y e^{f_{\theta}(x)[y]}}{Z(\theta)}$.</p>

<p>Notice that the numerator simply contains the sum of exponentiated outputs, which is the denominator in the softmax expression.
One can compute $p(y|x)$ to perform classification using the same rules of marginalising out variables, and surprisingly, obtain the exact same formulation of a softmax-based classifier we introduced in the beginning!</p>

<p>Authors then go on and train models as standard classifiers while also maximising the likelihood $p(x)$ at the same time.</p>

<p>The benefits are numerous:</p>
<ul>
  <li>Obtain good classification accuracy, almost as good as purely discriminative training</li>
  <li>Models can be used to generate new input samples</li>
  <li>Better calibrated classifier output probabilities - NNs are often prone to output probabilities close to 0 or 1, when they should be more uncertain, especially for novel inputs not seen during training. When using the proposed method, samples assigned to a class with a probability of 0.8 would actually end up being from that class 80% of the time.</li>
  <li>Out of distribution detection: Simply check an input example $x$ for its likelihood $p(x)$ - if it is too low, reject the sample and return “I don’t know”</li>
  <li>More robust to adversarial attacks. Even further increased robustness if the input $x$ is first preprocessed by letting the model perturb it into a version $\hat{x}$ that has higher likelihood $p(\hat{x}) &gt; p(x)$ first, thereby “undoing” the adversarial manipulation and restricting classification to input samples that are similar to those seen during training</li>
</ul>

<p><a href="https://iclr.cc/virtual/poster_ByxGkySKwH.html">Towards neural networks that provably know when they don’t know</a></p>

<p>In a similar vein, this paper calibrates classifier output probabilities by reformulating the conditional $p(y|x)$.
This approach assumes samples either come from the “in-distribution” (seen during training), or from a specific “out-distribution”, where the classifier should indicate its complete uncertainty by assigning the same probability to all classes.
$p(y|x)$ is then decomposed using Bayes rule:</p>

<p>$p(y \vert x) = \frac{p(y \vert x,i)p(x \vert i)p(i) + p(y \vert x,o)p(x \vert o)p(o)}{p(x \vert i)p(i) + p(x \vert o)p(o)}$</p>

<p>$i$ and $o$ indicate whether a sample comes from the in- or out distribution. $p(y \vert x,i)$ is the classifier of interest, while $p(y \vert x,o)$ is simply set to a uniform distribution over classes, which allows the authors to make uncertainty guarantees.
$p(x \vert i)$ and $p(x \vert o)$ are Gaussian mixture models indicating how likely it is to observe this input sample $x$ assuming it’s drawn from the in- or out distribution, respectively.</p>

<p>While the assumption of a specific out-distribution seems limiting, it is very nice to have mathematically proven guarantees for classifier confidences.</p>

<h3 id="learning-with-small-data-learning-representations">Learning with small data, learning representations</h3>

<p>Research on how to make deep learning generalise in the face of small datasets has reached a new peak in the last few years. Representation learning, self-supervised learning and meta learning are very popular topics, especially given recent breakthroughs in NLP by models such as BERT, and so ICLR also had a good representation (ha) of papers on these topics.</p>

<p>Current meta-learning approaches are often limited to the few-shot setting, where a model is only updated a few times on a task before it is used to make predictions (e.g. MAML <a class="citation" href="#finnModelAgnosticMetaLearning2017">[1], [2]</a>.
<a href="https://iclr.cc/virtual/poster_rkeiQlBFPB.html">WarpGrad</a> aims to extend the applicability of meta learning to settings where more adaptation might be needed.
Instead of directly learning an update rule for gradient descent, or a model initialisation from which training on a new task should start, it introduces so-called warp layers that essentially transform the optimisation landscape itself. The warp layer parameters can then be meta-learned so that normal SGD methods can more easily converge to good solutions.</p>

<p>For representation learning, <a href="https://iclr.cc/virtual/poster_BkeoaeHKDS.html">Gradients as Features for Deep Representation Learning</a> add another trainable output layer to pre-trained networks that operates on the network’s gradients, in addition to the usual linear output layer that is used to process intermediate activations from the pre-trained network.</p>

<p>In <a href="https://iclr.cc/virtual/poster_Syx79eBKwr.html">A Mutual Information Maximization Perspective of Language Representation Learning</a>, authors gain very interesting theoretical insight that commonly used representation learning techniques, such as Deep InfoMax or BERT, while not similar at first glance, all end up optimising a version of a common objective that maximises the mutual information between different parts of the input. This paper might turn out to be critical in developing self-supervised learning techniques that work reliably across different input domains (such as text, audio and video).</p>

<p><a href="https://iclr.cc/virtual/poster_B1esx6EYvr.html">A critical analysis of self-supervision, or what we can learn from a single image</a> investigates what current computer vision models can learn from very few (even just single) images under current self-supervision techniques, when strong data augmentation is used. The results are quite concerning: Self-supervision techniques currently can not rival standard supervised training even if millions of unlabelled images are used for self-supervision. Also, similar performance with self-supervision can be reached even when using a single image under heavy data augmentation, as this is sufficient to for early network layers to pick up on low-level statistics of natural images. It seems that self-supervision at the moment suffers from the unsolved problem of finding optimisation objectives that actually encourage modelling high-level, semantically meaningful properties of the input.</p>

<h3 id="audio-processing">Audio processing</h3>

<p>Due to my background in audio processing, I wanted to specifically highlight two audio related papers.</p>

<p>In <a href="https://iclr.cc/virtual/poster_rygjHxrYDB.html">Deep Audio Priors</a>, authors propose a new convolution kernel for audio spectrograms. They correctly note that using normal convolutions is well motivated for images, where nearby pixels are strongly correlated. For spectrograms, this also applies to the time dimension, but not to the frequency dimension, where one can find strong dependencies across the whole frequency band. In particular, many sound sources are harmonic, meaning they are comprised of a sine wave with a certain base frequency (fundamental frequency), accompanied by additional sine waves at frequencies which are multiples of the base frequency (caled harmonics). Authors change convolution kernels to reflect this to obtain “harmonic convolution”, which are assigned to attend to a certain base frequency in addition to frequency bins representing the harmonics. Experiments in audio source separation and audio denoising show improved performance over spectrogram-based U-Nets and Wave-U-Net, indicating that such convolutions provide a more suitable “audio prior”.</p>

<p><a href="https://iclr.cc/virtual/poster_B1x1ma4tDr.html">DDSP - Differentiable Digital Signal Processing</a>
This paper integrates many tools from traditional signal processing, such as synthesisers, with deep learning to gain the benefits of both - DSP provides useful building blocks that can realise complicated audio transformations with just a few control parameters, thereby bringing a lot of prior knowledge to bear on the problem at hand, while deep learning can flexibly learn the desired transformation based on the available training data. This can be especially useful for small data scenarios, where DSP tools are not flexible enough and can not make use of the data to improve results, and where standard deep learning models fail since they require much more data since they have to learn everything from scratch.</p>

<h3 id="a-final-note-on-transformer-efficiency">A final note on transformer efficiency</h3>

<p>There was lots of work trying to make transformer models more computationally efficient <a href="https://iclr.cc/virtual/poster_H1eA7AEtvS.html">[1]</a><a href="https://iclr.cc/virtual/poster_rkgNKkHtvB.html">[2]</a><a href="https://iclr.cc/virtual/poster_SylO2yStDr.html">[3]</a>, since they have a computational complexity of $O(N^2)$ for sequence inputs of length $N$.
This is encouraging to see – while their application was mostly limited to processing a few sentences at a time in the domain of NLP, this might allow for modelling long sequences such as audio signals and other time series data.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><div>
<a name="finnModelAgnosticMetaLearning2017" />
<b>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</b> <span style="font-size:15px"> () </span>
<br />

  Proc. of the International Conference on Machine Learning (ICML)
  <br />


<i>Finn, Chelsea and Abbeel, Pieter and Levine, Sergey</i>
</div>


    





    <a target="_blank" rel="noopener noreferrer" href="http://proceedings.mlr.press/v70/finn17a.html"><input class="button0" type="button" value="Link" /></a>


<a download="finnModelAgnosticMetaLearning2017.bib" href="data:application/x-bibtex,%7B%25raw%25%7D@inproceedings%7BfinnModelAgnosticMetaLearning2017,%0A%20%20title%20=%20%7BModel-%7B%7BAgnostic%20Meta%7D%7D-%7B%7BLearning%7D%7D%20for%20%7B%7BFast%20Adaptation%7D%7D%20of%20%7B%7BDeep%20Networks%7D%7D%7D,%0A%20%20booktitle%20=%20%7BProc.%20of%20the%20%7B%7BInternational%20Conference%7D%7D%20on%20%7B%7BMachine%20Learning%7D%7D%20(%7B%7BICML%7D%7D)%7D,%0A%20%20author%20=%20%7BFinn,%20Chelsea%20and%20Abbeel,%20Pieter%20and%20Levine,%20Sergey%7D,%0A%20%20editor%20=%20%7BPrecup,%20Doina%20and%20Teh,%20Yee%20Whye%7D,%0A%20%20date%20=%20%7B2017-08-06/2017-08-11%7D,%0A%20%20volume%20=%20%7B70%7D,%0A%20%20pages%20=%20%7B1126--1135%7D,%0A%20%20publisher%20=%20%7B%7BPMLR%7D%7D,%0A%20%20location%20=%20%7B%7BInternational%20Convention%20Centre,%20Sydney,%20Australia%7D%7D,%0A%20%20url%20=%20%7Bhttp://proceedings.mlr.press/v70/finn17a.html%7D,%0A%20%20abstract%20=%20%7BWe%20propose%20an%20algorithm%20for%20meta-learning%20that%20is%20model-agnostic,%20in%20the%20sense%20that%20it%20is%20compatible%20with%20any%20model%20trained%20with%20gradient%20descent%20and%20applicable%20to%20a%20variety%20of%20different%20learning%20problems,%20including%20classification,%20regression,%20and%20reinforcement%20learning.%20The%20goal%20of%20meta-learning%20is%20to%20train%20a%20model%20on%20a%20variety%20of%20learning%20tasks,%20such%20that%20it%20can%20solve%20new%20learning%20tasks%20using%20only%20a%20small%20number%20of%20training%20samples.%20In%20our%20approach,%20the%20parameters%20of%20the%20model%20are%20explicitly%20trained%20such%20that%20a%20small%20number%20of%20gradient%20steps%20with%20a%20small%20amount%20of%20training%20data%20from%20a%20new%20task%20will%20produce%20good%20generalization%20performance%20on%20that%20task.%20In%20effect,%20our%20method%20trains%20the%20model%20to%20be%20easy%20to%20fine-tune.%20We%20demonstrate%20that%20this%20approach%20leads%20to%20state-of-the-art%20performance%20on%20two%20few-shot%20image%20classification%20benchmarks,%20produces%20good%20results%20on%20few-shot%20regression,%20and%20accelerates%20fine-tuning%20for%20policy%20gradient%20reinforcement%20learning%20with%20neural%20network%20policies.%7D,%0A%20%20series%20=%20%7BProceedings%20of%20%7B%7BMachine%20Learning%20Research%7D%7D%7D%0A%7D%0A%7B%25endraw%25%7D"><input class="button0" type="button" value="Bibtex" /></a>
<a class="details" href="/repository/finnModelAgnosticMetaLearning2017/">Details</a></li>
<li><div>
<a name="nicholFirstOrderMetaLearning2018" />
<b>On First-Order Meta-Learning Algorithms</b> <span style="font-size:15px"> () </span>
<br />


<i>Nichol, Alex and Achiam, Joshua and Schulman, John</i>
</div>


    





    <a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1803.02999"><input class="button0" type="button" value="Link" /></a>


<a download="nicholFirstOrderMetaLearning2018.bib" href="data:application/x-bibtex,%7B%25raw%25%7D@article%7BnicholFirstOrderMetaLearning2018,%0A%20%20title%20=%20%7BOn%20%7B%7BFirst%7D%7D-%7B%7BOrder%20Meta%7D%7D-%7B%7BLearning%20Algorithms%7D%7D%7D,%0A%20%20author%20=%20%7BNichol,%20Alex%20and%20Achiam,%20Joshua%20and%20Schulman,%20John%7D,%0A%20%20date%20=%20%7B2018%7D,%0A%20%20journaltitle%20=%20%7BCoRR%7D,%0A%20%20volume%20=%20%7Babs/1803.02999%7D,%0A%20%20url%20=%20%7Bhttp://arxiv.org/abs/1803.02999%7D,%0A%20%20urldate%20=%20%7B2020-01-28%7D,%0A%20%20abstract%20=%20%7BThis%20paper%20considers%20meta-learning%20problems,%20where%20there%20is%20a%20distribution%20of%20tasks,%20and%20we%20would%20like%20to%20obtain%20an%20agent%20that%20performs%20well%20(i.e.,%20learns%20quickly)%20when%20presented%20with%20a%20previously%20unseen%20task%20sampled%20from%20this%20distribution.%20We%20analyze%20a%20family%20of%20algorithms%20for%20learning%20a%20parameter%20initialization%20that%20can%20be%20fine-tuned%20quickly%20on%20a%20new%20task,%20using%20only%20first-order%20derivatives%20for%20the%20meta-learning%20updates.%20This%20family%20includes%20and%20generalizes%20first-order%20MAML,%20an%20approximation%20to%20MAML%20obtained%20by%20ignoring%20second-order%20derivatives.%20It%20also%20includes%20Reptile,%20a%20new%20algorithm%20that%20we%20introduce%20here,%20which%20works%20by%20repeatedly%20sampling%20a%20task,%20training%20on%20it,%20and%20moving%20the%20initialization%20towards%20the%20trained%20weights%20on%20that%20task.%20We%20expand%20on%20the%20results%20from%20Finn%20et%20al.%20showing%20that%20first-order%20meta-learning%20algorithms%20perform%20well%20on%20some%20well-established%20benchmarks%20for%20few-shot%20classification,%20and%20we%20provide%20theoretical%20analysis%20aimed%20at%20understanding%20why%20these%20algorithms%20work.%7D,%0A%20%20archiveprefix%20=%20%7BarXiv%7D,%0A%20%20eprint%20=%20%7B1803.02999%7D,%0A%20%20eprinttype%20=%20%7Barxiv%7D,%0A%20%20keywords%20=%20%7BComputer%20Science%20-%20Machine%20Learning%7D%0A%7D%0A%7B%25endraw%25%7D"><input class="button0" type="button" value="Bibtex" /></a>
<a class="details" href="/repository/nicholFirstOrderMetaLearning2018/">Details</a></li></ol>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#conference" class="page__taxonomy-item" rel="tag">Conference</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#iclr" class="page__taxonomy-item" rel="tag">ICLR</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#machine-learning" class="page__taxonomy-item" rel="tag">Machine learning</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#theory" class="page__taxonomy-item" rel="tag">Theory</a>
    
    </span>
  </p>




        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2019-02-21T00:00:00+01:00">February 21, 2019</time></p>
        
      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=ICLR+2020+impressions+and+paper+highlights%20https%3A%2F%2Fdans.world%2FICLR-2020%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdans.world%2FICLR-2020%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fdans.world%2FICLR-2020%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/Spotify-internship/" class="pagination--pager" title="Spotify Internship Report
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/Spotify-internship/" rel="permalink">Spotify Internship Report
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  6 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">From June to September 2019, I took a break from my ongoing PhD and worked as a Research Intern at Spotify in London.
I was under the supervision of Simon Du...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/Bounded-output-networks/" rel="permalink">Bounded output regression with neural networks
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  5 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Say we have a neural network (or some other model trainable with gradient descent) that performs supervised regression: For an input $x$, it outputs one or m...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/ISMIR-Summary/" rel="permalink">ISMIR 2018 - Paper Overviews
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  13 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This year’s ISMIR was great as ever, this time featuring


  lots of deep learning - I suspect since it became much more easy to use with recently developed ...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/Spectrogram-input-normalisation-for-neural-networks/" rel="permalink">Spectrogram input normalisation for neural networks
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  7 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">In this post, I want to talk about magnitude spectrograms as inputs and outputs of neural networks, and how to normalise them to help the training process.

</p>
  </article>
</div>
        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>
      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
    
    
    
      <li><a href="https://github.com/f90"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Daniel Stoller. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.1.0/js/all.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    
  



  </body>
</html>