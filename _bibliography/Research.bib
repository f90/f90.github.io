% This file was created with JabRef 2.7.1.
% Encoding: UTF8

@PHDTHESIS{Adiloglu2012,
  author = {Adiloglu, Kamil and Vincent, Emmanuel},
  title = {Variational Bayesian inference for source separation and robust feature
	extraction},
  school = {INRIA},
  year = {2012},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Adiloglu, Vincent - Variational Bayesian Inference for Source Separation and Robust Feature Extraction.pdf:PDF}
}

@INPROCEEDINGS{Airas2007,
  author = {Matti Airas and Paavo Alku},
  title = {Comparison of multiple voice source parameters in different phonation
	types},
  booktitle = {8th Annual Conference of the International Speech Communication Association
	{(INTERSPEECH)}},
  year = {2007},
  pages = {1410-1413},
  abstract = {A large sample of vowels produced by male and female speakers were
	inverse filtered and parameterized using 21 different glottal flow
	parameters. The performance of the different parameters in expression
	of the phonation type was then tested using objective statistical
	methods. The comparison of the results revealed marked differences
	in the parameters ’ performance, and therefore, guidelines for parameter
	use and comparison were established. Index Terms: voice quality,
	phonation type, inverse filtering, voice source, parameterization},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=AD56AFF7FF508CEA6D9CFF9299D2B8DD?doi=10.1.1.205.1553}
}

@INPROCEEDINGS{Alkhouli2016,
  author = {Tamer Alkhouli and Gabriel Bretschner and Jan-Thorsten Peter and
	Mohammed Hethnawi and Andreas Guta and Hermann Ney},
  title = {Alignment-Based Neural Machine Translation},
  booktitle = {WMT},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Alkhouli, Bretschner, Peter, Hethnawi, Guta, Ney - Alignment-based neural machine translation.pdf:PDF}
}

@INPROCEEDINGS{Alku1992,
  author = {Alku, Paavo},
  title = {An automatic method to estimate the time-based parameters of the
	glottal pulseform},
  booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing
	(ICASSP)},
  year = {1992},
  volume = {2},
  pages = {29--32},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Alku - An automatic method to estimate the time-based parameters of the glottal waveform.pdf:PDF}
}

@ARTICLE{Alku2002,
  author = {Alku, Paavo and B{\"a}ckstr{\"o}m, Tom and Vilkman, Erkki},
  title = {Normalized amplitude quotient for parametrization of the glottal
	flow},
  journal = {The Journal of the Acoustical Society of America},
  year = {2002},
  volume = {112},
  pages = {701-710},
  number = {2},
  doi = {http://dx.doi.org/10.1121/1.1490365},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Alku, Backstrom, Vilkman - Normalised amplitude quotient for parametrisation of the glottal flow.pdf:PDF},
  url = {http://scitation.aip.org/content/asa/journal/jasa/112/2/10.1121/1.1490365;jsessionid=tsivhlva9c43.x-aip-live-06}
}

@ARTICLE{Ambrogioni2017,
  author = {Ambrogioni, Luca and G{\"u}{\c{c}}l{\"u}, Umut and van Gerven, Marcel
	AJ and Maris, Eric},
  title = {The Kernel Mixture Network: A Nonparametric Method for Conditional
	Density Estimation of Continuous Random Variables},
  journal = {arXiv preprint arXiv:1705.07111},
  year = {2017},
  file = {:/mnt/daten/Seafile/PhD/Literature/Docea/Papers/Ambrogioni, Güclu, Gerven, Maris - The kernel mixture network - a nonparametric method for conditional density estimation of continuous random variables.pdf:PDF}
}

@ARTICLE{Andrews1995,
  author = {Andrews, Robert and Diederich, Joachim and Tickle, Alan B.},
  title = {Survey and critique of techniques for extracting rules from trained
	artificial neural networks},
  journal = {Knowledge-based systems},
  year = {1995},
  volume = {8},
  pages = {373--389},
  number = {6},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Andrews, Diederich, Tickle, Survey and ctriqiue of techniques for extracting rules from trained artificial neural networks.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Andrychowicz2016,
  author = {Marcin Andrychowicz and Misha Denil and Sergio Gomez Colmenarejo
	and Matthew W. Hoffman and David Pfau and Tom Schaul and Nando de
	Freitas},
  title = {Learning to learn by gradient descent by gradient descent},
  journal = {CoRR},
  year = {2016},
  volume = {abs/1606.04474},
  archiveprefix = {arXiv},
  eprint = {1606.04474},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Andrychowicz, Denil, Colmenarejo, Hoffman, Pfau, Schaul, Shillingford, de Freitas - Learning to learn by gradient descent by gradient descent.pdf:PDF},
  url = {http://arxiv.org/abs/1606.04474}
}

@ELECTRONIC{ApacheCommons2016,
  author = {{Apache Commons}},
  year = {2016},
  title = {Apache Commons Math Library},
  url = {https://commons.apache.org/proper/commons-math/},
  owner = {Daniel},
  timestamp = {2016.02.12}
}

@INPROCEEDINGS{Arjovsky2017a,
  author = {Arjovsky, Martin and Bottou, L{\'e}on},
  title = {Towards principled methods for training generative adversarial networks},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year = {2017},
  arxiv = {http://arxiv.org/abs/1312.5851},
  url = {http://openreview.net/document/aa6ab717-ca19-47e1-a958-823b9a106ca9}
}

@ARTICLE{Arjovsky2017,
  author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  title = {Wasserstein GAN},
  journal = {arXiv preprint arXiv:1701.07875},
  year = {2017},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Arjovsky, Chintala, Bottou - Wasserstein GAN.pdf:PDF}
}

@BOOK{Aronson2011,
  title = {Clinical voice disorders},
  publisher = {Thieme},
  year = {2011},
  author = {Aronson, Arnold E and Bless, Diane}
}

@ARTICLE{ArtemisMoroni2000,
  author = {Artemis Moroni, Jônatas Manzolli, Fernando von Zuben, Ricardo Gudwin},
  title = {Vox Populi: An Interactive Evolutionary System for Algorithmic Music
	Composition},
  journal = {Leonardo Music Journal},
  year = {2000},
  volume = {10},
  pages = {49-54},
  abstract = {While recent techniques of digital sound synthesis have put numerous
	new sounds on the musician's desktop, several artificial-intelligence
	(AI) techniques have also been applied to algorithmic composition.
	This article introduces Vox Populi, a system based on evolutionary
	computation techniques for composing music in real time. In Vox Populi,
	a population of chords codified according to MIDI protocol evolves
	through the application of genetic algorithms to maximize a fitness
	criterion based on physical factors relevant to music. Graphical
	controls allow the user to manipulate fitness and sound attributes.},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Moroni Manzolli Von Zuben Gudwin - Vox Populi - An Interactive Evolutionary System for Algorithmic Music Composition.pdf:PDF},
  issn = {09611215, 15314812},
  publisher = {The MIT Press},
  url = {http://www.jstor.org/stable/1513378}
}

@ARTICLE{assayag2004using,
  author = {Assayag, G{\'e}rard and Dubnov, Shlomo},
  title = {Using factor oracles for machine improvisation},
  journal = {Soft Computing},
  year = {2004},
  volume = {8},
  pages = {604--610},
  number = {9},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Assayag, Dubnov - Using factor oracles for machine improvisation.pdf:PDF},
  publisher = {Springer}
}

@MISC{Crossfading,
  author = {{Audacity team}},
  title = {Crossfade types},
  howpublished = {\url{http://manual.audacityteam.org/o/man/crossfade_tracks.html}},
  note = {Accessed: 2017-02-15}
}

@INPROCEEDINGS{Avidan:2007,
  author = {Avidan, S. and Shamir, A.},
  title = {Seam carving for content-aware image resizing},
  booktitle = {ACM Transactions on graphics (TOG)},
  year = {2007},
  volume = {26},
  number = {3},
  pages = {10},
  //organization = {ACM}
}

@BOOK{Back1996,
  title = {Evolutionary Algorithms in Theory and Practice: Evolution Strategies,
	Evolutionary Programming, Genetic Algorithms},
  publisher = {Oxford University Press},
  year = {1996},
  author = {B\"{a}ck, Thomas},
  address = {Oxford, UK},
  isbn = {0-19-509971-0}
}

@ARTICLE{Bahdanau2014,
  author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  title = {Neural machine translation by jointly learning to align and translate},
  journal = {arXiv preprint arXiv:1409.0473},
  year = {2014},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Bahdanau, Cho, Bengio - Neural machine translation by jointly learning to align and translate.pdf:PDF}
}

@INPROCEEDINGS{Bahdanau2016,
  author = {Bahdanau, Dzmitry and Chorowski, Jan and Serdyuk, Dmitriy and Bengio,
	Yoshua and others},
  title = {End-to-end attention-based large vocabulary speech recognition},
  booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2016},
  pages = {4945--4949},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Bahdanau, Chorowski, Serdyuk, Brakel, Bengio - End-to-end attention-based large vocabulary speech recognition.pdf:PDF}
}

@INPROCEEDINGS{Balcan2005,
  author = {Balcan, Maria-Florina and Blum, Avrim},
  title = {A PAC-style model for learning from labeled and unlabeled data},
  booktitle = {International Conference on Computational Learning Theory},
  year = {2005},
  pages = {111--126},
  organization = {Springer},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Balcan, Blum - A PAC-style model for learning from labeled and unlabeled data.pdf:PDF}
}

@ARTICLE{Balduzzi2016,
  author = {Balduzzi, David and Ghifary, Muhammad},
  title = {Strongly-Typed Recurrent Neural Networks},
  journal = {arXiv preprint arXiv:1602.02218},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Balduzzi, Ghifary - Strongly-Typed Recurrent Neural Networks.pdf:PDF}
}

@INPROCEEDINGS{Barker2018,
  author = {Jon Barker and Shinji Watanabe and Emmanuel Vincent and Jan Trmal},
  title = {The fifth {CHiME} Speech Separation and Recognition Challenge: Dataset,
	task and baselines},
  booktitle = {Proceedings Interspeech},
  year = {2018}
}

@ARTICLE{Bartsch2005,
  author = {Bartsch, Mark A and Wakefield, Gregory H},
  title = {Audio thumbnailing of popular music using chroma-based representations},
  journal = {Multimedia, IEEE Transactions on},
  year = {2005},
  volume = {7},
  pages = {96--104},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Audio Thumbnailing with chroma features.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Ben-David2008,
  author = {Ben-David, Shai and Lu, Tyler and P{\'a}l, D{\'a}vid},
  title = {Does Unlabeled Data Provably Help? Worst-case Analysis of the Sample
	Complexity of Semi-Supervised Learning.},
  booktitle = {COLT},
  year = {2008},
  pages = {33--44}
}

@INPROCEEDINGS{Ben-David2008a,
  author = {Ben-David, Shai and Lu, Tyler and P{\'a}l, D{\'a}vid},
  title = {Does Unlabeled Data Provably Help? Worst-case Analysis of the Sample
	Complexity of Semi-Supervised Learning.},
  booktitle = {COLT},
  year = {2008},
  pages = {33--44},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ben-David, Lu, Pal - Does unlabeled data provably help - worst-case analysis of the sample complexity of semi-supervised learning.pdf:PDF}
}

@ARTICLE{Benetos2013,
  author = {Benetos, Emmanouil and Dixon, Simon and Giannoulis, Dimitrios and
	Kirchhoff, Holger and Klapuri, Anssi},
  title = {Automatic music transcription: challenges and future directions},
  journal = {Journal of Intelligent Information Systems},
  year = {2013},
  volume = {41},
  pages = {407--434},
  number = {3},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Benetos, Dixon, Giannoulis, Kirchhoff, Klapuri - Automatic Music Transcription Challenges and Future Directions.pdf:PDF},
  publisher = {Springer}
}

@ARTICLE{Bengio2013,
  author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pierre},
  title = {Representation learning: A review and new perspectives},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {2013},
  volume = {35},
  pages = {1798--1828},
  number = {8},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Bengio, Courville, Vincent - Representation Learning - A review and new perspectives.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Bengio2016,
  author = {Bengio, Yoshua and Scellier, Benjamin and Bilaniuk, Olexa and Sacramento,
	Joao and Senn, Walter},
  title = {Feedforward Initialization for Fast Inference of Deep Generative
	Networks is biologically plausible},
  journal = {arXiv preprint arXiv:1606.01651},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Bengio, Scellier, Bilaniuk, Sacramento, Senn - Feedforward initialization for fast inference in deep generative networks is biologically plausible.pdf:PDF}
}

@INPROCEEDINGS{Bengio2013a,
  author = {Bengio, Yoshua and Yao, Li and Alain, Guillaume and Vincent, Pascal},
  title = {Generalized denoising auto-encoders as generative models},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2013},
  pages = {899--907},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Bengio, Yao, Alain, Vincent- Generalized denoising auto-encoders as generative models.pdf:PDF}
}

@ARTICLE{Benzi2016,
  author = {Kirell Benzi and Micha{\"{e}}l Defferrard and Pierre Vandergheynst
	and Xavier Bresson},
  title = {{FMA:} {A} Dataset For Music Analysis},
  journal = {CoRR},
  year = {2016},
  volume = {abs/1612.01840},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.org/rec/bib/journals/corr/BenziDVB16},
  eprint = {1612.01840},
  timestamp = {Wed, 07 Jun 2017 14:40:59 +0200},
  url = {http://arxiv.org/abs/1612.01840}
}

@ARTICLE{Bergan2004,
  author = {Christine C. Bergan and Ingo R. Titze and Brad Story},
  title = {The perception of two vocal qualities in a synthesized vocal utterance:
	ring and pressed voice },
  journal = {Journal of Voice },
  year = {2004},
  volume = {18},
  pages = {305 - 317},
  number = {3},
  abstract = {Two vocal qualities, ring quality and pressed quality, were analyzed
	perceptually. Listeners were asked to rate (on a scale from 0 to
	10) the “amount of ring�? in one listening and the “amount of pressedness�?
	in another listening. The stimulus was the synthesized utterance
	/ya-ya-ya-ya-ya/. In the continuum representation of ring, the skewing
	quotient and the cross section of the epilaryngeal tube area were
	systematically varied, independently and by a covariation rule. In
	the continuum representation of pressed, the flow amplitude and open
	quotient were similarly varied. Results indicated that the crossover
	point between ring and no ring occurred with an epilaryngeal area
	of around 1.0 cm2, and the crossover point between pressed and not
	pressed quality occurred at an open quotient of about 0.4. Fundamental
	frequency also had an effect on the perceptions, with a higher fundamental
	frequency receiving higher ratings of ring and pressed for otherwise
	the same parameters. Listeners demonstrated highly variable perceptions
	in both continua with poor intersubject, intrasubject, and intergroup
	reliability. },
  doi = {http://dx.doi.org/10.1016/j.jvoice.2003.09.004},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Bergan Titze Story - The perception of two vocal qualities in a synthesized vocal utterance ring and pressed voice.pdf:PDF},
  issn = {0892-1997},
  keywords = {Voice},
  url = {http://www.sciencedirect.com/science/article/pii/S0892199703001668}
}

@ARTICLE{Berthouzoz2012,
  author = {Berthouzoz, Floraine and Li, Wilmot and Agrawala, Maneesh},
  title = {Tools for placing cuts and transitions in interview video},
  journal = {ACM Transactions on Graphics (TOG)},
  year = {2012},
  volume = {31},
  pages = {67},
  number = {4},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Tools for placing cuts and transitions in video interviews.pdf:PDF},
  publisher = {ACM}
}

@INPROCEEDINGS{Biles1994,
  author = {Biles, John},
  title = {GenJam: A genetic algorithm for generating jazz solos},
  booktitle = {Proceedings of the International Computer Music Conference},
  year = {1994},
  pages = {131--131},
  organization = {INTERNATIONAL COMPUTER MUSIC ACCOCIATION},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\GenJam - Genetic Algorithm for Generating Jazz Solos.pdf:PDF}
}

@INPROCEEDINGS{Birkholz2007,
  author = {Birkholz, Peter},
  title = {Articulatory synthesis of singing.},
  booktitle = {INTERSPEECH},
  year = {2007},
  pages = {4001--4004},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Birkholz - Articulatory synthesis of singing.pdf:PDF}
}

@INPROCEEDINGS{Bittner2014,
  author = {Rachel Bittner and Justin Salamon and Mike Tierney and Matthias Mauch
	and Chris Cannam and Juan Bello},
  title = {{MedleyDB}: A multitrack dataset for annotation-intensive {MIR} research},
  booktitle = {International Society for Music Information Retrieval Conference
	({ISMIR})},
  year = {2014}
}

@ARTICLE{Blaauw2017,
  author = {Blaauw, Merlijn and Bonada, Jordi},
  title = {A Neural Parametric Singing Synthesizer},
  journal = {arXiv preprint arXiv:1704.03809},
  year = {2017},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Blaauw, Bonada - A neural parametric singing synthesizer.pdf:PDF}
}

@INPROCEEDINGS{Black2014,
  author = {Black, Dawn A. A. and Li, Ma and Tian, Mi},
  title = {Automatic Identification of Emotional Cues in Chinese Opera Singing},
  booktitle = {13th Int. Conf. on Music Perception and Cognition (ICMPC)},
  year = {2014},
  pages = {250--255},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Black, Li, Tian - Automatic Identification of emotional cues in chinese opera singing.pdf:PDF}
}

@ARTICLE{Blei2016,
  author = {Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  title = {Variational inference: A review for statisticians},
  journal = {arXiv preprint arXiv:1601.00670},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Blei, Kucukelbir, McAuliffe - Variational inference - a review for statisticians.pdf:PDF}
}

@ARTICLE{Borch2011,
  author = {Daniel Z. Borch and Johan Sundberg},
  title = {Some Phonatory and Resonatory Characteristics of the Rock, Pop, Soul,
	and Swedish Dance Band Styles of Singing },
  journal = {Journal of Voice },
  year = {2011},
  volume = {25},
  pages = {532 - 537},
  number = {5},
  abstract = {Summary This investigation aims at describing voice function of four
	nonclassical styles of singing, Rock, Pop, Soul, and Swedish Dance
	Band. A male singer, professionally experienced in performing in
	these genres, sang representative tunes, both with their original
	lyrics and on the syllable /pae/. In addition, he sang tones in a
	triad pattern ranging from the pitch Bb2 to the pitch \{C4\} on the
	syllable /pae/ in pressed and neutral phonation. An expert panel
	was successful in classifying the samples, thus suggesting that the
	samples were representative of the various styles. Subglottal pressure
	was estimated from oral pressure during the occlusion for the consonant
	[p]. Flow glottograms were obtained from inverse filtering. The four
	lowest formant frequencies differed between the styles. The mean
	of the subglottal pressure and the mean of the normalized amplitude
	quotient (NAQ), that is, the ratio between the flow pulse amplitude
	and the product of period and maximum flow declination rate, were
	plotted against the mean of fundamental frequency. In these graphs,
	Rock and Swedish Dance Band assumed opposite extreme positions with
	respect to subglottal pressure and mean phonation frequency, whereas
	the mean \{NAQ\} values differed less between the styles.},
  doi = {http://dx.doi.org/10.1016/j.jvoice.2010.07.014},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Borch Sundberg - Some Phonatory and Resonatory Characteristics of the Rock, Pop, Soul, and Swedish Dance Band Styles of Singing.pdf:PDF},
  issn = {0892-1997},
  keywords = {Formant frequencies},
  url = {http://www.sciencedirect.com/science/article/pii/S0892199710001372}
}

@BOOK{Boost,
  title = {The Boost C++ Libraries},
  publisher = {XML Press},
  year = {2011},
  author = {Boris, S.},
  //isbn = {0982219199, 9780982219195}
}

@INPROCEEDINGS{Boulanger-Lewandowski2013,
  author = {Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
  title = {Audio Chord Recognition with Recurrent Neural Networks.},
  booktitle = {ISMIR},
  year = {2013},
  pages = {335--340},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Boulanger-Lewandowski, Bengio, Vincent - Audio chord recognition with recurrent neural networks.pdf:PDF}
}

@ARTICLE{Boulanger-Lewandowski2012,
  author = {Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
  title = {Modeling temporal dependencies in high-dimensional sequences: Application
	to polyphonic music generation and transcription},
  journal = {arXiv preprint arXiv:1206.6392},
  year = {2012},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Boulanger-Lewandowski, Bengio, Vincent - Modeling Temporal Dependencies in high-dimensional sequences - application to polyphonic music generation and transcription.pdf:PDF}
}

@BOOK{Bracewell1986,
  title = {The Fourier transform and its applications},
  publisher = {McGraw-Hill New York},
  year = {1986},
  author = {Bracewell, Ronald Newbold and Bracewell, Ronald N},
  volume = {31999},
  pages = {46}
}

@ARTICLE{Brakel2017,
  author = {{Brakel}, P. and {Bengio}, Y.},
  title = {{Learning Independent Features with Adversarial Nets for Non-linear
	ICA}},
  journal = {ArXiv e-prints},
  year = {2017},
  archiveprefix = {arXiv},
  eprint = {1710.05050},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Brakel, Bengio - Learning independent features with adversarial nets for non-linear ICA.pdf:PDF},
  keywords = {Statistics - Machine Learning},
  primaryclass = {stat.ML}
}

@ARTICLE{Bregman1971,
  author = {Bregman, Albert S and Campbell, Jeffrey},
  title = {Primary auditory stream segregation and perception of order in rapid
	sequences of tones.},
  journal = {Journal of experimental psychology},
  year = {1971},
  volume = {89},
  pages = {244},
  number = {2},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Bregman, Campbell - Primary Auditory Stream Segregation and Perception of Order in Rapid Sequences Of Tones.pdf:PDF},
  publisher = {American Psychological Association}
}

@ARTICLE{Bregman1978,
  author = {Bregman, Albert S and Pinker, Steven},
  title = {Auditory streaming and the building of timbre.},
  journal = {Canadian Journal of Psychology/Revue canadienne de psychologie},
  year = {1978},
  volume = {32},
  pages = {19},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Bregman, Pinker - Auditory Streaming and the building of timbre.pdf:PDF},
  publisher = {University of Toronto Press}
}

@BOOK{Breiman1984,
  title = {Classification and regression trees},
  publisher = {CRC press},
  year = {1984},
  author = {Breiman, Leo and Friedman, Jerome and Stone, Charles J. and Olshen,
	Richard A.}
}

@INCOLLECTION{Burgoyne2007,
  author = {Burgoyne, John Ashley and McAdams, Stephen},
  title = {A meta-analysis of timbre perception using nonlinear extensions to
	CLASCAL},
  booktitle = {Computer Music Modeling and Retrieval. Sense of Sounds},
  publisher = {Springer},
  year = {2007},
  pages = {181--202},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Burgoyne - A meta-analysis of timbre perception using nonlinear extensions to CLASCAL.pdf:PDF}
}

@ARTICLE{Caclin2005,
  author = {Caclin, Anne and McAdams, Stephen and Smith, Bennett K and Winsberg,
	Suzanne},
  title = {Acoustic correlates of timbre space dimensions: A confirmatory study
	using synthetic tonesa)},
  journal = {The Journal of the Acoustical Society of America},
  year = {2005},
  volume = {118},
  pages = {471--482},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Caclin - Acoustic correlates of timbre space dimensions A confirmatory study using synthetic tonesa).pdf:PDF},
  publisher = {Acoustical Society of America}
}

@INBOOK{Caruana1998,
  pages = {95--133},
  title = {Multitask Learning},
  publisher = {Springer US},
  year = {1998},
  editor = {Thrun, Sebastian and Pratt, Lorien},
  author = {Caruana, Rich},
  address = {Boston, MA},
  abstract = {Multitask Learning is an approach to inductive transfer that improves
	generalization by using the domain information contained in the training
	signals of related tasks as an inductive bias. It does this by learning
	tasks in parallel while using a shared representation; what is learned
	for each task can help other tasks be learned better. This paper
	reviews prior work on MTL, presents new evidence that MTL in backprop
	nets discovers task relatedness without the need of supervisory signals,
	and presents new results for MTL with k-nearest neighbor and kernel
	regression. In this paper we demonstrate multitask learning in three
	domains. We explain how multitask learning works, and show that there
	are many opportunities for multitask learning in real domains. We
	present an algorithm and results for multitask learning with case-based
	methods like k-nearest neighbor and kernel regression, and sketch
	an algorithm for multitask learning in decision trees. Because multitask
	learning works, can be applied to many different kinds of domains,
	and can be used with different learning algorithms, we conjecture
	there will be many opportunities for its use on real-world problems.},
  booktitle = {Learning to Learn},
  isbn = {978-1-4615-5529-2}
}

@ARTICLE{Celeux1992,
  author = {Celeux, Gilles and Govaert, G{\'e}rard},
  title = {A Classification {EM} Algorithm for Clustering and Two Stochastic
	Versions},
  journal = {Computational Statistics and Data Analysis},
  year = {1992},
  volume = {14},
  pages = {315--332},
  number = {3},
  acmid = {146608},
  address = {Amsterdam, The Netherlands, The Netherlands},
  issn = {0167-9473},
  issue_date = {Oct. 1992},
  numpages = {18},
  publisher = {Elsevier Science Publishers B. V.}
}

@ARTICLE{Cemgil2007,
  author = {Cemgil, A Taylan and F{\'e}votte, C{\'e}dric and Godsill, Simon J},
  title = {Variational and stochastic inference for Bayesian source separation},
  journal = {Digital Signal Processing},
  year = {2007},
  volume = {17},
  pages = {891--913},
  number = {5},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Cemgil, Fevotte, Godsill - Variational and stochastic inference for Bayesian source separation.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Chan2015,
  author = {Chan, Tak-Shing and Yeh, Tzu-Chun and Fan, Zhe-Cheng and Chen, Hung-Wei
	and Su, Li and Yang, Yi-Hsuan and Jang, Roger},
  title = {Vocal activity informed singing voice separation with the {iKala}
	dataset},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing
	(ICASSP)},
  year = {2015},
  pages = {718--722},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Chan, Yeh, Fan, Chen, Su, Yang, Jang - Vocal activity informed singing voice separation with the ikala dataset.pdf:PDF}
}

@ARTICLE{Chan2016,
  author = {Chan, Tak-Shing T and Yang, Yi-Hsuan},
  title = {Complex and Quaternionic Principal Component Pursuit and Its Application
	to Audio Separation},
  journal = {IEEE Signal Processing Letters},
  year = {2016},
  volume = {23},
  pages = {287--291},
  number = {2},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Chan, Yang - Complex and quaternionic principal component pursuit and its application to audio separation - preprint.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Chang2017,
  author = {Chang, Sungkyun and Lee, Kyogu},
  title = {Lyrics-to-Audio Alignment by Unsupervised Discovery of Repetitive
	Patterns in Vowel Acoustics},
  journal = {arXiv preprint arXiv:1701.06078},
  year = {2017},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Lyrics-to-Audio Alignment by Unsupervised Discovery of Repetitive Patterns in Vowel Acoustics.pdf:PDF}
}

@ARTICLE{Chen2016,
  author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and
	Sutskever, Ilya and Abbeel, Pieter},
  title = {InfoGAN: Interpretable Representation Learning by Information Maximizing
	Generative Adversarial Nets},
  journal = {arXiv preprint arXiv:1606.03657},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Chen, Duan, Houthooft, Schulman, Sutskever, Abbeel -  infoGAN - Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets.pdf:PDF}
}

@INCOLLECTION{Chew2013,
  author = {Chew, Elaine and Callender, Clifton},
  title = {Conceptual and Experiential Representations of Tempo: Effects on
	Expressive Performance Comparisons},
  booktitle = {Mathematics and Computation in Music},
  publisher = {Springer},
  year = {2013},
  pages = {76--87},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Chew, Callender - Conceptual and Experiential Representations of Tempo.pdf:PDF}
}

@ARTICLE{Chien2016,
  author = {Chien, Yu-Ren and Wang, Hsin-Min and Jeng, Shyh-Kang},
  title = {Alignment of Lyrics With Accompanied Singing Audio Based on Acoustic-Phonetic
	Vowel Likelihood Modeling},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year = {2016},
  volume = {24},
  pages = {1998--2008},
  number = {11},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Chien, Wang, Jeng - Alignment of lyrics with accompanied singing audio based on acoustic-phonetic vowel likelihood modeling.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Choi2017,
  author = {Choi, Keunwoo and Fazekas, Gy{\"o}rgy and Sandler, Mark and Cho,
	Kyunghyun},
  title = {Transfer learning for music classification and regression tasks},
  booktitle = {Proceedings of the International Society for Music Information Retrieval
	Conference ({ISMIR})},
  year = {2018},
  volume = {18},
  pages = {141--149},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Choi, Fazekas, Sandler, Cho - Transfer learning for music classification and regression tasks.pdf:PDF}
}

@ARTICLE{Chuan2011,
  author = {Chuan, Ching-Hua and Chew, Elaine},
  title = {Generating and evaluating musical harmonizations that emulate style},
  journal = {Computer Music Journal},
  year = {2011},
  volume = {35},
  pages = {64--82},
  number = {4},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Generating and evaluating musical harmonisations that emulate style.pdf:PDF},
  publisher = {MIT Press}
}

@ARTICLE{Chung2016,
  author = {Chung, Junyoung and Ahn, Sungjin and Bengio, Yoshua},
  title = {Hierarchical Multiscale Recurrent Neural Networks},
  journal = {arXiv preprint arXiv:1609.01704},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Chung, Ahn, Bengio - Hierarchical Multiscale Recurrent Neural Networks.pdf:PDF}
}

@INPROCEEDINGS{Chung2015,
  author = {Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth
	and Courville, Aaron C and Bengio, Yoshua},
  title = {A recurrent latent variable model for sequential data},
  booktitle = {Advances in neural information processing systems},
  year = {2015},
  pages = {2980--2988},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Chung, Kastner, Dinh, Goel, Courville, Bengio - A recurrent latent variable model for sequential data.pdf:PDF}
}

@ARTICLE{Ciarleglio2008,
  author = {Ciarleglio, Michael Ian},
  title = {Modular abstract self-learning tabu search (MASTS): Metaheuristic
	search theory and practice},
  year = {2008},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Keskar, Mudigere, Nocedal, Smelyanskiy - On Large-Batch Training for Deep Learning - Generalization Gap and Sharp Minima.pdf:PDF}
}

@ARTICLE{Clarke1987,
  author = {Clarke, Eric F},
  title = {Categorical rhythm perception: an ecological perspective},
  journal = {Action and perception in rhythm and music},
  year = {1987},
  volume = {55},
  pages = {19--33},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Clarke - Categorical rhythm perception, an ecological perspective.pdf:PDF},
  publisher = {Royal Swedish Academy of Music Stockholm}
}

@ARTICLE{Cleveland1988,
  author = {Cleveland, William S. and Devlin, Susan J.},
  title = {Locally weighted regression: an approach to regression analysis by
	local fitting},
  journal = {Journal of the American statistical association},
  year = {1988},
  volume = {83},
  pages = {596--610},
  number = {403},
  publisher = {Taylor \& Francis Group}
}

@ARTICLE{Cuddy1976,
  author = {Cuddy, Lola L and Cohen, Annabel J},
  title = {Recognition of transposed melodic sequences},
  journal = {The Quarterly Journal of Experimental Psychology},
  year = {1976},
  volume = {28},
  pages = {255--270},
  number = {2},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Cuddy, Cohen - Recognition of transposed melodic sequences.pdf:PDF},
  publisher = {Taylor \& Francis}
}

@ARTICLE{Cybenko1989,
  author = {Cybenko, George},
  title = {Approximation by superpositions of a sigmoidal function},
  journal = {Mathematics of control, signals and systems},
  year = {1989},
  volume = {2},
  pages = {303--314},
  number = {4},
  publisher = {Springer}
}

@INPROCEEDINGS{Dai2015,
  author = {Dai, Jiajie and Mauch, Matthias and Dixon, Simon},
  title = {ANALYSIS OF INTONATION TRAJECTORIES IN SOLO SINGING},
  booktitle = {Proceedings of the 16th ISMIR Conference},
  year = {2015},
  volume = {421},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Analysis of Intonation Trajectories in Solo Singing.pdf:PDF}
}

@ARTICLE{Dai2017a,
  author = {Dai, Zihang and Almahairi, Amjad and Bachman, Philip and Hovy, Eduard
	and Courville, Aaron},
  title = {Calibrating energy-based generative adversarial networks},
  journal = {arXiv preprint arXiv:1702.01691},
  year = {2017},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Dai, Almahairi, Bachmann, Hovy, Courville - Calibrating energy-based generative adversarial networks.pdf:PDF}
}

@ARTICLE{Dai2017,
  author = {Dai, Zihang and Yang, Zhilin and Yang, Fan and Cohen, William W and
	Salakhutdinov, Ruslan},
  title = {Good Semi-supervised Learning that Requires a Bad GAN},
  journal = {arXiv preprint arXiv:1705.09783},
  year = {2017},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Dai, Yang, Yang, Cohen, Salakhutdinov - Good semi-supervised learning that requires a bad GAN.pdf:PDF}
}

@ARTICLE{Danihelka2017,
  author = {Ivo Danihelka and Balaji Lakshminarayanan and Benigno Uria and Daan
	Wierstra and Peter Dayan},
  title = {Comparison of Maximum Likelihood and GAN-based training of Real NVPs},
  journal = {CoRR},
  year = {2017},
  volume = {abs/1705.05263},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/journals/corr/DanihelkaLUWD17},
  eprint = {1705.05263},
  timestamp = {Wed, 07 Jun 2017 14:41:13 +0200},
  url = {http://arxiv.org/abs/1705.05263}
}

@INPROCEEDINGS{Davies2007,
  author = {Davies, M. E. P. and Plumbley, M. D.},
  title = {Context-Dependent Beat Tracking of Musical Audio},
  booktitle = {{IEEE} International Conference on Acoustics, Speech, and Signal
	Processing ({ICASSP})},
  year = {2007},
  volume = {15},
  number = {3},
  pages = {1009-1020},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Context-Dependent Beat Tracking of Musical Audio.pdf:PDF},
  journal = {IEEE International Conference on Acoustics, Speech, and Signal Processing
	(ICASSP)}
}

@INBOOK{Davis:1989,
  chapter = {12},
  pages = {201--203},
  title = {The sound reinforcement handbook},
  publisher = {Hal Leonard Corporation},
  year = {1989},
  editor = {Yamaha Corporation},
  author = {Davis, Gary and Jones, Ralph}
}

@INPROCEEDINGS{DeLannoy2010,
  author = {De Lannoy, Gael and Fran{\c{c}}ois, Damien and Delbeke, Jean and
	Verleysen, Michel},
  title = {Weighted SVMs and feature relevance assessment in supervised heart
	beat classification},
  booktitle = {International Joint Conference on Biomedical Engineering Systems
	and Technologies},
  year = {2010},
  pages = {212--223},
  organization = {Springer},
  note = {balanced classification rate}
}

@ARTICLE{Delong1988,
  author = {DeLong, Elizabeth R and DeLong, David M and Clarke-Pearson, Daniel
	L},
  title = {Comparing the areas under two or more correlated receiver operating
	characteristic curves: a nonparametric approach},
  journal = {Biometrics},
  year = {1988},
  pages = {837--845},
  publisher = {JSTOR}
}

@INPROCEEDINGS{Demetriou2018,
  author = {Demetriou, Andrew and Jansson, Andreas and Kumar, Aparna and M. Bittner,
	Rachel},
  title = {Vocals in Music Matter: The Relevance of Vocals in the Minds of Listeners},
  booktitle = {Proceedings of the International Society for Music Information Retrieval
	Conference ({ISMIR})},
  year = {2018},
  volume = {19},
  pages = {514--520},
  month = {09}
}

@INPROCEEDINGS{Deng2013,
  author = {Deng, Li and Hinton, Geoffrey and Kingsbury, Brian},
  title = {New types of deep neural network learning for speech recognition
	and related applications: An overview},
  booktitle = {Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International
	Conference on},
  year = {2013},
  pages = {8599--8603},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Deng, Hinton, Brian Kingsbury - New types of deep neural network learning for speech recognition and related applications - an overview.pdf:PDF}
}

@INPROCEEDINGS{Deng2010,
  author = {Deng, Li and Seltzer, Michael L and Yu, Dong and Acero, Alex and
	Mohamed, Abdel-Rahman and Hinton, Geoffrey E},
  title = {Binary coding of speech spectrograms using a deep auto-encoder.},
  booktitle = {Interspeech},
  year = {2010},
  pages = {1692--1695},
  organization = {Citeseer},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Deng, Seltzer, Yu, Acero, Mohamed, Hinton - Binary coding of speech spectrograms using a deep auto-encoder.pdf:PDF}
}

@INPROCEEDINGS{Denton2015,
  author = {Denton, Emily L and Chintala, Soumith and Fergus, Rob and others},
  title = {Deep Generative Image Models using a￼ Laplacian Pyramid of Adversarial
	Networks},
  booktitle = {Advances in neural information processing systems},
  year = {2015},
  pages = {1486--1494},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Denton, Chintala, Szlam, Fergus - Deep generative image models using a laplacian pyramid of adversarial networks.pdf:PDF}
}

@INPROCEEDINGS{Derrien2015,
  author = {Derrien, Olivier and Necciarf, Thibaud and Balazs, Peter},
  title = {A quasi-orthogonal, invertible, and perceptually relevant time-frequency
	transform for audio coding},
  booktitle = {Signal Processing Conference (EUSIPCO), 2015 23rd European},
  year = {2015},
  pages = {799--803},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Derrien, Necciari, Balazs - a quasi-orthogonal invertible and perceptually relevant time-frequency transform for audio coding.pdf:PDF}
}

@ARTICLE{Desai2010,
  author = {Desai, Srinivas and Black, Alan W and Yegnanarayana, B and Prahallad,
	Kishore},
  title = {Spectral mapping using artificial neural networks for voice conversion},
  journal = {Audio, Speech, and Language Processing, IEEE Transactions on},
  year = {2010},
  volume = {18},
  pages = {954--964},
  number = {5},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Desai, Black, Yegnananarayana, Prahallad - Spectral Mapping Using Artificial Neural Networks for Voice Conversion.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Desain1994,
  author = {Desain, Peter and Honing, Henkjan},
  title = {Does expressive timing in music performance scale proportionally
	with tempo?},
  journal = {Psychological Research},
  year = {1994},
  volume = {56},
  pages = {285--292},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Does expressive timing music performance scale proportionally with tempo.pdf:PDF},
  publisher = {Springer}
}

@ARTICLE{Devlin2018,
  author = {{Devlin}, J. and {Chang}, M.-W. and {Lee}, K. and {Toutanova}, K.},
  title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language
	Understanding}},
  journal = {ArXiv e-prints},
  year = {2018},
  archiveprefix = {arXiv},
  eprint = {1810.04805},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Devlin, Chang, Lee, Toutanova - BERT - Pre-training of deep bidirectional transformers for language understanding.pdf:PDF},
  keywords = {Computer Science - Computation and Language},
  primaryclass = {cs.CL}
}

@INPROCEEDINGS{Dieleman2011,
  author = {Dieleman, Sander and Brakel, Phil{\'e}mon and Schrauwen, Benjamin},
  title = {Audio-based music classification with a pretrained convolutional
	network},
  booktitle = {12th International Society for Music Information Retrieval Conference
	(ISMIR-2011)},
  year = {2011},
  pages = {669--674},
  organization = {University of Miami},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dieleman, Brakel, Schrauwen - Audio-based music classification with a pretrained convolutional network.pdf:PDF}
}

@MISC{Dieleman2015,
  author = {Dieleman, S. and Schl{\"u}ter, J. and Raffel, C. and Olson, E. and
	Sønderby, S. K. and Nouri, D. and Maturana, D. and Thoma, M. and
	Battenberg, E. and Kelly, J. and De Fauw, J. and Heilman, M. and
	de Almeida, D. M. and McFee, B. and Weideman, H. and Takács, G. and
	de Rivaz, P. and Crall, J. and Sanders, G. and Rasul, K. and Liu,
	C. and French, G. and Degrave, J.},
  title = {Lasagne: First release.},
  howpublished = {\url{http://dx.doi.org/10.5281/zenodo.27878}},
  month = {August},
  year = {2015},
  note = {Accessed: 2018-05-14},
  doi = {10.5281/zenodo.27878},
  url = {http://dx.doi.org/10.5281/zenodo.27878}
}

@ARTICLE{Dieleman2016,
  author = {Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals,
	Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and
	Kavukcuoglu, Koray and others},
  title = {WaveNet: A Generative Model for Raw Audio},
  journal = {arXiv preprint arXiv:1609.03499},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Oord, Dieleman, Ze, Simonyan, Vinyals, Graves, Kalchbrenner, Senior, Kavukcuoglu - Wavenet - A generative model for raw audio.pdf:PDF}
}

@ARTICLE{Dijkstra1959,
  author = {Dijkstra, E. W.},
  title = {A note on two problems in connexion with graphs.},
  journal = {Numerische Mathematik},
  year = {1959},
  volume = {1},
  pages = {269--271},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\dijkstra.pdf:PDF},
  url = {http://gdzdoc.sub.uni-goettingen.de/sub/digbib/loader?did=D196313}
}

@ARTICLE{Dinh2016,
  author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  title = {Density estimation using Real NVP},
  journal = {arXiv preprint arXiv:1605.08803},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dinh, Sohl-Dickstein, Bengio - Density estimation using real NVP.pdf:PDF}
}

@ARTICLE{Dixon2005,
  author = {Dixon, Simon and Goebl, Werner and Widmer, Gerhard},
  title = {The" Air Worm": An Interface for Real-Time Manipulation of Expressive
	Music Performance},
  journal = {Proc. ICMC'05},
  year = {2005},
  pages = {614--617},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dixon, Goebl, Widmer - The air worm, an interface for real-time manipulation of expressive music performance.pdf:PDF}
}

@ARTICLE{Doersch2016,
  author = {Doersch, Carl},
  title = {Tutorial on Variational Autoencoders},
  journal = {arXiv preprint arXiv:1606.05908},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Doersch - Tutorial on variational autoencoders.pdf:PDF}
}

@ARTICLE{Donahue2013,
  author = {Jeff Donahue and Yangqing Jia and Oriol Vinyals and Judy Hoffman
	and Ning Zhang and Eric Tzeng and Trevor Darrell},
  title = {DeCAF: {A} Deep Convolutional Activation Feature for Generic Visual
	Recognition},
  journal = {CoRR},
  year = {2013},
  volume = {abs/1310.1531},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/journals/corr/DonahueJVHZTD13},
  eprint = {1310.1531},
  timestamp = {Mon, 13 Aug 2018 16:46:51 +0200},
  url = {http://arxiv.org/abs/1310.1531}
}

@ARTICLE{Dong2017,
  author = {Dong, Hao-Wen and Hsiao, Wen-Yi and Yang, Li-Chia and Yang, Yi-Hsuan},
  title = {MuseGAN: Symbolic-domain music generation and accompaniment with
	multi-track sequential generative adversarial networks},
  journal = {arXiv preprint arXiv:1709.06298},
  year = {2017}
}

@ARTICLE{Dong2013,
  author = {Dong, Yiran and Peng, Chao-Ying Joanne},
  title = {Principled missing data methods for researchers},
  journal = {SpringerPlus},
  year = {2013},
  volume = {2},
  pages = {1},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dong, Ying, Peng - Principled missing data methods for researchers.pdf:PDF},
  publisher = {Springer International Publishing}
}

@ARTICLE{Dowling1991,
  author = {Dowling, W Jay},
  title = {Tonal strength and melody recognition after long and short delays},
  journal = {Perception \& Psychophysics},
  year = {1991},
  volume = {50},
  pages = {305--313},
  number = {4},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dowling - Tonal strength and melody recognition after long and short delays.pdf:PDF},
  publisher = {Springer}
}

@ARTICLE{Dowling1978,
  author = {Dowling, W Jay},
  title = {Scale and contour: Two components of a theory of memory for melodies.},
  journal = {Psychological review},
  year = {1978},
  volume = {85},
  pages = {341},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dowling - Scale and contour - two components of a theory of memory for melodies.pdf:PDF},
  publisher = {American Psychological Association}
}

@ARTICLE{Dowling1978a,
  author = {Dowling, W Jay},
  title = {Scale and contour: Two components of a theory of memory for melodies.},
  journal = {Psychological review},
  year = {1978},
  volume = {85},
  pages = {341},
  number = {4},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dowling - Scale and contour Two components of a theory of memory for melodies.pdf:PDF},
  publisher = {American Psychological Association}
}

@ARTICLE{Dowling1973,
  author = {Dowling, W Jay},
  title = {The perception of interleaved melodies},
  journal = {Cognitive psychology},
  year = {1973},
  volume = {5},
  pages = {322--337},
  number = {3},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dowling - The perception of interleaved melodies.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Dowling1973a,
  author = {Dowling, W Jay},
  title = {Rhythmic groups and subjective chunks in memory for melodies},
  journal = {Perception \& Psychophysics},
  year = {1973},
  volume = {14},
  pages = {37--40},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dowling - Rhythmic groups and subjective chunks in memory for melodies.pdf:PDF},
  publisher = {Springer}
}

@INPROCEEDINGS{TSMToolbox,
  author = {Driedger, J. and M{\"u}ller, M.},
  title = {TSM Toolbox: MATLAB Implementations of Time-Scale Modification Algorithms},
  booktitle = {Proceedings of the International Conference on Digital Audio Effects
	(DAFx)},
  year = {2014},
  pages = {249--256},
  address = {Erlangen, Germany}
}

@INPROCEEDINGS{Drugman2011,
  author = {Drugman, Thomas and Alwan, Abeer},
  title = {Joint Robust Voicing Detection and Pitch Estimation Based on Residual
	Harmonics.},
  booktitle = {12th Annual Conference of the International Speech Communication
	Association {(INTERSPEECH)}},
  year = {2011},
  pages = {1973--1976},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Drugman, Alwan - Joint Robust Voicing Detection and Pitch Estimation Based On Residual Harmonics.pdf:PDF}
}

@INPROCEEDINGS{Duan2013,
  author = {Duan, Zhiyan and Fang, Haotian and Li, Bo and Sim, Khe Chai and Wang,
	Ye},
  title = {The NUS sung and spoken lyrics corpus: A quantitative comparison
	of singing and speech},
  booktitle = {Signal and Information Processing Association Annual Summit and Conference
	(APSIPA), 2013 Asia-Pacific},
  year = {2013},
  pages = {1--9},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Duan, Fang, Li, Sim, Wang - The NUS Sung and spoken lyrics corpus - a quantitative comparison of singing and speech.pdf:PDF}
}

@ARTICLE{Dumoulin2016,
  author = {Dumoulin, Vincent and Belghazi, Ishmael and Poole, Ben and Lamb,
	Alex and Arjovsky, Martin and Mastropietro, Olivier and Courville,
	Aaron},
  title = {Adversarially Learned Inference},
  journal = {arXiv preprint arXiv:1606.00704},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dumoulin, Belghazi, Poole, Lamb, Arjovsky, Mastropietro, Courville - Adversarially learned inference.pdf:PDF}
}

@ARTICLE{Dumoulin2016a,
  author = {Dumoulin, Vincent and Visin, Francesco},
  title = {A guide to convolution arithmetic for deep learning},
  journal = {arXiv preprint arXiv:1603.07285},
  year = {2016}
}

@INPROCEEDINGS{Durand2014,
  author = {Durand, Simon and David, Barak and Richard, Guilhem},
  title = {Enhancing downbeat detection when facing different music styles},
  booktitle = {Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International
	Conference on},
  year = {2014},
  pages = {3132--3136},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\ENHANCING DOWNBEAT DETECTION WHEN FACING DIFFERENT MUSIC STYLES.pdf:PDF}
}

@BOOK{Durbin1998,
  title = {Biological sequence analysis: probabilistic models of proteins and
	nucleic acids},
  publisher = {Cambridge university press},
  year = {1998},
  author = {Durbin, Richard and Eddy, Sean R and Krogh, Anders and Mitchison,
	Graeme}
}

@ARTICLE{Durrieu2013,
  author = {Durrieu, Jean-Louis and Thiran, Jean-Philippe},
  title = {Source/Filter Factorial Hidden Markov Model, With Application to
	Pitch and Formant Tracking},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  year = {2013},
  volume = {21},
  pages = {2541--2553},
  number = {12},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Durrieu, Thiran - Source-Filter Factorial Hidden Markov Model with application to pitch and formant tracking.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Dzhambazov2015,
  author = {Dzhambazov, Georgi and Serra, Xavier},
  title = {Modeling of phoneme durations for alignment between polyphonic audio
	and lyrics},
  booktitle = {Proceedings of the Sound and Music Computing Conference (SMC)},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Dzhambazov, Serra - Modeling of phoneme durations for alignment between polyphonic audio and lyrics.pdf:PDF}
}

@ARTICLE{Dollinger,
  author = {D{\"o}llinger, Ing M and Kniesburges, S and Kaltenbacher, M and Echternach,
	M},
  title = {Aktuelle Methoden zur Modellierung des Stimmgebungsprozesses},
  journal = {HNO},
  pages = {1--8},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Döllinger, Kniesburges, Kaltenbacher, Echternach - Aktuelle Methoden zur Modellierung des Stimmgebungsprozesses.pdf:PDF},
  publisher = {Springer}
}

@INPROCEEDINGS{Einbond2014,
  author = {Einbond, Aaron and Trapani, Christopher and Agostini, Andrea and
	Ghisi, Daniele and Schwarz, Diemo},
  title = {Fine-tuned control of concatenative synthesis with catart using the
	bach library for {Max}},
  booktitle = {International Computer Music Conference ({ICMC})},
  year = {2014},
  pages = {1037--1042},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Einbond, Trapani, Agostini, Ghisi, Schwarz - Fine-tuned control of concatenative synthesis with cataRT using the bach library for Max.pdf:PDF}
}

@INPROCEEDINGS{Elkan2001,
  author = {Elkan, Charles},
  title = {The foundations of cost-sensitive learning},
  booktitle = {International joint conference on artificial intelligence},
  year = {2001},
  volume = {17},
  number = {1},
  pages = {973--978},
  organization = {Lawrence Erlbaum Associates LTD},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Elkan - The foundations of cost-sensitive learning.pdf:PDF}
}

@OTHER{Ellis2009,
  author = {Ellis, D. P. W.},
  title = {Gammatone-like spectrograms},
  url = {http://www.ee.columbia.edu/ln/rosa/matlab/gammatonegram/},
  urldate = {2016-08-17},
  year = {2009}
}

@INPROCEEDINGS{Erdogan2015,
  author = {Erdogan, Hakan and Hershey, John R and Watanabe, Shinji and Le Roux,
	Jonathan},
  title = {Phase-sensitive and recognition-boosted speech separation using deep
	recurrent neural networks},
  booktitle = {Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International
	Conference on},
  year = {2015},
  pages = {708--712},
  organization = {IEEE},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Erdogan, Hershey, Watanabe, Le Roux - Phase-sensitive and recognition-boosted speech separation using deep recurrent neural networks.pdf:PDF}
}

@ARTICLE{Erhan2010,
  author = {Erhan, Dumitru and Courville, Aaron and Bengio, Yoshua},
  title = {Understanding representations learned in deep architectures},
  journal = {Department d’Informatique et Recherche Operationnelle, University
	of Montreal, QC, Canada, Tech. Rep},
  year = {2010},
  volume = {1355},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Erhan, Courville, Bengio - Understanding representations learned in deep architectures.pdf:PDF}
}

@BOOK{Everest:2009,
  title = {Master Handbook of Acoustics},
  publisher = {McGraw-Hill Education},
  year = {2009},
  author = {Everest, F. A. and Pohlmann, K.},
  //isbn = {9780071603331},
  //url = {https://books.google.de/books?id=6tiJ1cwnwxoC}
}

@ARTICLE{Ewert2014,
  author = {Ewert, Sebastian and Pardo, Bryan and M{\"u}ller, Meinard and Plumbley,
	Mark D.},
  title = {Score-Informed Source Separation for Musical Audio Recordings: An
	Overview},
  journal = {IEEE Signal Processing Magazine},
  year = {2014},
  volume = {31},
  pages = {116--124},
  number = {3},
  codedemo = {http://www.audiolabs-erlangen.de/resources/2013-ACMMM-AudioDecomp/},
  doi = {10.1109/MSP.2013.2296076},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ewert, Pardo, Müller, Plumbley - Score-inforemd source separation for musical audio recordings - an overview.pdf:PDF},
  issn = {1053-5888}
}

@ARTICLE{ewert2016structured,
  author = {Ewert, Sebastian and Sandler, Mark B},
  title = {Structured Dropout for Weak Label and Multi-Instance Learning and
	Its Application to Score-Informed Source Separation},
  journal = {arXiv preprint arXiv:1609.04557},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ewert, Sandler - Structured dropout for weak label and multi-instance learning and its application to score-informed source separation.pdf:PDF}
}

@INPROCEEDINGS{Ezzat2005,
  author = {Ezzat, Tony and Meyers, Ethan and Glass, James R and Poggio, Tomaso},
  title = {Morphing spectral envelopes using audio flow.},
  booktitle = {12th Annual Conference of the International Speech Communication
	Association {(INTERSPEECH)}},
  year = {2005},
  pages = {2545--2548},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Audio Flow.pdf:PDF}
}

@ARTICLE{Fabius2014,
  author = {Fabius, Otto and van Amersfoort, Joost R},
  title = {Variational recurrent auto-encoders},
  journal = {arXiv preprint arXiv:1412.6581},
  year = {2014},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Fabius, Amersfoort - Variational recurrent auto-encoders.pdf:PDF}
}

@ARTICLE{Fan2017,
  author = {Zhe{-}Cheng Fan and Yen{-}Lin Lai and Jyh{-}Shing Roger Jang},
  title = {{SVSGAN:} Singing Voice Separation via Generative Adversarial Network},
  journal = {CoRR},
  year = {2017},
  volume = {abs/1710.11428},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.org/rec/bib/journals/corr/abs-1710-11428},
  eprint = {1710.11428},
  timestamp = {Thu, 02 Nov 2017 14:25:36 +0100},
  url = {http://arxiv.org/abs/1710.11428}
}

@ARTICLE{Farbood2004,
  author = {Farbood, Morwaread M and Pasztor, Egon and Jennings, Kevin},
  title = {Hyperscore: a graphical sketchpad for novice composers},
  journal = {Computer Graphics and Applications, IEEE},
  year = {2004},
  volume = {24},
  pages = {50--54},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Farbood, Pasztor - Hyperscore - A Graphical Sketchpad for Novice Composers.pdf:PDF},
  publisher = {IEEE}
}

@BOOK{Zwicker:1999,
  title = {Psychoacoustics: Facts and models},
  publisher = {Springer Science \& Business Media},
  year = {2007},
  author = {Fastl, H. and Zwicker, E.},
  volume = {22}
}

@ARTICLE{Fernandez2013,
  author = {Fern{\'a}ndez, Jose D and Vico, Francisco},
  title = {AI methods in algorithmic composition: A comprehensive survey},
  journal = {Journal of Artificial Intelligence Research},
  year = {2013},
  pages = {513--582},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Fernandez, Vico - AI Methods in Algorithmic Composition, A Comprehensive Survey.pdf:PDF}
}

@INPROCEEDINGS{Fernandez2007,
  author = {Fern{\'a}ndez, Santiago and Graves, Alex and Schmidhuber, J{\"u}rgen},
  title = {Sequence Labelling in Structured Domains with Hierarchical Recurrent
	Neural Networks.},
  booktitle = {IJCAI},
  year = {2007},
  pages = {774--779},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Fernandez, Graves, Schmidhuber - Sequence labelling in structured domains with hierarchical recurrent neural networks.pdf:PDF}
}

@TECHREPORT{Fevotte2005,
  author = {Fevotte, C. and Gribonval, R. and Vincent, E.},
  title = {BASS_EVAL Toolbox User Guide},
  year = {2005},
  owner = {Daniel},
  subtitle = {IRISA Technical Report 1706},
  timestamp = {2016.10.06}
}

@INPROCEEDINGS{Finn2017,
  author = {Chelsea Finn and Pieter Abbeel and Sergey Levine},
  title = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  year = {2017},
  editor = {Doina Precup and Yee Whye Teh},
  volume = {70},
  series = {Proceedings of Machine Learning Research},
  pages = {1126--1135},
  address = {International Convention Centre, Sydney, Australia},
  month = {06--11 Aug},
  publisher = {PMLR},
  abstract = {We propose an algorithm for meta-learning that is model-agnostic,
	in the sense that it is compatible with any model trained with gradient
	descent and applicable to a variety of different learning problems,
	including classification, regression, and reinforcement learning.
	The goal of meta-learning is to train a model on a variety of learning
	tasks, such that it can solve new learning tasks using only a small
	number of training samples. In our approach, the parameters of the
	model are explicitly trained such that a small number of gradient
	steps with a small amount of training data from a new task will produce
	good generalization performance on that task. In effect, our method
	trains the model to be easy to fine-tune. We demonstrate that this
	approach leads to state-of-the-art performance on two few-shot image
	classification benchmarks, produces good results on few-shot regression,
	and accelerates fine-tuning for policy gradient reinforcement learning
	with neural network policies.},
  pdf = {http://proceedings.mlr.press/v70/finn17a/finn17a.pdf},
  url = {http://proceedings.mlr.press/v70/finn17a.html}
}

@ARTICLE{Fletcher:1937,
  author = {Fletcher, H. and Munson, W. A.},
  title = {Relation between loudness and masking},
  journal = {The Journal of the Acoustical Society of America},
  year = {1937},
  volume = {9},
  pages = {78-78},
  number = {1},
  publisher = {Acoustical Society of America}
}

@INPROCEEDINGS{Foote2000,
  author = {Foote, Jonathan},
  title = {Automatic audio segmentation using a measure of audio novelty},
  booktitle = {Multimedia and Expo, 2000. ICME 2000. 2000 IEEE International Conference
	on},
  year = {2000},
  volume = {1},
  pages = {452--455},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Automatic Audio Segmentation Using a Measure of Audio Novelty.pdf:PDF}
}

@INPROCEEDINGS{Foote:2003,
  author = {Foote, J. T. and Cooper, M. L.},
  title = {Media segmentation using self-similarity decomposition},
  booktitle = {Electronic Imaging 2003},
  year = {2003},
  pages = {167--175},
  publisher = {International Society for Optics and Photonics}
}

@ARTICLE{Fraccaro2016,
  author = {Fraccaro, Marco and S{\o}nderby, S{\o}ren Kaae and Paquet, Ulrich
	and Winther, Ole},
  title = {Sequential Neural Models with Stochastic Layers},
  journal = {arXiv preprint arXiv:1605.07571},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Fraccaro, Sonderby, Paquet, Winther - Sequential neural models with stochastic layers.pdf:PDF}
}

@INPROCEEDINGS{Franzini1990,
  author = {Franzini, Michael and Lee, K-F and Waibel, Alex},
  title = {Connectionist {V}iterbi training: a new hybrid method for continuous
	speech recognition},
  booktitle = {Proceedings of the IEEE International Conference on Acoustics, Speech
	and Signal Processing (ICASSP)},
  year = {1990},
  pages = {425--428}
}

@ARTICLE{Fredman:1987,
  author = {Fredman, M. L. and Tarjan, R. E.},
  title = {Fibonacci heaps and their uses in improved network optimization algorithms},
  journal = {Journal of the ACM (JACM)},
  year = {1987},
  volume = {34},
  pages = {596--615},
  number = {3},
  publisher = {ACM}
}

@ARTICLE{Froeschels1943,
  author = {Froeschels, Emil},
  title = {Hygiene of the voice},
  journal = {Archives of Otolaryngology},
  year = {1943},
  volume = {38},
  pages = {122--130},
  number = {2},
  publisher = {American Medical Association}
}

@ARTICLE{Fujihara2010,
  author = {Fujihara, Hiromasa and Goto, Masataka and Kitahara, Tetsuro and Okuno,
	Hiroshi G},
  title = {A modeling of singing voice robust to accompaniment sounds and its
	application to singer identification and vocal-timbre-similarity-based
	music information retrieval},
  journal = {Audio, Speech, and Language Processing, IEEE Transactions on},
  year = {2010},
  volume = {18},
  pages = {638--648},
  number = {3},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\A Modeling of Singing Voice Robust to Accompaniment Sounds and its application to singer identification and vocal-timbre-similarity-based music information retrieval.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Fujihara2006,
  author = {Hiromasa Fujihara and Masataka Goto and Jun Ogata and Kazunori Komatani
	and Tetsuya Ogata and Hiroshi G. Okuno},
  title = {Automatic Synchronization between Lyrics and Music CD Recordings
	Based on Viterbi Alignment of Segregated Vocal Signals},
  booktitle = {Proceedings of the IEEE International Symposium on Multimedia (ISM)},
  year = {2006},
  pages = {257-264},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Fujihara, Goto, Ogata, Komatani, Ogata, Okuno - Automatic synchronisation between lyrics and music CD recordings based on Viterbi alignment of segregated vocal signals.pdf.pdf:PDF}
}

@ARTICLE{Fujihara2011,
  author = {Fujihara, Hiromasa and Goto, Masataka and Ogata, Jun and Okuno, Hiroshi
	G},
  title = {LyricSynchronizer: Automatic synchronization system between musical
	audio signals and lyrics},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  year = {2011},
  volume = {5},
  pages = {1252--1261},
  number = {6},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Fujihara, Goto, Ogata, Okuno - LyricSynchronizer - Automatic synchronization system between musical audio signals and lyrics.pdf:PDF},
  publisher = {IEEE}
}

@INCOLLECTION{Fevotte2007,
  author = {F{\'e}votte, C{\'e}dric},
  title = {Bayesian audio source separation},
  booktitle = {Blind Speech Separation},
  publisher = {Springer},
  year = {2007},
  pages = {305--335},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Fevotte - Bayesian audio source separation.pdf:PDF}
}

@ARTICLE{Gala,
  author = {Gal, Yarin},
  title = {Rapid Prototyping of Probabilistic Models: Emerging Challenges in
	Variational Inference},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Gal - Rapid Prototyping of probabilistic models - emerging challenges in variational inference.pdf:PDF}
}

@ARTICLE{Gal,
  author = {Gal, Yarin and Ghahramani, Zoubin},
  title = {On Modern Deep Learning and Variational Inference},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Gal, Ghahramani - On Modern Deep Learning and Variational Inference.pdf:PDF}
}

@ARTICLE{Gal2015,
  author = {Gal, Yarin and Ghahramani, Zoubin},
  title = {Dropout as a Bayesian approximation: Representing model uncertainty
	in deep learning},
  journal = {arXiv preprint arXiv:1506.02142},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Gal, Ghahramani - Dropout as a bayesian approximation - representing model uncertainty in deep learning.pdf:PDF}
}

@INPROCEEDINGS{Ganin2015,
  author = {Ganin, Yaroslav and Lempitsky, Victor},
  title = {Unsupervised domain adaptation by backpropagation},
  booktitle = {International Conference on Machine Learning},
  year = {2015},
  pages = {1180--1189}
}

@MISC{LoudnessToolbox,
  author = {Genesis},
  title = {{MATLAB} Loudness Toolbox},
  howpublished = {\url{http://genesis-acoustics.com/en/loudness_online-32.html}},
  year = {2009},
  note = {Accessed: 2018-01-21}
}

@INPROCEEDINGS{Gershman2014,
  author = {Gershman, Samuel J and Goodman, Noah D},
  title = {Amortized inference in probabilistic reasoning},
  booktitle = {Proceedings of the 36th Annual Conference of the Cognitive Science
	Society},
  year = {2014},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Gershman, Goodman - Amortized Inference in Probabilistic Reasoning.pdf:PDF}
}

@ARTICLE{Glasberg:2002,
  author = {Glasberg, B. R. and Moore, Moore, B. C. J.},
  title = {A model of loudness applicable to time-varying sounds},
  journal = {Journal of the Audio Engineering Society},
  year = {2002},
  volume = {50},
  pages = {331--342},
  number = {5},
  publisher = {Audio Engineering Society}
}

@INCOLLECTION{Gomez2012,
  author = {Gomez, Faustino and Koutn{\'\i}k, Jan and Schmidhuber, J{\"u}rgen},
  title = {Compressed network complexity search},
  booktitle = {Parallel Problem Solving from Nature-PPSN XII},
  publisher = {Springer},
  year = {2012},
  pages = {316--326},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Gomez, Koutnik, Schmidhuber - Compressed network complexity search.pdf:PDF}
}

@UNPUBLISHED{Goodfellow2016,
  author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  title = {Deep Learning},
  note = {Book in preparation for MIT Press},
  year = {2016},
  url = {http://www.deeplearningbook.org}
}

@INPROCEEDINGS{Goodfellow2013,
  author = {Goodfellow, Ian and Mirza, Mehdi and Courville, Aaron and Bengio,
	Yoshua},
  title = {Multi-prediction deep Boltzmann machines},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2013},
  pages = {548--556},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Goodfellow, Mirza, Courville, Bengio - Multi-prediction deep boltzmann machines.pdf:PDF}
}

@INPROCEEDINGS{Goodfellow2014,
  author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu,
	Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron
	and Bengio, Yoshua},
  title = {Generative adversarial nets},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2014},
  pages = {2672--2680},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Goodfellow et al - Generative adversarial nets.pdf:PDF}
}

@ARTICLE{Grais2018,
  author = {Grais, Emad M and Ward, Dominic and Plumbley, Mark D},
  title = {Raw Multi-Channel Audio Source Separation using Multi-Resolution
	Convolutional Auto-Encoders},
  journal = {arXiv preprint arXiv:1803.00702},
  year = {2018}
}

@ARTICLE{Grave2016,
  author = {Grave, Edouard and Joulin, Armand and Usunier, Nicolas},
  title = {Improving Neural Language Models with a Continuous Cache},
  journal = {arXiv preprint arXiv:1612.04426},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Grave, Joulin, Usunier - Improving neural language models with a continuous cache.pdf:PDF}
}

@ARTICLE{Graves2012,
  author = {Graves, Alex},
  title = {Sequence transduction with recurrent neural networks},
  journal = {arXiv preprint arXiv:1211.3711},
  year = {2012},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Graves - Sequence Transduction with Recurrent Neural Networks.pdf:PDF}
}

@INPROCEEDINGS{Graves2006,
  author = {Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and
	Schmidhuber, J{\"u}rgen},
  title = {Connectionist temporal classification: labelling unsegmented sequence
	data with recurrent neural networks},
  booktitle = {Proceedings of the ACM International Conference on Machine learning
	({ICML})},
  year = {2006},
  pages = {369--376},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Graves, Fernandez, Gomez, Schmidhuber - Connectionist temporal classification - labelling unsegmented sequence data with recurrent neural networks.pdf:PDF}
}

@INPROCEEDINGS{Graves2014a,
  author = {Graves, Alex and Jaitly, Navdeep},
  title = {Towards End-To-End Speech Recognition with Recurrent Neural Networks.},
  booktitle = {ICML},
  year = {2014},
  volume = {14},
  pages = {1764--1772},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Graves, Jaitly - End-to-end speech recognition with recurrent neural networks.pdf:PDF}
}

@INPROCEEDINGS{Graves2013,
  author = {Graves, Alan and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  title = {Speech recognition with deep recurrent neural networks},
  booktitle = {Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International
	Conference on},
  year = {2013},
  pages = {6645--6649},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Graves, Mohamed, Hinton - SPEECH RECOGNITION WITH DEEP RECURRENT NEURAL NETWORKS.pdf:PDF}
}

@ARTICLE{Graves2014,
  author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  title = {Neural turing machines},
  journal = {arXiv preprint arXiv:1410.5401},
  year = {2014},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Graves, Wayne, Danihelka - Neural Turing Machines.pdf:PDF}
}

@ARTICLE{Greff2016,
  author = {Greff, Klaus and Rasmus, Antti and Berglund, Mathias and Hao, Tele
	Hotloo and Schmidhuber, J{\"u}rgen and Valpola, Harri},
  title = {Tagger: Deep Unsupervised Perceptual Grouping},
  journal = {arXiv preprint arXiv:1606.06724},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Greff, Rasmus, Berglund, Hao, Schmidhuber, Valpola - Tagger - deep unsupervised perceptual grouping.pdf:PDF}
}

@ARTICLE{Gregor2015,
  author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Wierstra, Daan},
  title = {DRAW: A recurrent neural network for image generation},
  journal = {arXiv preprint arXiv:1502.04623},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Gregor, Danihelka, Graves, Rezende, Wierstra - DRAW - A recurrent neural network for image generation.pdf:PDF}
}

@ARTICLE{Griffin1984,
  author = {D. Griffin and Jae Lim},
  title = {Signal estimation from modified short-time Fourier transform},
  journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  year = {1984},
  volume = {32},
  pages = {236-243},
  number = {2},
  doi = {10.1109/TASSP.1984.1164317},
  issn = {0096-3518},
  keywords = {Degradation;Discrete Fourier transforms;Estimation theory;Fourier
	transforms;Hardware;Iterative algorithms;Monitoring;Sampling methods;Signal
	processing;Speech enhancement}
}

@ARTICLE{Grillo2008,
  author = {Elizabeth U. Grillo and Katherine Verdolini and},
  title = {Evidence for Distinguishing Pressed, Normal, Resonant, and Breathy
	Voice Qualities by Laryngeal Resistance and Vocal Efficiency in Vocally
	Trained Subjects },
  journal = {Journal of Voice },
  year = {2008},
  volume = {22},
  pages = {546 - 552},
  number = {5},
  abstract = {Summary The purpose of this study was to determine if pressed, normal,
	resonant, and breathy voice qualities can be distinguished from one
	another by laryngeal resistance (LR; cm H2O/l/s) and/or vocal efficiency
	(VE; dB/cm \{H2O\} × l/s) in vocally, trained subjects. The experimental
	design was a within-subjects repeated measures design. Independent
	variables were pressed, normal, resonant, and breathy voice qualities.
	Dependent variables were \{LR\} and VE. Participants were 13 women
	of age 18–45 years with established vocal expertise. After a brief
	training phase, subjects were asked to produce each of the voice
	qualities on the pitch \{A3\} (220 Hz) at a constant, individually
	identified comfortable dB level (±1 dB), during a repeated consonant-vowel
	utterance of /pi pi pi pi pi/. Results indicated that \{LR\} but
	not \{VE\} reliably distinguished pressed, normal, and breathy voice.
	Neither of the measures, however, distinguished normal from resonant
	voice, which were distinguished perceptually. The results suggest
	that \{LR\} may provide a useful tool for studying the coordinative
	dynamics of pressed, normal, and breathy voice qualities.},
  doi = {http://dx.doi.org/10.1016/j.jvoice.2006.12.008},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Grillo Verdolini - Evidence for Distinguishing Pressed, Normal, Resonant, and Breathy Voice Qualities by Laryngeal Resistance and Vocal Efficiency in Vocally Trained Subjects .pdf:PDF},
  issn = {0892-1997},
  keywords = {Laryngeal resistance},
  url = {http://www.sciencedirect.com/science/article/pii/S0892199706001895}
}

@ARTICLE{Grosche2011,
  author = {Grosche, P. and M{\"u}ller, M.},
  title = {Extracting Predominant Local Pulse Information from Music Recordings},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  year = {2011},
  volume = {19},
  pages = {1688--1701},
  number = {6}
}

@ARTICLE{Gulrajani2017,
  author = {Ishaan Gulrajani and Faruk Ahmed and Mart{\'{\i}}n Arjovsky and Vincent
	Dumoulin and Aaron C. Courville},
  title = {Improved Training of {Wasserstein} {GANs}},
  journal = {CoRR},
  year = {2017},
  volume = {abs/1704.00028},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.org/rec/bib/journals/corr/GulrajaniAADC17},
  eprint = {1704.00028},
  timestamp = {Wed, 07 Jun 2017 14:42:35 +0200},
  url = {http://arxiv.org/abs/1704.00028}
}

@INPROCEEDINGS{Gupta2018,
  author = {Gupta, Chitralekha and Tong, Rong and Li, Haizhou and Wang, Ye},
  title = {Semi-supervised lyrics and solo-singing alignment},
  booktitle = {Proceedings of the International Society for Music Information Retrieval
	Conference ({ISMIR})},
  year = {2018},
  pages = {600--607},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Gupta, Tong, Li, Wang - Semi-supervised lyrics and solo-singing alignment.pdf:PDF}
}

@INPROCEEDINGS{Hadsell2006,
  author = {Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
  title = {Dimensionality reduction by learning an invariant mapping},
  booktitle = {Computer vision and pattern recognition, 2006 IEEE computer society
	conference on},
  year = {2006},
  volume = {2},
  pages = {1735--1742},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hadsell, Chopra, LeCun - DImensionality reduction by learning an invariant mapping.pdf:PDF}
}

@INPROCEEDINGS{Hamel2011,
  author = {Hamel, Philippe and Lemieux, Simon and Bengio, Yoshua and Eck, Douglas},
  title = {Temporal Pooling and Multiscale Learning for Automatic Annotation
	and Ranking of Music Audio.},
  booktitle = {ISMIR},
  year = {2011},
  pages = {729--734},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hamel, Lemieux, Bengio, Eck - Temporal Pooling and multiscale learning for automatic annotation and ranking of music audio.pdf:PDF}
}

@INPROCEEDINGS{Han2015,
  author = {Han, Song and Pool, Jeff and Tran, John and Dally, William},
  title = {Learning both Weights and Connections for Efficient Neural Network},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2015},
  pages = {1135--1143},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Han, Pool - Learning both weights and connections for efficient neural networks.pdf:PDF}
}

@ARTICLE{Hannon2005,
  author = {Hannon, Erin E and Trehub, Sandra E},
  title = {Tuning in to musical rhythms: Infants learn more readily than adults},
  journal = {Proceedings of the National Academy of Sciences of the United States
	of America},
  year = {2005},
  volume = {102},
  pages = {12639--12643},
  number = {35},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hannon, Trehub - Tuning in to musical rhythms, Infants learn more readily than adults.pdf:PDF},
  publisher = {National Acad Sciences}
}

@ARTICLE{Hannon2005a,
  author = {Hannon, Erin E and Trehub, Sandra E},
  title = {Metrical categories in infancy and adulthood},
  journal = {Psychological Science},
  year = {2005},
  volume = {16},
  pages = {48--55},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hannon, Trehub - Metrical Categories in Infancy and Adulthood.pdf:PDF},
  publisher = {SAGE Publications}
}

@INPROCEEDINGS{Hansen2012,
  author = {Hansen, Jens Kofod and Fraunhofer, IDMT},
  title = {Recognition of phonemes in a-cappella recordings using temporal patterns
	and mel frequency cepstral coefficients},
  booktitle = {9th Sound and Music Computing Conference (SMC)},
  year = {2012},
  pages = {494--499},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hansen - Recognition of phonemes in a-cappella recordings using temporal patterns and mel frequency cepstral coefficients.pdf:PDF}
}

@INPROCEEDINGS{Hart1968,
  author = {Hart, P. E. and Nilsson, N. J. and Raphael, B.},
  title = {A Formal Basis for the Heuristic Determination of Minimum Cost Paths},
  booktitle = {{IEEE} Transactions on Systems Science and Cybernetics},
  year = {1968},
  volume = {4},
  number = {2},
  pages = {100-107},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\astar.pdf:PDF},
  issn = {0536-1567},
  journal = {IEEE Transactions on Systems Science and Cybernetics},
  keywords = {Automatic control;Automatic programming;Chemical technology;Costs;Functional
	programming;Gradient methods;Instruction sets;Mathematical programming;Minimax
	techniques;Minimization methods}
}

@ARTICLE{He2015,
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title = {Deep residual learning for image recognition},
  journal = {arXiv preprint arXiv:1512.03385},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Deep Residual Learning for Image Recognition.pdf:PDF}
}

@INPROCEEDINGS{Heittola2011,
  author = {Heittola, Toni and Mesaros, Annamaria and Virtanen, Tuomas and Eronen,
	Antti},
  title = {Sound event detection in multisource environments using source separation},
  booktitle = {Machine Listening in Multisource Environments},
  year = {2011},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Heittola, Mesaros, Virtanen, Eronen - Sound event detection in multisource environments using source separation.pdf:PDF}
}

@INPROCEEDINGS{Hershey2016,
  author = {Hershey, John R and Chen, Zhuo and Le Roux, Jonathan and Watanabe,
	Shinji},
  title = {Deep clustering: Discriminative embeddings for segmentation and separation},
  booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2016},
  pages = {31--35},
  organization = {IEEE},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hershey, Chen, Le Roux, Watanabe - Deep clustering - Discriminative embeddings for segmentation and separation.pdf:PDF}
}

@ARTICLE{Hershey2014,
  author = {Hershey, John R and Roux, Jonathan Le and Weninger, Felix},
  title = {Deep unfolding: Model-based inspiration of novel deep architectures},
  journal = {arXiv preprint arXiv:1409.2574},
  year = {2014},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hershey, Le Roux, Weninger - Deep unfolding - model-based inspiration for novel deep architectures.pdf:PDF}
}

@ARTICLE{Higgins2016,
  author = {Higgins, Irina and Matthey, Loic and Glorot, Xavier and Pal, Arka
	and Uria, Benigno and Blundell, Charles and Mohamed, Shakir and Lerchner,
	Alexander},
  title = {Early Visual Concept Learning with Unsupervised Deep Learning},
  journal = {arXiv preprint arXiv:1606.05579},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Higgins, Matthey, Glorot, Pal, Uria, Blundell, Mohamed, Lerchner - Early Visual Concept Learning with unsupervised deep learning.pdf:PDF}
}

@INPROCEEDINGS{Higuchi2017,
  author = {Higuchi, Takuya and Kinoshita, Keisuke and Delcroix, Marc and Nakatani,
	Tomohiro},
  title = {Adversarial training for data-driven speech enhancement without parallel
	corpus},
  booktitle = {Automatic Speech Recognition and Understanding Workshop (ASRU), 2017
	IEEE},
  year = {2017},
  pages = {40--47},
  organization = {IEEE}
}

@ARTICLE{Hillenbrand1994,
  author = {Hillenbrand, James and Cleveland, Ronald A. and Erickson, Robert
	L.},
  title = {Acoustic correlates of breathy vocal quality},
  journal = {Journal of Speech, Language, and Hearing Research},
  year = {1994},
  volume = {37},
  pages = {769--778},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hillenbrand, Cleveland, Erickson - Acoustic Correlates of Breathy Voice Quality.pdf:PDF},
  publisher = {ASHA}
}

@ARTICLE{Hinton2006,
  author = {Hinton, G. E. and Salakhutdinov, R. R.},
  title = {Reducing the dimensionality of data with neural networks},
  journal = {Science},
  year = {2006},
  volume = {313},
  pages = {504--507},
  number = {5786},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hinton, Salakhutdinov - Reducing the dimensionality of data with neural networks.pdf:PDF},
  publisher = {American Association for the Advancement of Science}
}

@ARTICLE{Hinton2012,
  author = {Hinton, G. E. and Srivastava, N. and Krizhevsky, Alex and Sutskever,
	Ilya and Salakhutdinov, Ruslan R},
  title = {Improving neural networks by preventing co-adaptation of feature
	detectors},
  journal = {arXiv preprint arXiv:1207.0580},
  year = {2012},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hinton, Srivastava, Krizhevsky, Sutskever, Salakhutdinov - Improving neural networks by preventing co-adaptation of feature detectors.pdf:PDF}
}

@ARTICLE{Hjelm2017,
  author = {Hjelm, R Devon and Jacob, Athul Paul and Che, Tong and Cho, Kyunghyun
	and Bengio, Yoshua},
  title = {Boundary-Seeking Generative Adversarial Networks},
  journal = {arXiv preprint arXiv:1702.08431},
  year = {2017},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hjelm, Jacob, Che, Cho, Bengio - Boundary-seeking generative adversarial networks.pdf:PDF}
}

@INPROCEEDINGS{Hockman2008,
  author = {Hockman, Jason A and Bello, Juan P and Davies, Matthew EP and Plumbley,
	Mark D},
  title = {Automated rhythmic transformation of musical audio},
  booktitle = {Proceedings of 11th International Conference on Digital Audio Effects
	(DAFx)},
  year = {2008},
  pages = {177--180},
  organization = {Citeseer},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\AUTOMATED RHYTHMIC TRANSFORMATION OF MUSICAL AUDIO.pdf:PDF}
}

@ARTICLE{Hollien1987,
  author = {Hollien, Harry},
  title = {“Old voices�?: What do we really know about them?},
  journal = {Journal of voice},
  year = {1987},
  volume = {1},
  pages = {2--17},
  number = {1},
  publisher = {Elsevier}
}

@ARTICLE{Honing2008,
  author = {Honing, Henkjan and De Haas, W Bas},
  title = {Swing once more: Relating timing and tempo in expert jazz drumming},
  year = {2008},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Swing Once More - Relating Timing and Tempo in Expert Jazz Drumming.pdf:PDF},
  publisher = {JSTOR}
}

@ARTICLE{Howard2018,
  author = {Jeremy Howard and Sebastian Ruder},
  title = {Fine-tuned Language Models for Text Classification},
  journal = {CoRR},
  year = {2018},
  volume = {abs/1801.06146},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/journals/corr/abs-1801-06146},
  eprint = {1801.06146},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Howard, Ruder - Universal language model fine-tuning for text classification.pdf:PDF},
  timestamp = {Mon, 13 Aug 2018 16:46:54 +0200},
  url = {http://arxiv.org/abs/1801.06146}
}

@OTHER{Hsu2010,
  author = {Chao-Ling Hsu and Jyh-Shing Roger Jang},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hsu, Jang - On the improvement of singing voice separation for monaural recordings using the MIR-1K dataset.pdf:PDF},
  journal = {{IEEE} Transactions on Audio, Speech, and Language Processing},
  month = {February},
  number = {2},
  pages = {310--319},
  title = {On the Improvement of Singing Voice Separation for Monaural Recordings
	Using the {MIR-1K} Dataset},
  volume = {18},
  year = {2010}
}

@ARTICLE{Huang2016,
  author = {De{-}An Huang and Li Fei{-}Fei and Juan Carlos Niebles},
  title = {Connectionist Temporal Modeling for Weakly Supervised Action Labeling},
  journal = {CoRR},
  year = {2016},
  volume = {abs/1607.08584},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/HuangFN16},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Huang, Fei-Fei, Niebles - Connectionist temporal modeling for weakly supervised action labeling.pdf:PDF},
  timestamp = {Tue, 02 Aug 2016 12:59:27 +0200},
  url = {http://arxiv.org/abs/1607.08584}
}

@INPROCEEDINGS{Huang2012,
  author = {Huang, Po-Sen and Chen, Scott Deeann and Smaragdis, Paris and Hasegawa-Johnson,
	Mark},
  title = {Singing-voice separation from monaural recordings using robust principal
	component analysis},
  booktitle = {2012 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2012},
  pages = {57--60},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Huang, Chen, Smaragdis, Hasegawa-Johnson - Singing-voice separation from monaural recordings using robust principal component analysis.pdf:PDF}
}

@INPROCEEDINGS{Huang2014,
  author = {Huang, Po-Sen and Kim, Minje and Hasegawa-Johnson, Mark and Smaragdis,
	Paris},
  title = {Singing-Voice Separation from Monaural Recordings using Deep Recurrent
	Neural Networks.},
  booktitle = {International Society for Music Information Retrieval ({ISMIR})},
  year = {2014},
  pages = {477--482},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Huang, Kim, Hasegawa-Johnson, Smaragdis - Singing-voice separation from monaural recordings using deep recurrent neural networks.pdf:PDF}
}

@INPROCEEDINGS{Humphrey2017,
  author = {Humphrey, Eric and Montecchio, Nicola and Bittner, Rachel and Jansson,
	Andreas and Jehan, Tristan},
  title = {Mining labeled data from web-scale collections for vocal activity
	detection in music},
  booktitle = {Proceedings of the 18th ISMIR Conference},
  year = {2017},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Humphrey, Montecchio, Bittner, Jansson, Jehan - Mining labeled data from web-scale collections for vocal activity detection in music.pdf:PDF}
}

@INPROCEEDINGS{Humphrey2011,
  author = {Humphrey, Eric J and Glennon, Aron P and Bello, Juan Pablo},
  title = {Non-linear semantic embedding for organizing large instrument sample
	libraries},
  booktitle = {Machine Learning and Applications and Workshops (ICMLA), 2011 10th
	International Conference on},
  year = {2011},
  volume = {2},
  pages = {142--147},
  organization = {IEEE},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Humphrey, Glennon, Bello - Non-linear semantic embedding for organizing large instrument sample libraries.pdf:PDF}
}

@ARTICLE{Huszar2015,
  author = {Husz{\'a}r, Ferenc},
  title = {How (not) to Train your Generative Model: Scheduled Sampling, Likelihood,
	Adversary?},
  journal = {arXiv preprint arXiv:1511.05101},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Huszar - How not to train your generative model - scheduled sampling, likelihood, adversary.pdf:PDF}
}

@INPROCEEDINGS{Hwang2016,
  author = {Hwang, Kyuyeon and Sung, Wonyong},
  title = {Sequence to Sequence Training of CTC-RNNs with Partial Windowing},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  year = {2016},
  pages = {2178--2187},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hwang, Sung - Sequence to sequence training of CTC-RNNs with partial windowing.pdf:PDF}
}

@INPROCEEDINGS{Hwang2016a,
  author = {Hwang, Kyuyeon and Sung, Wonyong},
  title = {Character-level incremental speech recognition with recurrent neural
	networks},
  booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2016},
  pages = {5335--5339},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hwang, Sung - Character-level incremental speech recognition with recurrent neural networks.pdf:PDF}
}

@ARTICLE{Hyvarinen1999,
  author = {Hyvarinen, Aapo},
  title = {Fast and robust fixed-point algorithms for independent component
	analysis},
  journal = {IEEE transactions on Neural Networks},
  year = {1999},
  volume = {10},
  pages = {626--634},
  number = {3},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Hyvarinen - Independent component analysis by minimization of mutual information.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Hausler2012,
  author = {H{\"a}usler, Chris and Susemihl, Alex},
  title = {Temporal Autoencoding Restricted Boltzmann Machine},
  journal = {arXiv preprint arXiv:1210.8353},
  year = {2012},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Häusler, Susemihl - Temporal autoencoding restricted boltzmann machine.pdf:PDF}
}

@ARTICLE{Ikemiya2016,
  author = {Ikemiya, Yukara and Itoyama, Katsutoshi and Yoshii, Kazuyoshi},
  title = {Singing Voice Separation and Vocal {F0} Estimation based on Mutual
	Combination of Robust Principal Component Analysis and Subharmonic
	Summation},
  journal = {arXiv preprint arXiv:1604.00192},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ikemiya - Singing voice separation and vocal F0 Estimation based on Mutual Combination of Robust Principal Component Analysis and Subharmonic Summation.pdf:PDF}
}

@INPROCEEDINGS{Ikemiya2015,
  author = {Ikemiya, Yukara and Yoshii, Kazuyoshi and Itoyama, Katsutoshi},
  title = {Singing voice analysis and editing based on mutually dependent {F0
	} estimation and source separation},
  booktitle = {2015 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2015},
  pages = {574--578},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\IOkemiya, Yoshii, Itoyama- Singing voice analysis and editing based on mutually dependent F0 estimation and source separation.pdf:PDF}
}

@INPROCEEDINGS{Ioannidis2014,
  author = {Ioannidis, L{\'e}onidas and Rouas, Jean-Luc and Desainte-Catherine,
	Myriam},
  title = {Caract{\'e}risation et classification automatique des modes phonatoires
	en voix chant{\'e}e},
  booktitle = {XXX{\`e}mes Journ{\'e}es d'{\'e}tudes sur la parole},
  year = {2014},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ioannidis Rouas Desainte-Catherine - Caracterisation et classification automatique des modes phonatoires en voix chantee.pdf:PDF}
}

@ARTICLE{Iverson1995,
  author = {Iverson, Paul},
  title = {Auditory stream segregation by musical timbre: effects of static
	and dynamic acoustic attributes.},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  year = {1995},
  volume = {21},
  pages = {751},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Iverson - Auditory Stream Segregation by musical timbre - effects of static and dynamic acoustic attributes.pdf:PDF},
  publisher = {American Psychological Association}
}

@ARTICLE{jaakkola200110,
  author = {Jaakkola, Tommi S},
  title = {10 Tutorial on Variational Approximation Methods},
  journal = {Advanced mean field methods: theory and practice},
  year = {2001},
  pages = {129},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Jaakkola - Tutorial on variational approximation methods.pdf:PDF},
  publisher = {MIT Press}
}

@ARTICLE{Jaitly2015,
  author = {Jaitly, Navdeep and Sussillo, David and Le, Quoc V and Vinyals, Oriol
	and Sutskever, Ilya and Bengio, Samy},
  title = {A neural transducer},
  journal = {arXiv preprint arXiv:1511.04868},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Jaitly, Sussillo, Le, Vinyals, Sutskver, Bengio - A neural transducer.pdf:PDF}
}

@BOOK{JanerMestres2008,
  title = {Singing-driven interfaces for sound synthesizers},
  publisher = {Universitat Pompeu Fabra},
  year = {2008},
  author = {Janer Mestres, Jordi and others},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Tesi Jianer - SINGING-DRIVEN INTERFACES FOR SOUND SYNTHESIZERS.pdf:PDF}
}

@ARTICLE{Jang2016,
  author = {Jang, Eric and Gu, Shixiang and Poole, Ben},
  title = {Categorical Reparameterization with Gumbel-Softmax},
  journal = {arXiv preprint arXiv:1611.01144},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Jang, Gu, Poole - Categorial reparameterization with gumbel-softmax.pdf:PDF}
}

@INPROCEEDINGS{Jansson2017,
  author = {Jansson, Andreas and Humphrey, Eric J. and Montecchio, Nicola and
	Bittner, Rachel and Kumar, Aparna and Weyde, Tillman},
  title = {Singing Voice Separation with Deep {U-Net} Convolutional Networks},
  booktitle = {Proceedings of the International Society for Music Information Retrieval
	Conference (ISMIR)},
  year = {2017},
  pages = {323--332}
}

@INPROCEEDINGS{Johnson2016,
  author = {Johnson, Matthew and Duvenaud, David K and Wiltschko, Alex and Adams,
	Ryan P and Datta, Sandeep R},
  title = {Composing graphical models with neural networks for structured representations
	and fast inference},
  booktitle = {Advances In Neural Information Processing Systems},
  year = {2016},
  pages = {2946--2954},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Johnson, Duvenaud, Wiltschko, Datta, Adams - Composing graphical models with neural networks for structured representations and fast inference.pdf:PDF}
}

@ARTICLE{Jozefowicz2016,
  author = {Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer,
	Noam and Wu, Yonghui},
  title = {Exploring the limits of language modeling},
  journal = {arXiv preprint arXiv:1602.02410},
  year = {2016},
  file = {:/mnt/daten/Seafile/PhD/Literature/Docea/Papers/Jozefowicz, Vinyals, Schuster, Shazeer, Wu - Exploring the limits of language modeling.pdf:PDF}
}

@ARTICLE{Ju2016,
  author = {Ju, Jianbo Chen Billy Fang Cheng},
  title = {When Variational Auto-encoders meet Generative Adversarial Networks},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Chen, Fang, Ju - When variational auto-encoders meet generative adversarial networks.pdf:PDF}
}

@ARTICLE{Kabal2002,
  author = {Kabal, Peter},
  title = {TSP speech database},
  journal = {McGill University, Database Version},
  year = {2002},
  volume = {1},
  pages = {09--02},
  number = {0},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kabal - TSP speech database.pdf:PDF}
}

@ARTICLE{Kabir2010,
  author = {Kabir, Md Monirul and Islam, Md Monirul and Murase, Kazuyuki},
  title = {A new wrapper feature selection approach using neural network},
  journal = {Neurocomputing},
  year = {2010},
  volume = {73},
  pages = {3273--3283},
  number = {16},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kabir, Islam, Murase - A new wrapper feature selection approach using neuralnetwork.pdf:PDF},
  publisher = {Elsevier}
}

@PHDTHESIS{Kain2001,
  author = {Kain, Alexander Blouke},
  title = {High resolution voice transformation},
  school = {Oregon Health \& Science University},
  year = {2001},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kain - High resolution voice transformation.pdf:PDF}
}

@ARTICLE{Kane2013,
  author = {Kane, John and Gobl, Christer},
  title = {Wavelet maxima dispersion for breathy to tense voice discrimination},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  year = {2013},
  volume = {21},
  pages = {1170--1179},
  number = {6},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kane, Gobl - Wavelet Maxima Dispersion for Breathy to Tense Voice Discrimination.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Kane2011,
  author = {John Kane and Christer Gobl},
  title = {Identifying Regions of Non-Modal Phonation Using Features of the
	Wavelet Transform},
  booktitle = {12th Annual Conference of the International Speech Communication
	Association {(INTERSPEECH)}},
  year = {2011},
  pages = {177--180},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/interspeech/KaneG11},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kane, Gobl - Identifying regions of non-modal phonation using features of the wavelet transform.pdf:PDF},
  timestamp = {Tue, 29 Jan 2013 12:31:18 +0100},
  url = {http://www.isca-speech.org/archive/interspeech_2011/i11_0177.html}
}

@INPROCEEDINGS{Kawai2017,
  author = {Kawai, Dairoku and Yamamoto, Kazumasa and Nakagawa, Seiichi},
  title = {Lyric recognition in monophonic singing using pitch-dependent {DNN}},
  booktitle = {Proceedings of the {IEEE} International Conference on Acoustics,
	Speech and Signal Processing ({ICASSP})},
  year = {2017},
  pages = {326-330},
  doi = {10.1109/ICASSP.2017.7952171},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Kawai, Yamamoto, Nakagawa - Lyric recognition in monophonic singing using pitch-dependent DNN.pdf:PDF},
  issn = {2379-190X}
}

@INPROCEEDINGS{Kendall2018,
  author = {Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
  title = {Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry
	and Semantics},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern
	Recognition ({CVPR})},
  year = {2018},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Kendall, Gal, Cipolla - Multi-task learning using uncertainty to weigh losses for scene geometry and semantics.pdf:PDF}
}

@ARTICLE{Kim2018,
  author = {Jaehun Kim and Juli{\'{a}}n Urbano and Cynthia C. S. Liem and Alan
	Hanjalic},
  title = {One Deep Music Representation to Rule Them All? : {A} comparative
	analysis of different representation learning strategies},
  journal = {CoRR},
  year = {2018},
  volume = {abs/1802.04051},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/journals/corr/abs-1802-04051},
  eprint = {1802.04051},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Kim, Urbano, Liem, Hanjalic - One deep music representation to rule them all.pdf:PDF},
  timestamp = {Mon, 13 Aug 2018 16:47:30 +0200},
  url = {http://arxiv.org/abs/1802.04051}
}

@ARTICLE{Kim2016,
  author = {Kim, Suyoun and Hori, Takaaki and Watanabe, Shinji},
  title = {Joint CTC-Attention based End-to-End Speech Recognition using Multi-task
	Learning},
  journal = {arXiv preprint arXiv:1609.06773},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kim, Hori, Watanabe - Joint CTC-attention based end-to-end speech recognition using multi-task learning.pdf:PDF}
}

@ARTICLE{Kim2016a,
  author = {Kim, Taesup and Bengio, Yoshua},
  title = {Deep directed generative models with energy-based probability estimation},
  journal = {arXiv preprint arXiv:1606.03439},
  year = {2016},
  file = {:/mnt/daten/Seafile/PhD/Literature/Docea/Papers/Kim, Bengio - Deep directed generative models with energy-based probability estimation.pdf:PDF}
}

@INPROCEEDINGS{Kim2001,
  author = {Kim, Youngmoo E},
  title = {Excitation codebook design for coding of the singing voice},
  booktitle = {Applications of Signal Processing to Audio and Acoustics, 2001 IEEE
	Workshop on the},
  year = {2001},
  pages = {155--158},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kim - Excitation codebook design for coding of the singing voice.pdf:PDF}
}

@INPROCEEDINGS{Kingma2014,
  author = {Kingma, Diederik P and Mohamed, Shakir and Rezende, Danilo Jimenez
	and Welling, Max},
  title = {Semi-supervised learning with deep generative models},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2014},
  pages = {3581--3589},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kingma, Rezende, Mohamed, Welling - Semi-supervised learning with deep generative models.pdf:PDF}
}

@ARTICLE{Kingma2016,
  author = {Kingma, Diederik P and Salimans, Tim and Jozefowicz, Rafal and Chen,
	Xi and Sutskever, Ilya and Welling, Max},
  title = {Improved Variational Inference with Inverse Autoregressive Flow},
  year = {2016},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Kingma, Salimans, Jozefowicz, Chen, Sutskever, Welling - Improved variational inference with inverse autoregressive flow.pdf:PDF}
}

@ARTICLE{Kingma2015,
  author = {Kingma, Diederik P and Salimans, Tim and Welling, Max},
  title = {Variational dropout and the local reparameterization trick},
  journal = {arXiv preprint arXiv:1506.02557},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kingma, Salimans, Welling - Variational Dropout and the local reparameterization trick.pdf:PDF}
}

@ARTICLE{Kingma2018,
  author = {{Kingma}, D.~P. and {Dhariwal}, P.},
  title = {{Glow: Generative Flow with Invertible 1x1 Convolutions}},
  journal = {ArXiv e-prints},
  year = {2018},
  archiveprefix = {arXiv},
  eprint = {1807.03039},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Kingma, Dhariwal - Glow - Generative flow with invertible 1x1 convolutions.pdf:PDF},
  keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence,
	Computer Science - Machine Learning},
  primaryclass = {stat.ML}
}

@ARTICLE{Kingma2013,
  author = {{Kingma}, D.~P and {Welling}, M.},
  title = {{Auto-Encoding Variational Bayes}},
  journal = {ArXiv e-prints},
  year = {2013},
  archiveprefix = {arXiv},
  eprint = {1312.6114},
  keywords = {Statistics - Machine Learning, Computer Science - Learning},
  primaryclass = {stat.ML}
}

@INPROCEEDINGS{Kiros2015,
  author = {Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Ruslan R and Zemel,
	Richard and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  title = {Skip-thought vectors},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2015},
  pages = {3276--3284},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kiros Zhu Salakhutdinov Zeel Torralba Urtasun Fidler - Skip-thought vectors.pdf:PDF}
}

@ARTICLE{Klapuri2006,
  author = {Klapuri, Anssi P and Eronen, Antti J and Astola, Jaakko T},
  title = {Analysis of the meter of acoustic musical signals},
  journal = {Audio, Speech, and Language Processing, IEEE Transactions on},
  year = {2006},
  volume = {14},
  pages = {342--355},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Analysis of the meter of acoustic musical signal.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Knuth2005,
  author = {Knuth, Kevin H},
  title = {Informed source separation: A Bayesian tutorial},
  booktitle = {Signal Processing Conference, 2005 13th European},
  year = {2005},
  pages = {1--8},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Knuth - Informed source separation - A bayesian tutorial.pdf:PDF}
}

@ARTICLE{Kob2011,
  author = {Kob, Malte and Henrich, Nathalie and Herzel, Hanspeter and Howard,
	David and Tokuda, Isao and Wolfe, Joe},
  title = {Analysing and understanding the singing voice: Recent progress and
	open questions},
  journal = {Current Bioinformatics},
  year = {2011},
  volume = {6},
  pages = {362--374},
  number = {3},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kob, Henrich, Herzel, Howard, Tokuda, Wolfe - Analysing and understanding the singing voice, recent progress and open questions.pdf:PDF},
  publisher = {Bentham Science Publishers}
}

@ARTICLE{Kong2017,
  author = {Qiuqiang Kong and Yong Xu and Wenwu Wang and Mark D. Plumbley},
  title = {A joint separation-classification model for sound event detection
	of weakly labelled data},
  journal = {CoRR},
  year = {2017},
  volume = {abs/1711.03037},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.org/rec/bib/journals/corr/abs-1711-03037},
  eprint = {1711.03037},
  timestamp = {Fri, 01 Dec 2017 14:22:24 +0100},
  url = {http://arxiv.org/abs/1711.03037}
}

@ARTICLE{Kozinski2017,
  author = {Kozi{\'n}ski, Mateusz and Simon, Lo{\"\i}c and Jurie, Fr{\'e}d{\'e}ric},
  title = {An Adversarial Regularisation for Semi-Supervised Training of Structured
	Output Neural Networks},
  journal = {arXiv preprint arXiv:1702.02382},
  year = {2017}
}

@INPROCEEDINGS{Krizhevsky2012,
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  title = {Imagenet classification with deep convolutional neural networks},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2012},
  pages = {1097--1105},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Krizhevsky, Sutskever, Hinton - ImageNet Classification With Deep Convolutional Neural Networks.pdf:PDF}
}

@ARTICLE{Krom1993,
  author = {de Krom, Guus},
  title = {A cepstrum-based technique for determining a harmonics-to-noise ratio
	in speech signals},
  journal = {Journal of Speech, Language, and Hearing Research},
  year = {1993},
  volume = {36},
  pages = {254--266},
  number = {2},
  publisher = {ASHA}
}

@BOOK{Krumhansl2001,
  title = {Cognitive foundations of musical pitch},
  publisher = {Oxford University Press},
  year = {2001},
  author = {Krumhansl, Carol L},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Krumhansl - Cognitive Foundations of Musical Pitch.pdf:PDF}
}

@ARTICLE{Krumhansl1995,
  author = {Krumhansl, Carol Lynn},
  title = {Effects of musical context on similarity and expectancy},
  journal = {Systematische musikwissenschaft},
  year = {1995},
  volume = {3},
  pages = {211--250},
  number = {2},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Krumhansl - Effects of musical context on similarity and expectancy.pdf:PDF}
}

@ARTICLE{Krumhansl1982,
  author = {Krumhansl, Carol L and Kessler, Edward J},
  title = {Tracing the dynamic changes in perceived tonal organization in a
	spatial representation of musical keys.},
  journal = {Psychological review},
  year = {1982},
  volume = {89},
  pages = {334},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Krumhansl, Kessler - Tracing the dynamic changes in perceived tonal organisation in a spatial representation of musical keys.pdf:PDF},
  publisher = {American Psychological Association}
}

@PHDTHESIS{Kruspe2018,
  author = {Kruspe, Anna M},
  title = {Application of automatic speech recognition technologies to singing},
  school = {{{Technische Universit{\"a}t Ilmenau}}},
  year = {2018},
  url = {https://www.db-thueringen.de/receive/dbt_mods_00035065}
}

@INPROCEEDINGS{Kruspe2016,
  author = {Kruspe, Anna M},
  title = {Retrieval of textual song lyrics from sung inputs},
  booktitle = {Proceedings of {INTERSPEECH}},
  year = {2016},
  pages = {2140-2144}
}

@INPROCEEDINGS{Kruspe2016a,
  author = {Kruspe, Anna M},
  title = {Bootstrapping a system for phoneme recognition and keyword spotting
	in unaccompanied singing},
  booktitle = {Proceedings of the International Conference on Music Information
	Retrieval (ISMIR)},
  year = {2016},
  pages = {358-364},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kruspe - Bootstrapping a system for phoneme recognition and keyword spotting in unaccompanied singing.pdf:PDF}
}

@ARTICLE{Kum,
  author = {Kum, Sangeun and Oh, Changheun and Nam, Juhan},
  title = {MELODY EXTRACTION ON VOCAL SEGMENTS USING MULTI-COLUMN DEEP NEURAL
	NETWORKS},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kum, Oh, Nam - Melody extraction on vocal segments using multi-column deep neural networks.pdf:PDF}
}

@ARTICLE{Kusner2016,
  author = {Kusner, Matt J and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel},
  title = {GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution},
  journal = {arXiv preprint arXiv:1611.04051},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Kusner, Hernandez-Lobato, GANs for sequences of discrete elements with the gumbel-softmax distribution.pdf:PDF}
}

@BOOK{Kuhn1987,
  title = {Formenlehre der Musik},
  publisher = {Deutscher Taschenbuch},
  year = {1987},
  author = {K{\"u}hn, Clemens},
  address = {Kassel}
}

@ARTICLE{Lake2015,
  author = {Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
  title = {Human-level concept learning through probabilistic program induction},
  journal = {Science},
  year = {2015},
  volume = {350},
  pages = {1332--1338},
  number = {6266},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Lake, Salakhutdinov, Tenenbaum - Human-level concept learning through probabilistic program induction.pdf:PDF},
  publisher = {American Association for the Advancement of Science}
}

@MISC{Lamere2012,
  author = {Lamere, Paul},
  title = {The Infinite Jukebox},
  howpublished = {\url{http://infinitejukebox.playlistmachinery.com/}},
  year = {2012},
  note = {Accessed: 2018-05-14},
  owner = {daniel},
  timestamp = {2018.05.14}
}

@ARTICLE{Larsen2015,
  author = {Larsen, Anders Boesen Lindbo and S{\o}nderby, S{\o}ren Kaae and Winther,
	Ole},
  title = {Autoencoding beyond pixels using a learned similarity metric},
  journal = {arXiv preprint arXiv:1512.09300},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Larsen, Sonderby, Larochelle, Winther - Autoencoding beyond pixels using a learned similarity metric.pdf:PDF}
}

@INPROCEEDINGS{Lartillot2013,
  author = {Lartillot, O. and Cereghetti, D. and Eliard, K. and Grandjean, D.},
  title = {A simple, high-yield method for assessing structural novelity},
  booktitle = {Proceedings of the 3rd International Conference on Music \& Emotion
	(ICME3), Jyv{\"a}skyl{\"a}, Finland, 11th-15th June 2013. Geoff Luck
	\& Olivier Brabant (Eds.). ISBN 978-951-39-5250-1},
  year = {2013},
  organization = {University of Jyv{\"a}skyl{\"a}, Department of Music},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Olivier Lartillot - A Simple, High-Yield Method For Assessing Structural Novelty.pdf:PDF}
}

@INPROCEEDINGS{Lartillot2013a,
  author = {Lartillot, Olivier and Cereghetti, Donato and Eliard, Kim and Trost,
	Wiebke J and Rappaz, Marc-Andr{\'e} and Grandjean, Didier},
  title = {Estimating tempo and metrical features by tracking the whole metrical
	hierarchy},
  booktitle = {Proceedings of the 3rd International Conference on Music \& Emotion
	(ICME3), Jyv{\"a}skyl{\"a}, Finland, 11th-15th June 2013. Geoff Luck
	\& Olivier Brabant (Eds.). ISBN 978-951-39-5250-1},
  year = {2013},
  organization = {University of Jyv{\"a}skyl{\"a}, Department of Music},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Olivier Lartillot - Estimating Tempo And Metrical Features By Tracking The Whole Metrical Hierarchy.pdf:PDF}
}

@INCOLLECTION{MATLAB:MIR,
  author = {Lartillot, O. and Toiviainen, P. and Eerola, T.},
  title = {A Matlab Toolbox for Music Information Retrieval},
  booktitle = {Data Analysis, Machine Learning and Applications},
  publisher = {Springer Berlin Heidelberg},
  year = {2008},
  editor = {Preisach, C. and Burkhardt, H. and Schmidt-Thieme, L. and Decker,
	Reinhold},
  series = {Studies in Classification, Data Analysis, and Knowledge Organization},
  pages = {261-268},
  //doi = {10.1007/978-3-540-78246-9_31},
  //isbn = {978-3-540-78239-1},
  //url = {http://dx.doi.org/10.1007/978-3-540-78246-9_31},
  language = {English}
}

@INPROCEEDINGS{LeRoux2008,
  author = {Le Roux, Jonathan and Ono, Nobutaka and Sagayama, Shigeki},
  title = {Explicit consistency constraints for {STFT} spectrograms and their
	application to phase reconstruction},
  booktitle = {{SAPA@ INTERSPEECH}},
  year = {2008},
  pages = {23--28},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Le Roux, Ono, Sagayama - Explicit consistency constraints for STFT spectrograms and their application to phase reconstruction.pdf:PDF}
}

@ARTICLE{Le2016,
  author = {Le, Tuan Anh and Baydin, Atilim Gunes and Wood, Frank},
  title = {Inference Compilation and Universal Probabilistic Programming},
  journal = {arXiv preprint arXiv:1610.09900},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Anh Le, Baydin, Wood - Inference compilation and universal probabilistic programming.pdf:PDF}
}

@INPROCEEDINGS{Lee2008,
  author = {Lee, Kyogu and Cremer, Markus},
  title = {Segmentation-Based Lyrics-Audio Alignment using Dynamic Programming.},
  booktitle = {ISMIR},
  year = {2008},
  pages = {395--400},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Lee, Cremer - Segmentation-based lyrics-audio alignment using dynamic programming.pdf:PDF}
}

@INPROCEEDINGS{Lee2017,
  author = {Lee, Sang Won and Scott, Jeffrey},
  title = {Word level lyrics-audio synchronization using separated vocals},
  booktitle = {Proceedings of the {IEEE} International Conference on Acoustics,
	Speech and Signal Processing ({ICASSP})},
  year = {2017},
  pages = {646--650}
}

@ARTICLE{Leech-Wilkinson2015,
  author = {Leech-Wilkinson, Daniel},
  title = {Cortot's Berceuse},
  journal = {Music Analysis},
  year = {2015},
  volume = {34},
  pages = {335--363},
  number = {3},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Leech-Wilkinson - Cortots Berceuse.pdf:PDF},
  publisher = {Wiley Online Library}
}

@INPROCEEDINGS{Lehner2013,
  author = {Lehner, Bernhard and Sonnleitner, Reinhard and Widmer, Gerhard},
  title = {Towards Light-Weight, Real-Time-Capable Singing Voice Detection.},
  booktitle = {ISMIR},
  year = {2013},
  pages = {53--58},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Towards lightweight, realtime-capable singing voice detection.pdf:PDF}
}

@INPROCEEDINGS{Lehner2015,
  author = {Lehner, Bernhard and Widmer, Gerhard and Bock, Sebastian},
  title = {A low-latency, real-time-capable singing voice detection method with
	LSTM recurrent neural networks},
  booktitle = {Signal Processing Conference (EUSIPCO), 2015 23rd European},
  year = {2015},
  pages = {21--25},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Lehner, Widmer, Böck - A low-latency, real-time-capable singing voice detection method with lstm recurrent neural networks.pdf:PDF}
}

@INPROCEEDINGS{Leke2016,
  author = {Leke, Collins and Marwala, Tshilidzi},
  title = {Missing Data Estimation in High-Dimensional Datasets: A Swarm Intelligence-Deep
	Neural Network Approach},
  booktitle = {International Conference in Swarm Intelligence},
  year = {2016},
  pages = {259--270},
  organization = {Springer},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Leke, Marwala - Missing data estimation in high-dimensional datasets - a swarm intelligence-deep neural network approach.pdf:PDF}
}

@ARTICLE{Lerdahl1988,
  author = {Lerdahl, Fred},
  title = {Tonal pitch space},
  journal = {Music Perception: An Interdisciplinary Journal},
  year = {1988},
  volume = {5},
  pages = {315--349},
  number = {3},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Lerdahl - tonal pitch space.pdf:PDF},
  publisher = {University of California Press Journals}
}

@ARTICLE{Lerdahl1987,
  author = {Lerdahl, Fred and Jackendoff, Ray},
  title = {A generative theory of tonal music},
  year = {1987},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Lerdahl Jackendoff - A Generative Theory of Tonal Music.pdf:PDF}
}

@ARTICLE{Lin2013,
  author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
  title = {Network in network},
  journal = {arXiv preprint arXiv:1312.4400},
  year = {2013},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Lin, Chen, Yan - Network in Network.pdf:PDF}
}

@ARTICLE{Liu2016,
  author = {Liu, Qiang and Wang, Dilin},
  title = {Stein Variational Gradient Descent: A General Purpose Bayesian Inference
	Algorithm},
  journal = {arXiv preprint arXiv:1608.04471},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Liu, Wang - Stein Variational Gradient Descent - A general purpose bayesian inference algorithm.pdf:PDF}
}

@INPROCEEDINGS{Liutkus2015,
  author = {Liutkus, Antoine and Fitzgerald, Derry and Rafii, Zafar},
  title = {Scalable audio separation with light kernel additive modelling},
  booktitle = {2015 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2015},
  pages = {76--80},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Liutkus, Fitzgerald, Rafii - Scalable audio separation with light kernel additive modelling.pdf:PDF}
}

@INPROCEEDINGS{Liutkus2017,
  author = {Liutkus, Antoine and St{\"o}ter, Fabian-Robert and Rafii, Zafar and
	Kitamura, Daichi and Rivet, Bertrand and Ito, Nobutaka and Ono, Nobutaka
	and Fontecave, Julie},
  title = {The 2016 signal separation evaluation campaign},
  booktitle = {Proceedings of the International Conference on Latent Variable Analysis
	and Signal Separation (LVA/ICA)},
  year = {2017},
  pages = {323--332}
}

@ARTICLE{Longuet-Higgins1984,
  author = {Longuet-Higgins, H Christopher and Lee, Christopher S},
  title = {The rhythmic interpretation of monophonic music},
  journal = {Music Perception: An Interdisciplinary Journal},
  year = {1984},
  volume = {1},
  pages = {424--441},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Longuet Higgins - The rhythmic interpretation of monophonic music.pdf:PDF},
  publisher = {University of California Press Journals}
}

@ARTICLE{Lu2009,
  author = {Lu, Tyler Tian},
  title = {Fundamental limitations of semi-supervised learning},
  year = {2009},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Lu - Fundamental limitations of semi-supervised learning.pdf:PDF},
  publisher = {University of Waterloo}
}

@INPROCEEDINGS{Lugger2007,
  author = {Lugger, Marko and Yang, Bin},
  title = {The Relevance of Voice Quality Features in Speaker Independent Emotion
	Recognition},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing
	(ICASSP)},
  year = {2007},
  volume = {4},
  pages = {IV-17-IV-20},
  month = {April},
  abstract = {This paper investigates the classification of different emotional
	states using presodic and voice quality information. We want to exploit
	the usage of different phonation types within the production of emotions.
	Therefore, as features we use prosodic features, voice quality parameters,
	and different combinations of both types. We study how prosodic and
	voice quality features overlap or complement each other in the application
	of emotion recognition. The classification is speaker independent
	and uses a reduced subset of 8 features and a Bayesian classifier.},
  doi = {10.1109/ICASSP.2007.367152},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Lugger, Yang - Relevance of voice quality features in speaker independent emotion recognition.pdf:PDF},
  issn = {1520-6149},
  keywords = {Bayes methods;emotion recognition;speaker recognition;speech processing;Bayesian
	classifier;phonation types;prosodic features;speaker independent;speaker
	independent emotion recognition;voice quality features;Bayesian methods;Emotion
	recognition;Feature extraction;Mel frequency cepstral coefficient;Pattern
	classification;Production;Psychology;Signal processing;Spatial databases;Speech
	analysis;Feature extraction;Pattern classification;Speech analysis}
}

@INPROCEEDINGS{Luo2017,
  author = {Y. Luo and Z. Chen and J. R. Hershey and J. Le Roux and N. Mesgarani},
  title = {Deep clustering and conventional networks for music separation: Stronger
	together},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing
	({ICASSP})},
  year = {2017},
  pages = {61-65},
  doi = {10.1109/ICASSP.2017.7952118},
  keywords = {approximation theory;audio signal processing;estimation theory;music;neural
	nets;pattern clustering;source separation;speaker recognition;audio
	separation;conventional networks;deep clustering;music separation;signal
	approximation;source signal estimation;speaker independent speech
	separation;Instruments;Linear programming;Source separation;Spectrogram;Speech;Time-frequency
	analysis;Training;Deep clustering;Deep learning;Music separation;Singing
	voice separation}
}

@ARTICLE{Luo2017a,
  author = {Yi Luo and Nima Mesgarani},
  title = {TasNet: time-domain audio separation network for real-time, single-channel
	speech separation},
  journal = {CoRR},
  year = {2017},
  volume = {abs/1711.00541},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/journals/corr/abs-1711-00541},
  eprint = {1711.00541},
  timestamp = {Fri, 01 Dec 2017 14:22:24 +0100},
  url = {http://arxiv.org/abs/1711.00541}
}

@ARTICLE{Maaloe2016,
  author = {Maal{\o}e, Lars and S{\o}nderby, Casper Kaae and S{\o}nderby, S{\o}ren
	Kaae and Winther, Ole},
  title = {Auxiliary Deep Generative Models},
  journal = {arXiv preprint arXiv:1602.05473},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Maaloe, Sonderby, Sonderby, Winther - Auxiliary Deep Generative Models.pdf:PDF}
}

@ARTICLE{Maaten2008,
  author = {Maaten, Laurens van der and Hinton, Geoffrey},
  title = {Visualizing data using t-SNE},
  journal = {Journal of Machine Learning Research},
  year = {2008},
  volume = {9},
  pages = {2579--2605},
  number = {Nov},
  file = {:/mnt/daten/Seafile/PhD/Literature/Docea/Papers/Maaten, Hinton - Visualizing data using t-SNE.pdf:PDF}
}

@INPROCEEDINGS{Maclaurin2015,
  author = {Maclaurin, Dougal and Duvenaud, David and Adams, Ryan P},
  title = {Gradient-based hyperparameter optimization through reversible learning},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Maclaurin, Duvenaud, Adams - Gradient-based hyperparameter optimization through reversible learning.pdf:PDF}
}

@ARTICLE{Makhzani2017,
  author = {Makhzani, Alireza and Frey, Brendan},
  title = {PixelGAN Autoencoders},
  journal = {arXiv preprint arXiv:1706.00531},
  year = {2017},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Makhzani, Frey - PixelGAN autoencoders.pdf:PDF}
}

@ARTICLE{Makhzani2015,
  author = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow,
	Ian},
  title = {Adversarial Autoencoders},
  journal = {arXiv preprint arXiv:1511.05644},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Makhzani, Navdeep Jaitly, Goodfellow, Frey - Adversarial Autoencoders.pdf:PDF}
}

@ARTICLE{Marblestone2016,
  author = {Marblestone, Adam and Wayne, Greg and Kording, Konrad},
  title = {Towards an integration of deep learning and neuroscience},
  journal = {arXiv preprint arXiv:1606.03813},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Marblestone, Wayne, Kording - Towards an integration of deep learning and neuroscience.pdf:PDF}
}

@ARTICLE{Marozeau2007,
  author = {Marozeau, Jeremy and de Cheveign{\'e}, Alain},
  title = {The effect of fundamental frequency on the brightness dimension of
	timbre},
  journal = {The Journal of the Acoustical Society of America},
  year = {2007},
  volume = {121},
  pages = {383--387},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Marozeau - The effect of fundamental frequency on the brightness dimension of timbre.pdf:PDF},
  publisher = {Acoustical Society of America}
}

@MISC{MATLAB,
  author = {Mathworks},
  title = {MATLAB programming language},
  howpublished = {\url{http://www.mathworks.com/products/matlab/}},
  note = {Accessed: 2017-02-15}
}

@MISC{MATLAB:Parallel,
  author = {Mathworks},
  title = {MATLAB Parallel Computing Toolbox},
  howpublished = {\url{http://mathworks.com/products/parallel-computing/}},
  note = {Accessed: 2017-02-15}
}

@MISC{MATLAB:Signal,
  author = {Mathworks},
  title = {MATLAB Signal Processing Toolbox},
  howpublished = {\url{http://mathworks.com/products/signal/}},
  note = {Accessed: 2017-02-15}
}

@MISC{UnbiasedCrosscorrelation,
  author = {Mathworks},
  title = {Cross-Correlation function "xcorr" in MATLAB},
  howpublished = {\url{http://de.mathworks.com/help/signal/ref/xcorr.html\#inputarg_scaleopt}},
  note = {Accessed: 2017-02-15}
}

@MISC{SpectralClustering,
  author = {Matthias H., von Luxburg, U.},
  title = {Graph Demo - a Matlab GUI to explore similarity graphs and their
	use in machine learning},
  howpublished = {\url{http://www.ml.uni-saarland.de/code/GraphDemo/GraphDemo.htm}},
  note = {Accessed: 2017-02-15}
}

@INPROCEEDINGS{Mauch2014,
  author = {Mauch, Matthias and Dixon, Simon},
  title = {{pYIN}: A fundamental frequency estimator using probabilistic threshold
	distributions},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing
	({ICASSP})},
  year = {2014},
  pages = {659--663},
  organization = {IEEE}
}

@INPROCEEDINGS{Mauch2010,
  author = {Mauch, Matthias and Fujihara, Hiromasa and Goto, Masataka},
  title = {Lyrics-to-audio alignment and phrase-level segmentation using incomplete
	internet-style chord annotations},
  booktitle = {Proceedings of the Sound Music Computing Conference ({SMC})},
  year = {2010},
  pages = {9--16},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mauch, Fujihara, Goto - Lyrics-to-audio alignment and phrase-level segmentation using incomplete internet-style chord annotations.pdf:PDF}
}

@INPROCEEDINGS{Mauch2011,
  author = {Mauch, Matthias and Fujihara, Hiromasa and Yoshii, Kazuyoshi and
	Goto, Masataka},
  title = {Timbre and Melody Features for the Recognition of Vocal Activity
	and Instrumental Solos in Polyphonic Music.},
  booktitle = {ISMIR},
  year = {2011},
  pages = {233--238},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mauch Fujihara Yoshii Goto - Timbre and melody features for the recognition of vocal activity and instrumental solos in polyphonic music.pdf:PDF}
}

@INPROCEEDINGS{Mayor2009,
  author = {Mayor, Oscar and Bonada, Jordi and Loscos, Alex},
  title = {Performance analysis and scoring of the singing voice},
  booktitle = {Proc. 35th AES Intl. Conf., London, UK},
  year = {2009},
  pages = {1--7},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Performance analysis and scoring of the singing voice.pdf:PDF}
}

@INPROCEEDINGS{Mayor2006,
  author = {Mayor, Oscar and Bonada, Jordi and Loscos, Alex},
  title = {The singing tutor: Expression categorization and segmentation of
	the singing voice},
  booktitle = {Proceedings of the AES 121st Convention},
  year = {2006},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mayor Bonada Loscos - Singing Tutor Expression Categorization and Segmentation of the Singing Voice.pdf:PDF}
}

@ARTICLE{McAdams1995,
  author = {McAdams, Stephen and Winsberg, Suzanne and Donnadieu, Sophie and
	De Soete, Geert and Krimphoff, Jochen},
  title = {Perceptual scaling of synthesized musical timbres: Common dimensions,
	specificities, and latent subject classes},
  journal = {Psychological research},
  year = {1995},
  volume = {58},
  pages = {177--192},
  number = {3},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\McAdams - Perceptual scaling of synthesized musical timbres - Common dimensions, specificities and latent subject classes.pdf:PDF},
  publisher = {Springer}
}

@OTHER{McNamara:2009,
  author = {McNamara, C.},
  title = {General Guidelines for Conducting Research Interviews},
  url = {http://managementhelp.org/businessresearch/interviews.htm},
  urldate = {2016-08-17},
  year = {2009}
}

@INPROCEEDINGS{McVicar2014,
  author = {McVicar, Matt and Ellis, Daniel PW and Goto, Masataka},
  title = {Leveraging repetition for improved automatic lyric transcription
	in popular music},
  booktitle = {Proceedings of the IEEE International Conference on Acoustics, Speech
	and Signal Processing (ICASSP)},
  year = {2014},
  pages = {3117--3121}
}

@INPROCEEDINGS{McVicar2016,
  author = {McVicar, M and Santos-Rodr, R and De Bie, T and others},
  title = {Learning to separate vocals from polyphonic mixtures via ensemble
	methods and structured output prediction},
  booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2016},
  pages = {450--454},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\McVicar, Santos-Rodriguez, De Bie - Learning to separate vocals from polyphonic mixtures via ensemble methods and structured output prediction.pdf:PDF}
}

@ARTICLE{Mehri2016,
  author = {Mehri, Soroush and Kumar, Kundan and Gulrajani, Ishaan and Kumar,
	Rithesh and Jain, Shubham and Sotelo, Jose and Courville, Aaron and
	Bengio, Yoshua},
  title = {SampleRNN: An Unconditional End-to-End Neural Audio Generation Model},
  journal = {arXiv preprint arXiv:1612.07837},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mehri, Kumar, Gulrajani, Kumar, Jain, Sotelo, Courville, Bengio - SampleRNN - An unconditional end-to-end neural audio generation model.pdf:PDF}
}

@INPROCEEDINGS{Mesaros2013,
  author = {Mesaros, Annamaria},
  title = {Singing voice identification and lyrics transcription for music information
	retrieval invited paper},
  booktitle = {Speech Technology and Human-Computer Dialogue (SpeD), 2013 7th Conference
	on},
  year = {2013},
  pages = {1--10},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mesaros - Singing voice identification and lyrics transcription for music information retrieval.pdf:PDF}
}

@ARTICLE{Mesaros2010,
  author = {Mesaros, Annamaria and Virtanen, Tuomas},
  title = {Automatic recognition of lyrics in singing},
  journal = {EURASIP Journal on Audio, Speech, and Music Processing},
  year = {2010},
  volume = {2010},
  pages = {1},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mesaros, Virtanen - Automatic recognition of lyrics in singing.pdf:PDF},
  publisher = {Springer International Publishing}
}

@INPROCEEDINGS{Mesaros2008,
  author = {Mesaros, Annamaria and Virtanen, Tuomas},
  title = {Automatic alignment of music audio and lyrics},
  booktitle = {Proceedings of the International Conference on Digital Audio Effects
	({DAFx})},
  year = {2008},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mesaors, Virtanen - Automatic alignment of music audio and lyrics.pdf:PDF}
}

@ARTICLE{Mescheder2017,
  author = {Mescheder, Lars and Nowozin, Sebastian and Geiger, Andreas},
  title = {Adversarial Variational Bayes: Unifying Variational Autoencoders
	and Generative Adversarial Networks},
  journal = {arXiv preprint arXiv:1701.04722},
  year = {2017},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mescheder, Nowozin, Geiger - Adversarial variational Bayes - Unifying variational autoencoders and generative adversarial networks.pdf:PDF}
}

@ARTICLE{Miconi2016,
  author = {Miconi, Thomas},
  title = {Neural networks with differentiable structure},
  journal = {arXiv preprint arXiv:1606.06216},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Miconi - Neural networks with differentiable structure.pdf:PDF}
}

@ARTICLE{Mikolov2012,
  author = {Mikolov, Tom{\'a}{\v{s}} and Sutskever, Ilya and Deoras, Anoop and
	Le, Hai-Son and Kombrink, Stefan and Cernocky, J},
  title = {Subword language modeling with neural networks},
  journal = {preprint (http://www. fit. vutbr. cz/imikolov/rnnlm/char. pdf)},
  year = {2012},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mikolov, Sutskever, Deoras, Le, Kombrink, Cernocky - Subword language modeling with neural networks.pdf:PDF}
}

@ARTICLE{Millgaard2015,
  author = {Millg{\aa}rd, Moa and Fors, Tobias and Sundberg, Johan},
  title = {Flow Glottogram Characteristics and Perceived Degree of Phonatory
	Pressedness},
  journal = {Journal of Voice. Article in press. DOI: http://dx.doi.org/10.1016/j.jvoice.2015.03.014},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Millgard Fors Sundberg - Flow Glottogram Characteristics and Perceived Degree of Phonatory Pressedness.pdf:PDF},
  publisher = {Elsevier}
}

@ELECTRONIC{MIREX,
  author = {MIREX},
  year = {2018},
  title = {Music Information Retrieval Evaluation eXchange},
  howpublished = {\url{https://www.music-ir.org/mirex/wiki/}},
  url = {https://www.music-ir.org/mirex/wiki},
  owner = {daniel},
  timestamp = {2018.10.23}
}

@ELECTRONIC{MIREX2017Alignment,
  author = {MIREX},
  year = {2017},
  title = {Lyrics alignment results},
  howpublished = {\url{https://www.music-ir.org/mirex/wiki/2017:Automatic_Lyrics-to-Audio_Alignment_Results}},
  url = {https://www.music-ir.org/mirex/wiki/2017:Automatic_Lyrics-to-Audio_Alignment_Results},
  owner = {daniel},
  timestamp = {2018.10.23}
}

@INPROCEEDINGS{Miron2017,
  author = {Miron, Marius and Janer Mestres, Jordi and G{\'o}mez Guti{\'e}rrez,
	Emilia},
  title = {Generating data to train convolutional neural networks for classical
	music source separation},
  booktitle = {Proceedings of the 14th Sound and Music Computing Conference},
  year = {2017},
  organization = {Aalto University}
}

@ARTICLE{Miyato2015,
  author = {Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Nakae,
	Ken and Ishii, Shin},
  title = {Distributional smoothing with virtual adversarial training},
  journal = {stat},
  year = {2015},
  volume = {1050},
  pages = {25},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Miyato, Maeda, Koyama, Nakae, Ishii - Distributional smoothing with virtual adversarial training.pdf:PDF}
}

@ARTICLE{Mnih2016,
  author = {Mnih, Andriy and Rezende, Danilo J},
  title = {Variational inference for Monte Carlo objectives},
  journal = {arXiv preprint arXiv:1602.06725},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mnih, Rezende - Variational Inference for Monte Carlo Objectives.pdf:PDF}
}

@INPROCEEDINGS{Mogren2016,
  author = {Olof Mogren},
  title = {C-RNN-GAN: A continuous recurrent neural network with adversarial
	training},
  booktitle = {Constructive Machine Learning Workshop (CML) at NIPS 2016},
  year = {2016},
  pages = {1}
}

@ARTICLE{Mohamed,
  author = {Mohamed, Shakir},
  title = {Variational Inference for Machine Learning},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mohamed - Variational Inference for Machine Learning.pdf:PDF},
  publisher = {Citeseer}
}

@ARTICLE{Mohamed2016,
  author = {Mohamed, Shakir and Lakshminarayanan, Balaji},
  title = {Learning in Implicit Generative Models},
  journal = {arXiv preprint arXiv:1610.03483},
  year = {2016},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Mohamed, Lakshminarayanan - Learning in implicit generative models.pdf:PDF}
}

@INPROCEEDINGS{Mohamed2005,
  author = {Mohamed, Shakir and Marwala, Tshilidzi},
  title = {Neural network based techniques for estimating missing data in databases},
  booktitle = {16th Annual Symposium of the Patten Recognition Association of South
	Africa, Langebaan},
  year = {2005},
  pages = {27--32},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mohamed, Marwala - Neural network based techniques for estimating missing data in databases.pdf:PDF}
}

@ARTICLE{Moore:1997,
  author = {Moore, B. C. J. and Glasberg, B. R. and Baer, T.},
  title = {A model for the prediction of thresholds, loudness, and partial loudness},
  journal = {Journal of the Audio Engineering Society},
  year = {1997},
  volume = {45},
  pages = {224--240},
  number = {4},
  publisher = {Audio Engineering Society}
}

@INPROCEEDINGS{Mueller2016,
  author = {Mueller, Jonas and Thyagarajan, Aditya},
  title = {Siamese Recurrent Architectures for Learning Sentence Similarity},
  booktitle = {Thirtieth AAAI Conference on Artificial Intelligence},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Mueller, Thyagarajan - Siamese recurren architectures for learning sentence similarity.pdf:PDF}
}

@ARTICLE{Mullensiefen2009,
  author = {M{\"u}llensiefen, Daniel},
  title = {Fantastic: Feature ANalysis Technology Accessing Statistics (In a
	Corpus): Technical report v1},
  year = {2009},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Müllensiefen - FANTASTIC - Feature Analysis. Accessing Statistics.pdf:PDF},
  publisher = {Citeseer}
}

@INPROCEEDINGS{Nair2010,
  author = {Nair, V. and Hinton, G. E.},
  title = {Rectified linear units improve restricted boltzmann machines},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning
	(ICML-10)},
  year = {2010},
  pages = {807--814},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Nair, HInton - Rectified linear units improve restricted boltzmann machines.pdf:PDF}
}

@INPROCEEDINGS{Nakano2011,
  author = {Nakano, Tomoyasu and Goto, Masataka},
  title = {VocaListener2: A singing synthesis system able to mimic a user's
	singing in terms of voice timbre changes as well as pitch and dynamics},
  booktitle = {Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International
	Conference on},
  year = {2011},
  pages = {453--456},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Vocalistener2 A singing synthesis system able to mimic a user's singing in terms of voice timbre changes as well as pitch and dynamics .pdf:PDF}
}

@ARTICLE{Nakano2006,
  author = {Nakano, Tomoyasu and Goto, Masataka and Hiraga, Yuzuru},
  title = {An automatic singing skill evaluation method for unknown melodies
	using pitch interval accuracy and vibrato features},
  journal = {Rn},
  year = {2006},
  volume = {12},
  pages = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Nakano, Goto, Hiraga - An Automatic Singing Skill Evaluation Method for Unknown Melodies Using Pitch Interval Accuracy And Vibrato Features.pdf:PDF}
}

@ARTICLE{Nakano2006a,
  author = {Nakano, Tomoyasu and Goto, Masataka and Hiraga, Yuzuru},
  title = {Subjective evaluation of common singing skills using the rank ordering
	method},
  journal = {Proc. of ICMPC},
  year = {2006},
  pages = {1507--1512},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Nakano Goto Hiraga - Subjective evaluation of common singing skills.pdf:PDF},
  publisher = {Citeseer}
}

@INPROCEEDINGS{Nam2012,
  author = {Nam, Juhan and Herrera, Jorge and Slaney, Malcolm and Smith, Julius
	O},
  title = {Learning Sparse Feature Representations for Music Annotation and
	Retrieval.},
  booktitle = {ISMIR},
  year = {2012},
  pages = {565--570},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Nam, Herrera, Slaney, Smith - Learning sparse feature representations for music annotation and retrieval.pdf:PDF}
}

@INPROCEEDINGS{Nesterov1983,
  author = {Nesterov, Y.},
  title = {A method of solving a convex programming problem with convergence
	rate O (1/k2)},
  booktitle = {Soviet Mathematics Doklady},
  year = {1983},
  volume = {27},
  number = {2},
  pages = {372--376}
}

@INPROCEEDINGS{Nguyen1990,
  author = {Derrick Nguyen and Bernard Widrow},
  title = {Improving the learning speed of 2-layer neural networks by choosing
	initial values of the adaptive weights},
  booktitle = {IJCNN International Joint Conference on Neural Networks},
  year = {1990},
  pages = {21-26 vol.3},
  month = {June},
  abstract = {The authors describe how a two-layer neural network can approximate
	any nonlinear function by forming a union of piecewise linear segments.
	A method is given for picking initial weights for the network to
	decrease training time. The authors have used the method to initialize
	adaptive weights over a large number of different training problems
	and have achieved major improvements in learning speed in every case.
	The improvement is best when a large number of hidden units is used
	with a complicated desired response. The authors have used the method
	to train the truck-backer-upper and were able to decrease the training
	time from about two days to four hours},
  doi = {10.1109/IJCNN.1990.137819},
  keywords = {adaptive systems;learning systems;neural nets;2-layer neural networks;adaptive
	weights;complicated desired response;hidden units;initial weights;learning
	speed;nonlinear function;piecewise linear segments;training problems;training
	time;truck-backer-upper;two-layer neural network}
}

@ARTICLE{Nowozin2016,
  author = {Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  title = {f-GAN: Training Generative Neural Samplers using Variational Divergence
	Minimization},
  journal = {arXiv preprint arXiv:1606.00709},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Nowozin, Cseke - f-GAN - Training Generative Neural Samplers using Variational Divergence Minimization.pdf:PDF}
}

@PHDTHESIS{Nugraha2015,
  author = {Nugraha, Aditya Arie and Liutkus, Antoine and Vincent, Emmanuel},
  title = {Multichannel audio source separation with deep neural networks},
  school = {Inria},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Nugraha, Liutkus, Vincent - Multichannel audio source separation with deep neural networks.pdf:PDF}
}

@ARTICLE{Odena2016,
  author = {Odena, Augustus and Dumoulin, Vincent and Olah, Chris},
  title = {Deconvolution and Checkerboard Artifacts},
  journal = {Distill},
  year = {2016},
  doi = {10.23915/distill.00003},
  url = {http://distill.pub/2016/deconv-checkerboard}
}

@ARTICLE{Olden2002,
  author = {Olden, Julian D and Jackson, Donald A},
  title = {Illuminating the “black box�?: a randomization approach for understanding
	variable contributions in artificial neural networks},
  journal = {Ecological modelling},
  year = {2002},
  volume = {154},
  pages = {135--150},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Olden, Jackson - Illuminating the black box - a randomization approach for understanding variable contributions in artificial neural networks.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Olson:1972,
  author = {Olson, H. F.},
  title = {The measurement of loudness},
  journal = {Audio Magazine},
  year = {1972},
  volume = {56 No. 2},
  pages = {18--22}
}

@INPROCEEDINGS{Ono2015,
  author = {Ono, Nobutaka and Rafii, Zafar and Kitamura, Daichi and Ito, Nobutaka
	and Liutkus, Antoine},
  title = {The 2015 signal separation evaluation campaign},
  booktitle = {International Conference on Latent Variable Analysis and Signal Separation},
  year = {2015},
  pages = {387--395},
  organization = {Springer}
}

@INPROCEEDINGS{Oord2016,
  author = {van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and
	Vinyals, Oriol and Graves, Alex and others},
  title = {Conditional image generation with pixelcnn decoders},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2016},
  pages = {4790--4798},
  file = {:/mnt/daten/Seafile/PhD/Literature/Docea/Papers/Oord, Kalchbrenner, Vinyals, Espeholt, Graves, Kavukcuoglu - Conditional image generation with PixelCNN decoders.pdf:PDF}
}

@ARTICLE{Ozerov2007,
  author = {Ozerov, Alexey and Philippe, Pierrick and Bimbot, Frdric and Gribonval,
	Rmi},
  title = {Adaptation of Bayesian models for single-channel source separation
	and its application to voice/music separation in popular songs},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  year = {2007},
  volume = {15},
  pages = {1564--1578},
  number = {5},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ozerov, Philippe, Bimbot, Gribonval - Adaptation of Bayesian models for single channel source separation and its application to voice-music separation in popular songs.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Ozerov2012,
  author = {Ozerov, Alexey and Vincent, Emmanuel and Bimbot, Fr{\'e}d{\'e}ric},
  title = {A general flexible framework for the handling of prior information
	in audio source separation},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  year = {2012},
  volume = {20},
  pages = {1118--1133},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ozerov, Vincent, Bimbot - A general flexible framework for the handling of prior information in audio source separation.pdf:PDF},
  publisher = {IEEE}
}

@ARTICLE{Paige2016,
  author = {Paige, Brooks and Wood, Frank},
  title = {Inference Networks for Sequential Monte Carlo in Graphical Models},
  journal = {arXiv preprint arXiv:1602.06701},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Paige, Wood - Inference networks for sequential monte carlo in graphical models.pdf:PDF}
}

@ARTICLE{Paine2014,
  author = {Tom Le Paine and Pooya Khorrami and Wei Han and Thomas S. Huang},
  title = {An Analysis of Unsupervised Pre-training in Light of Recent Advances},
  journal = {CoRR},
  year = {2014},
  volume = {abs/1412.6597},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/journals/corr/PaineKHH14},
  eprint = {1412.6597},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Le Paine, Khorrami, Han, Huang - An analysis of unsupervised pre-training in light of recent advances.pdf:PDF},
  timestamp = {Wed, 15 Aug 2018 12:55:38 +0200},
  url = {http://arxiv.org/abs/1412.6597}
}

@ARTICLE{Paliwal2011,
  author = {Paliwal, Mukta and Kumar, Usha A},
  title = {Assessing the contribution of variables in feed forward neural network},
  journal = {Applied Soft Computing},
  year = {2011},
  volume = {11},
  pages = {3690--3696},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Paliwal, Kumar - Assessing the contribution of variables in feed forward neural network.pdf:PDF},
  publisher = {Elsevier}
}

@BOOK{Papadimitriou:1998,
  title = {Combinatorial optimization: algorithms and complexity},
  publisher = {Courier Corporation},
  year = {1998},
  author = {Papadimitriou, C. H. and Steiglitz, K.}
}

@ARTICLE{Papernot2015,
  author = {Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson,
	Matt and Celik, Z Berkay and Swami, Ananthram},
  title = {The Limitations of Deep Learning in Adversarial Settings},
  journal = {arXiv preprint arXiv:1511.07528},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Papernot, McDaniel, Jhay, Fredriksonz, Celik, Swami - The limiations of deep learning in adversarial settings.pdf:PDF}
}

@ARTICLE{Papernot2015a,
  author = {Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh
	and Swami, Ananthram},
  title = {Distillation as a Defense to Adversarial Perturbations against Deep
	Neural Networks},
  journal = {arXiv preprint arXiv:1511.04508},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Papernot, McDaniel, Wux, Jhax, Swamiz - Distillation as a defense against adversarial pertubations in deep neural networks.pdf:PDF}
}

@INPROCEEDINGS{Parker:2004,
  author = {Parker, J. R. and Behm, B.},
  title = {Creating audio textures by example: tiling and stitching},
  booktitle = {{IEEE} International Conference on Acoustics, Speech, and Signal
	Processing ({ICASSP})},
  year = {2004},
  pages = {317--320},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Creating Audio Textures by Example - Tiling and Stitching.pdf:PDF}
}

@ARTICLE{Pascual2017,
  author = {Pascual, Santiago and Bonafonte, Antonio and Serra, Joan},
  title = {SEGAN: Speech enhancement generative adversarial network},
  journal = {arXiv preprint arXiv:1703.09452},
  year = {2017}
}

@INPROCEEDINGS{Patterson1987,
  author = {Patterson, RD and Nimmo-Smith, Ian and Holdsworth, John and Rice,
	Peter},
  title = {An efficient auditory filterbank based on the gammatone function},
  booktitle = {a meeting of the IOC Speech Group on Auditory Modelling at RSRE},
  year = {1987},
  volume = {2},
  number = {7},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Patterson, Nimmo-Smith, Holdsworth, Rice - An efficient auditory filterbank based on the gammatone function.pdf:PDF}
}

@INPROCEEDINGS{Paulus2006,
  author = {Paulus, Jouni and Klapuri, Anssi},
  title = {Music structure analysis by finding repeated parts},
  booktitle = {Proceedings of the 1st ACM workshop on Audio and music computing
	multimedia},
  year = {2006},
  pages = {59--68},
  organization = {ACM},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Paulus, Klapuri - Music Structure Analysis by Finding Repeated Parts.pdf:PDF}
}

@ARTICLE{Peng2005,
  author = {Peng, Hanchuan and Long, Fuhui and Ding, Chris},
  title = {Feature selection based on mutual information criteria of max-dependency,
	max-relevance, and min-redundancy},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2005},
  volume = {27},
  pages = {1226--1238},
  number = {8},
  publisher = {IEEE}
}

@ARTICLE{Pezeshki2015,
  author = {Pezeshki, Mohammad and Fan, Linxi and Brakel, Philemon and Courville,
	Aaron and Bengio, Yoshua},
  title = {Deconstructing the ladder network architecture},
  journal = {arXiv preprint arXiv:1511.06430},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Pezeshki, Fan, Brakel, Courville - Deconstructing the ladder network architecture.pdf:PDF}
}

@ARTICLE{Pons2017,
  author = {Pons, Jordi and Slizovskaia, Olga and Gong, Rong and G{\'o}mez, Emilia
	and Serra, Xavier},
  title = {Timbre Analysis of Music Audio Signals with Convolutional Neural
	Networks},
  journal = {arXiv preprint arXiv:1703.06697},
  year = {2017},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Pons, Slizovskaia, Gong, Gomez, Serra - Timbre analysis of music audio signals with convolutional neural networks.pdf:PDF}
}

@ARTICLE{Povel1985,
  author = {Povel, Dirk-Jan and Essens, Peter},
  title = {Perception of temporal patterns},
  journal = {Music Perception: An Interdisciplinary Journal},
  year = {1985},
  volume = {2},
  pages = {411--440},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Povel, Essens - Perceptionof temporal patterns.pdf:PDF},
  publisher = {University of California Press Journals}
}

@ARTICLE{Proutskova2013,
  author = { Polina Proutskova and Christophe Rhodes and Tim Crawford and Geraint
	Wiggins },
  title = {Breathy, Resonant, Pressed – Automatic Detection of Phonation Mode
	from Audio Recordings of Singing},
  journal = {Journal of New Music Research},
  year = {2013},
  volume = {42},
  pages = {171-186},
  number = {2},
  abstract = { Abstract In this paper we present an experiment on automatic detection
	of phonation modes from recordings of sustained sung vowels. We created
	an open dataset specifically for this experiment, containing recordings
	of nine vowels from multiple languages, sung by a female singer on
	all pitches in her vocal range in phonation modes breathy, neutral,
	flow (resonant) and pressed. The dataset is available under a Creative
	Commons license at http://www.proutskova.de/phonation-modes. First,
	glottal flow waveform is estimated via inverse filtering (IAIF) from
	audio recordings. Then six parameters of the glottal flow waveform
	are calculated. A 4-class Support Vector Machine classifier is constructed
	to separate these features into phonation mode classes. We automated
	the IAIF approach by computing the values of the input arguments
	– lip radiation and formant count – leading to the best-performing
	SVM classifiers (average classification accuracy over 60\%), yielding
	a physical model for the articulation of the vowels. We examine the
	steps needed to generalize and extend the experimental work presented
	in this paper in order to apply this method in ethnomusicological
	investigations. },
  doi = {10.1080/09298215.2013.821496},
  eprint = { http://dx.doi.org/10.1080/09298215.2013.821496 },
  url = { http://dx.doi.org/10.1080/09298215.2013.821496 
}
}

@INPROCEEDINGS{Proutskova2012,
  author = {Polina Proutskova and Christophe Rhodes and Geraint A. Wiggins and
	Tim Crawford},
  title = {Breathy or Resonant - {A} Controlled and Curated Dataset for Phonation
	Mode Detection in Singing},
  booktitle = {Proceedings of the 13th International Society for Music Information
	Retrieval Conference {(ISMIR)}},
  year = {2012},
  pages = {589--594},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.uni-trier.de/rec/bib/conf/ismir/ProutskovaRWC12},
  timestamp = {Thu, 25 Oct 2012 15:38:35 +0200},
  url = {http://ismir2012.ismir.net/event/papers/589-ismir-2012.pdf}
}

@INPROCEEDINGS{Pu2018,
  author = {Pu, Yunchen and Dai, Shuyang and Gan, Zhe and Wang, Weiyao and Wang,
	Guoyin and Zhang, Yizhe and Henao, Ricardo and Duke, Lawrence Carin},
  title = {{J}oint{GAN}: Multi-Domain Joint Distribution Learning with Generative
	Adversarial Nets},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  year = {2018},
  editor = {Dy, Jennifer and Krause, Andreas},
  volume = {80},
  series = {Proceedings of Machine Learning Research},
  pages = {4151--4160},
  address = {Stockholmsmässan, Stockholm Sweden},
  month = {10--15 Jul},
  publisher = {PMLR},
  abstract = {A new generative adversarial network is developed for joint distribution
	matching.Distinct from most existing approaches, that only learn
	conditional distributions, the proposed model aims to learn a joint
	distribution of multiple random variables (domains). This is achieved
	by learning to sample from conditional distributions between the
	domains, while simultaneously learning to sample from the marginals
	of each individual domain.The proposed framework consists of multiple
	generators and a single softmax-based critic, all jointly trained
	via adversarial learning.From a simple noise source, the proposed
	framework allows synthesis of draws from the marginals, conditional
	draws given observations from a subset of random variables, or complete
	draws from the full joint distribution. Most examples considered
	are for joint analysis of two domains, with examples for three domains
	also presented.},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Pu, Dai, Gan, Wang, Wang, Zhang, Henao, Carin - JointGAN - Multi-domain joint distribution learning with generative adversarial nets.pdf:PDF},
  pdf = {http://proceedings.mlr.press/v80/pu18a/pu18a.pdf},
  url = {http://proceedings.mlr.press/v80/pu18a.html}
}

@ARTICLE{Qi2017,
  author = {Qi, Guo-Jun},
  title = {Loss-sensitive generative adversarial networks on lipschitz densities},
  journal = {arXiv preprint arXiv:1701.06264},
  year = {2017},
  file = {:/mnt/daten/Seafile/PhD/Literature/Docea/Papers/Qi, Guo-Jun - Loss-sensitive generative adversarial networks on lipschitz densities.pdf:PDF}
}

@MANUAL{R,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2017},
  url = {http://www.R-project.org/}
}

@ARTICLE{Rabiner1989,
  author = {Rabiner, Lawrence R},
  title = {A tutorial on hidden {M}arkov models and selected applications in
	speech recognition},
  journal = {Proceedings of the IEEE},
  year = {1989},
  volume = {77},
  pages = {257--286},
  number = {2}
}

@ARTICLE{Radford2015,
  author = {Alec Radford and Luke Metz and Soumith Chintala},
  title = {Unsupervised Representation Learning with Deep Convolutional Generative
	Adversarial Networks},
  journal = {CoRR},
  year = {2015},
  volume = {abs/1511.06434},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.org/rec/bib/journals/corr/RadfordMC15},
  eprint = {1511.06434},
  timestamp = {Wed, 07 Jun 2017 14:40:30 +0200},
  url = {http://arxiv.org/abs/1511.06434}
}

@INPROCEEDINGS{Rafii2013,
  author = {Rafii, Zafar and Germain, Fran{\c{c}}ois and Sun, Dennis L and Mysore,
	Gautham J},
  title = {Combining Modeling Of Singing Voice And Background Music For Automatic
	Separation Of Musical Mixtures.},
  booktitle = {ISMIR},
  year = {2013},
  volume = {10},
  pages = {645--680},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Rafii, Germain, Sun-Mysore - Combining Modeling of Singing Voice and Background Music for Automatic Separation of Musical Mixtures.pdf:PDF}
}

@MISC{Rafii2017,
  author = {Rafii, Zafar and Liutkus, Antoine and Fabian-Robert St{\"o}ter and
	Mimilakis, Stylianos Ioannis and Bittner, Rachel},
  title = {The {MUSDB18} corpus for music separation},
  year = {2017},
  doi = {10.5281/zenodo.1117372},
  url = {https://doi.org/10.5281/zenodo.1117372}
}

@ARTICLE{Rafii2013a,
  author = {Rafii, Zafar and Pardo, Bryan},
  title = {Repeating pattern extraction technique (REPET): A simple method for
	music/voice separation},
  journal = {IEEE transactions on audio, speech, and language processing},
  year = {2013},
  volume = {21},
  pages = {73--84},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Rafii, Pardo - Repeating Pattern Extraction Technique (REPET) - A simple method for music-voice separation.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Raiko2014,
  author = {Raiko, Tapani and Li, Yao and Cho, Kyunghyun and Bengio, Yoshua},
  title = {Iterative neural autoregressive distribution estimator nade-k},
  booktitle = {Advances in neural information processing systems},
  year = {2014},
  pages = {325--333},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Raiko, Yao, Cho, Bengio - Iterative Neural Autoregressive Distribution Estimator (NADE-k).pdf:PDF}
}

@INPROCEEDINGS{Ramona2008,
  author = {Mathieu Ramona and Ga{\"e}l Richard and Bertrand David},
  title = {Vocal detection in music with Support Vector Machines},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing
	({ICASSP})},
  year = {2008},
  pages = {1885--1888}
}

@INCOLLECTION{Rao2011,
  author = {Rao, Vishweshwara and Gupta, Chitralekha and Rao, Preeti},
  title = {Context-aware features for singing voice detection in polyphonic
	music},
  booktitle = {Adaptive Multimedia Retrieval. Large-Scale Multimedia Retrieval and
	Evaluation},
  publisher = {Springer},
  year = {2011},
  pages = {43--57},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Context-Aware Features for Singing Voice Detection in Polyphonic Music.pdf:PDF}
}

@INPROCEEDINGS{Rasmus2015,
  author = {Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola,
	Harri and Raiko, Tapani},
  title = {Semi-supervised learning with ladder networks},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2015},
  pages = {3546--3554},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Rasmus, Valpola, Honkala - Semi-Supervised Learning with Ladder Networks.pdf:PDF}
}

@INPROCEEDINGS{Regnier2009,
  author = {Regnier, Lise and Peeters, Geoffroy},
  title = {Singing voice detection in music tracks using direct voice vibrato
	detection},
  booktitle = {Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE
	International Conference on},
  year = {2009},
  pages = {1685--1688},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Singing voice detection in music tracks using direct voice vibrato detection.pdf:PDF}
}

@ARTICLE{Rethage2017,
  author = {Dario Rethage and Jordi Pons and Xavier Serra},
  title = {A Wavenet for Speech Denoising},
  journal = {CoRR},
  year = {2017},
  volume = {abs/1706.07162},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/journals/corr/RethagePS17},
  eprint = {1706.07162},
  timestamp = {Mon, 03 Jul 2017 13:29:02 +0200},
  url = {http://arxiv.org/abs/1706.07162}
}

@ARTICLE{Rezende2014,
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  title = {Stochastic backpropagation and approximate inference in deep generative
	models},
  journal = {arXiv preprint arXiv:1401.4082},
  year = {2014},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Rezende, Mohamed, Wierstra - Stochastic backpropagation and approximate inference in deep generative models.pdf:PDF}
}

@ARTICLE{Ribeiro2016,
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  title = {Model-Agnostic Interpretability of Machine Learning},
  journal = {arXiv preprint arXiv:1606.05386},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ribeiro, Singh, Guestrin - Model-Agnostic Interpretability of Machine Learning.pdf:PDF}
}

@ARTICLE{Richmond2015,
  author = {Richmond, Korin and Ling, Zhenhua and Yamagishi, Junichi},
  title = {The use of articulatory movement data in speech synthesis applications:
	An overview—Application of articulatory movements using machine learning
	algorithms—},
  journal = {Acoustical Science and Technology},
  year = {2015},
  volume = {36},
  pages = {467--477},
  number = {6},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Richmond, Ling, Yamagishi - The use of articulatory movement data in speech synthesis applications - an overview.pdf:PDF},
  publisher = {ACOUSTICAL SOCIETY OF JAPAN}
}

@INPROCEEDINGS{Rifai2011,
  author = {Rifai, Salah and Vincent, Pascal and Muller, Xavier and Glorot, Xavier
	and Bengio, Yoshua},
  title = {Contractive auto-encoders: Explicit invariance during feature extraction},
  booktitle = {Proceedings of the 28th international conference on machine learning
	(ICML-11)},
  year = {2011},
  pages = {833--840},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Rifai, Vincent, Muller, Glorot, Bengio - Contractive auto-encoders - explicit invariance during feature extraction.pdf:PDF}
}

@MISC{Robinson2001,
  author = {Robinson, David},
  title = {Replay Gain - A proposed standard},
  howpublished = {\url{http://wiki.hydrogenaud.io/index.php?title=ReplayGain_1.0_specification}},
  year = {2001},
  note = {Accessed: 2018-05-14},
  url = {http://wiki.hydrogenaud.io/index.php?title=ReplayGain_1.0_specification}
}

@MISC{ROLILtd.2004,
  author = {{ROLI Ltd.}},
  title = {{JUCE} Framework},
  year = {2004},
  note = {Accessed: 2018-01-21},
  owner = {Daniel},
  timestamp = {2016.02.12},
  url = {www.juce.com}
}

@INPROCEEDINGS{Ronneberger2015,
  author = {Ronneberger, O. and Fischer, P. and Brox, T.},
  title = {U-net: Convolutional networks for biomedical image segmentation},
  booktitle = {International Conference on Medical Image Computing and Computer-Assisted
	Intervention},
  year = {2015},
  pages = {234--241},
  organization = {Springer},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ronneberger, Fischer, Brox - U-Net - Convolutional networks for biomedical image segmentation.pdf:PDF}
}

@INPROCEEDINGS{Rouas2016a,
  author = {Rouas, Jean-Luc and Ioannidis, Leonidas},
  title = {Automatic classification of phonation modes in singing voice: towards
	singing style characterisation and application to ethnomusicological
	recordings},
  booktitle = {interspeech},
  year = {2016},
  volume = {2016},
  pages = {150--154},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Rouas, Ioannidis - Automatic classification of phonation modes in singing voice - towards singing style characterisation and application to ethnomusicological recordings.pdf:PDF}
}

@ARTICLE{Rousseeuw:1987,
  author = {Rousseeuw, P. J.},
  title = {Silhouettes: a graphical aid to the interpretation and validation
	of cluster analysis},
  journal = {Journal of computational and applied mathematics},
  year = {1987},
  volume = {20},
  pages = {53--65},
  publisher = {Elsevier}
}

@MISC{DrowAudio,
  author = {Rowland, D.},
  title = {{dRowAudio} - A {JUCE} module for high level audio application development},
  howpublished = {\url{http://drowaudio.co.uk/docs/}},
  year = {2010},
  note = {Accessed: 2018-01-21}
}

@INPROCEEDINGS{Rubinstein2010,
  author = {Rubinstein, Michael and Gutierrez, Diego and Sorkine, Olga and Shamir,
	Ariel},
  title = {A comparative study of image retargeting},
  booktitle = {ACM transactions on graphics (TOG)},
  year = {2010},
  volume = {29},
  number = {6},
  pages = {160},
  organization = {ACM},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Comparative Study of Image Retargeting.pdf:PDF}
}

@ARTICLE{Saatchi2017,
  author = {Saatchi, Yunus and Wilson, Andrew Gordon},
  title = {Bayesian GAN},
  journal = {arXiv preprint arXiv:1705.09558},
  year = {2017},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Saatchi, Wilson - Bayesian GAN.pdf:PDF}
}

@INPROCEEDINGS{Sak2015,
  author = {Sak, Ha{\c{s}}im and Senior, Andrew and Rao, Kanishka and Irsoy,
	Ozan and Graves, Alex and Beaufays, Fran{\c{c}}oise and Schalkwyk,
	Johan},
  title = {Learning acoustic frame labeling for speech recognition with recurrent
	neural networks},
  booktitle = {Proceedings of the IEEE International Conference on Acoustics, Speech
	and Signal Processing (ICASSP)},
  year = {2015},
  pages = {4280-4284},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Sak, Senior, Rao, Irsoy, Graves, Beaufays, Schalkwyk - Learning acoustic frame labeling for speech recognition with recurrent neural networks.pdf:PDF}
}

@ARTICLE{Salimans2016,
  author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung,
	Vicki and Radford, Alec and Chen, Xi},
  title = {Improved Techniques for Training GANs},
  journal = {arXiv preprint arXiv:1606.03498},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Salimans, Goodfelow, Zaremba, Cheung, Radford, Chen - Improved Techniques for Training GANs.pdf:PDF}
}

@ARTICLE{Salimans2017,
  author = {Salimans, Tim and Karpathy, Andrej and Chen, Xi and Kingma, Diederik
	P},
  title = {PixelCNN++: Improving the PixelCNN with discretized logistic mixture
	likelihood and other modifications},
  journal = {arXiv preprint arXiv:1701.05517},
  year = {2017},
  file = {:/mnt/daten/Seafile/PhD/Literature/Docea/Papers/Salimans, Karpathy, Chen, Kingma - PixelCNN++ - Improving the PixelCNN with discretized logistic mixture likelihood and other modifications.pdf:PDF}
}

@INPROCEEDINGS{Salimans2015,
  author = {Salimans, Tim and Kingma, Diederik P and Welling, Max and others},
  title = {Markov chain Monte Carlo and variational inference: Bridging the
	gap},
  booktitle = {International Conference on Machine Learning},
  year = {2015},
  pages = {1218--1226},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Markov Chain Monte Carlo and Variational Inference - Bridging the gap.pdf:PDF}
}

@ARTICLE{Santoro2016,
  author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra,
	Daan and Lillicrap, Timothy},
  title = {One-shot Learning with Memory-Augmented Neural Networks},
  journal = {arXiv preprint arXiv:1605.06065},
  year = {2016},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Santoro, Bartunov, Botvinick, Wierstra, Lillicrap - One-shot Learning with Memory-Augmented Neural Networks.pdf:PDF}
}

@INPROCEEDINGS{Sato2016,
  author = {Sato, Haruki and Hirai, Tatsunori and Nakano, Tomoyasu and Goto,
	Masataka and Morishima, Shigeo},
  title = {A soundtrack generation system to synchronize the climax of a video
	clip with music},
  booktitle = {{IEEE} International Conference on Multimedia and Expo ({ICME})},
  year = {2016},
  pages = {1--6},
  organization = {IEEE},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Sato, Hirai, Nakano, Goto, Morishima - A soundtrack generation system to synchronise the climax of a video clip with music.pdf:PDF}
}

@ARTICLE{Scellier2016,
  author = {Scellier, Benjamin and Bengio, Yoshua},
  title = {Towards a biologically plausible backprop},
  journal = {arXiv preprint arXiv:1602.05179},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Scellier, Bengio - Towards a biologically plausible backprop.pdf:PDF}
}

@INPROCEEDINGS{Schluter2016,
  author = {Schl{\"u}ter, J.},
  title = {Learning to pinpoint singing voice from weakly labeled examples},
  booktitle = {Proceedings of the International Society for Music Information Retrieval
	Conference (ISMIR)},
  year = {2016},
  pages = {44--50},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Schlüter - Learning to pinpoint singing voice from weakly labeled examples.pdf:PDF}
}

@MISC{Schluter2015a,
  author = {Schl{\"u}ter, J.},
  title = {Saliency Maps and Guided Backpropagation},
  howpublished = {\url{https://github.com/Lasagne/Recipes/blob/master/examples/Saliency%20Maps%20and%20Guided%20Backpropagation.ipynb}},
  year = {2015},
  note = {Accessed: 2018-05-14},
  owner = {Daniel},
  url = {https://github.com/Lasagne/Recipes/blob/master/examples/Saliency%20Maps%20and%20Guided%20Backpropagation.ipynb},
  urldate = {2016-08-29}
}

@INPROCEEDINGS{Schlueter2014,
  author = {J. Schl{\"u}ter and S. B{\"o}ck},
  title = {Improved musical onset detection with Convolutional Neural Networks},
  booktitle = {2014 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2014},
  pages = {6979-6983},
  month = {May},
  doi = {10.1109/ICASSP.2014.6854953},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Schlüter, Böck - Improved musical onset detection with Convolutional Neural Networks.pdf:PDF},
  issn = {1520-6149},
  keywords = {audio signal processing;information retrieval;learning (artificial
	intelligence);music;neural nets;CNN;computer vision problem;convolutional
	neural networks;hand-designed methods;harmonic onsets;improved musical
	onset detection;knowledge engineering;machine learning;music analysis;percussive
	onsets;polyphonic music signals;signal processing tasks;spectrograms;Computer
	architecture;Convolution;Detectors;Music information retrieval;Neural
	networks;Spectrogram;Training;Multi-layer neural network;Music information
	retrieval}
}

@INPROCEEDINGS{Schluter2015,
  author = {Schl{\"u}ter, J. and Grill, T.},
  title = {Exploring data augmentation for improved singing voice detection
	with neural networks},
  booktitle = {International Society for Music Information Retrieval Conference
	(ISMIR)},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Schlüter, Grill - Exploring data augmentation for improved singing voice detection with neural networks.pdf:PDF}
}

@ARTICLE{Schmidhuber2012,
  author = {Schmidhuber, Juergen},
  title = {Self-delimiting neural networks},
  journal = {arXiv preprint arXiv:1210.0118},
  year = {2012},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Schmidhuber - Self-Delimiting Neural Networks.pdf:PDF}
}

@ARTICLE{Schmidhuber2015,
  author = {Schmidhuber, J{\"u}rgen},
  title = {Deep learning in neural networks: An overview},
  journal = {Neural Networks},
  year = {2015},
  volume = {61},
  pages = {85--117},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Schmidthuber - Deep Learning - An Overview.pdf:PDF},
  publisher = {Elsevier}
}

@ARTICLE{Schmidhuber1997,
  author = {Schmidhuber, J{\"u}rgen},
  title = {Discovering neural nets with low Kolmogorov complexity and high generalization
	capability},
  journal = {Neural Networks},
  year = {1997},
  volume = {10},
  pages = {857--873},
  number = {5},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Schmidhuber - Discovering neural nets with low kolmogorov complexity and high generalization capability.pdf:PDF},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Schulman2015,
  author = {Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel,
	Pieter},
  title = {Gradient estimation using stochastic computation graphs},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2015},
  pages = {3528--3536},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Schulman, Heess, Weber, Abbeel - Gradient estimation using stochastic computation graphs.pdf:PDF}
}

@INPROCEEDINGS{Schwarz2008,
  author = {Schwarz, Diemo and Cahen, Roland and Britton, Sam},
  title = {Principles and applications of interactive corpus-based concatenative
	synthesis},
  booktitle = {Journ{\'e}es d'Informatique Musicale ({JIM})},
  year = {2008},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Schwarz, Cahen, Britton - Principles and applications of interactive corpus-based concatenative synthesis.pdf:PDF}
}

@INPROCEEDINGS{Schorkhuber2014,
  author = {Sch{\"o}rkhuber, Christian and Klapuri, Anssi and Holighaus, Nicki
	and D{\"o}rfler, Monika},
  title = {A Matlab toolbox for efficient perfect reconstruction time-frequency
	transforms with log-frequency resolution},
  booktitle = {Audio Engineering Society Conference: 53rd International Conference:
	Semantic Audio},
  year = {2014},
  organization = {Audio Engineering Society},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Schörkhuber, Klapuri, Holighaus, Dörfler - A Matlab Toolbox for Efficient Perfect Reconstruction Time-Frequency Transforms with Log-Frequency Resolution.pdf:PDF}
}

@MISC{Sengpiel,
  author = {Sengpiel, E.},
  title = {The human perception of loudness},
  howpublished = {\url{http://www.sengpielaudio.com/calculator-loudness.htm}},
  year = {2018},
  note = {Accessed: 2018-01-21}
}

@ARTICLE{Shepard1982,
  author = {Shepard, Roger N},
  title = {Structural representations of musical pitch},
  journal = {The psychology of music},
  year = {1982},
  pages = {343--390},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Shepard - Structural representations of musical pitch.pdf:PDF}
}

@ARTICLE{Shi2000,
  author = {Shi, Jianbo and Malik, Jitendra},
  title = {Normalized cuts and image segmentation},
  journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  year = {2000},
  volume = {22},
  pages = {888--905},
  number = {8},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Normalized cutsand image segmentation.pdf:PDF},
  publisher = {IEEE}
}

@BOOK{Siegel:1988,
  title = {Nonparametric statistics for the behavioral sciences},
  publisher = {McGraw--Hill, Inc.},
  year = {1988},
  author = {Siegel, S. and Castellan, N.J.},
  edition = {Second edition}
}

@ARTICLE{Sigtia2015a,
  author = {Sigtia, Siddharth and Benetos, Emmanouil and Dixon, Simon},
  title = {An End-to-End Neural Network for Polyphonic Music Transcription},
  journal = {arXiv preprint arXiv:1508.01774},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Sigtia, Benetos, Dixon - An end-to-end neural network for polyphonic music transcription.pdf:PDF}
}

@INPROCEEDINGS{Sigtia2015,
  author = {Sigtia, Siddharth and Boulanger-Lewandowski, Nicolas and Dixon, Simon},
  title = {Audio Chord Recognition with a Hybrid Recurrent Neural Network},
  booktitle = {Proceedings of the 16th International Society for Music Information
	Retrieval Conference (ISMIR 2015). Malaga, Spain},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Audio Chord Recognition with a Hybrid Recurrent Neural Network.pdf:PDF}
}

@INPROCEEDINGS{Sigtia2014,
  author = {Sigtia, Siddharth and Dixon, Sam},
  title = {Improved music feature learning with deep neural networks},
  booktitle = {Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International
	Conference on},
  year = {2014},
  pages = {6959--6963},
  organization = {IEEE},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Improved music feature learning with deep neural networks.pdf:PDF}
}

@ARTICLE{Simonyan2013,
  author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  title = {Deep inside convolutional networks: Visualising image classification
	models and saliency maps},
  journal = {arXiv preprint arXiv:1312.6034},
  year = {2013},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Simonyan, Vedaldi, Zisserman - Deep inside convolutional networks - visualising image classification models and saliency maps.pdf:PDF}
}

@INPROCEEDINGS{Simpson2015,
  author = {Simpson, Andrew JR and Roma, Gerard and Plumbley, Mark D},
  title = {Deep karaoke: Extracting vocals from musical mixtures using a convolutional
	deep neural network},
  booktitle = {International Conference on Latent Variable Analysis and Signal Separation},
  year = {2015},
  pages = {429--436},
  organization = {Springer}
}

@INPROCEEDINGS{Skovenborg2004,
  author = {Skovenborg, Esben and Nielsen, S{\o}ren H},
  title = {Evaluation of different loudness models with music and speech material},
  booktitle = {Proc. of the AES 117th Convention, San Francisco},
  year = {2004},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Loudness Evaluation.pdf:PDF}
}

@PHDTHESIS{Smith2013,
  author = {Smith, Jeffrey C.},
  title = {Correlation Analyses of Encoded Music Performance},
  year = {2013},
  address = {Stanford, CA, USA},
  advisor = {Berger, Jonathan and Aquilanti, Giancarlo and Chafe, Chris},
  publisher = {Stanford University},
  source = {http://purl.stanford.edu/rg667zs0240}
}

@ARTICLE{Soltau2016,
  author = {Soltau, Hagen and Liao, Hank and Sak, Hasim},
  title = {Neural Speech Recognizer: Acoustic-to-Word LSTM Model for Large Vocabulary
	Speech Recognition},
  journal = {arXiv preprint arXiv:1610.09975},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Soltau, Liao, Sak - Neural speech recognizer - acoustic-to-word LSTM model for large vocabulary speech recognition.pdf:PDF}
}

@ARTICLE{Speed2012,
  author = {Speed, Matthew DA},
  title = {Voice synthesis using the three-dimensional digital waveguide mesh},
  year = {2012},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Speed - Voice synthesis using the three-dimensional digital waveguide mesh.pdf:PDF},
  publisher = {University of York}
}

@ARTICLE{Springenberg2015,
  author = {Springenberg, Jost Tobias},
  title = {Unsupervised and semi-supervised learning with categorical generative
	adversarial networks},
  journal = {arXiv preprint arXiv:1511.06390},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Springenberg - Unsupervised and semi-supervised learning with categorical generative adversarial networks.pdf:PDF}
}

@INPROCEEDINGS{Springenberg2014,
  author = {J. T. Springenberg and A. Dosovitskiy and T. Brox and M. Riedmiller},
  title = {Striving for Simplicity: The All Convolutional Net},
  booktitle = {arXiv:1412.6806, also appeared at ICLR 2015 Workshop Track},
  year = {2015},
  conference = {ICLR 2015 Workshop Track},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Springenberg, Dosovitskiy, Brox, Riedmiller - Striving for simplicity - the all convolutional net.pdf:PDF}
}

@ELECTRONIC{Steinberg2016,
  author = {{Steinberg}},
  year = {2016},
  title = {VST Technology},
  url = {https://www.steinberg.net/en/products/vst.html},
  owner = {Daniel},
  timestamp = {2016.02.12}
}

@MASTERSTHESIS{Stoller2015,
  author = {Daniel Stoller},
  title = {{Constrained-based rearrangement of music}},
  school = {Technical University Dortmund},
  year = {2015},
  address = {Germany},
  institution = {Technical University Dortmund},
  owner = {Daniel},
  timestamp = {2016.08.17}
}

@INPROCEEDINGS{Stoller2018d,
  author = {D. Stoller and V. Akkermans and S. Dixon},
  title = {Detection of Cut-Points for Automatic Music Rearrangement},
  booktitle = {2018 {IEEE} 28th International Workshop on Machine Learning for Signal
	Processing ({MLSP})},
  year = {2018},
  pages = {1--6},
  abstract = {Existing music recordings are often rearranged, for example to fit
	their duration and structure to video content. Often an expert is
	needed to find suitable cut points allowing for imperceptible transitions
	between different sections. In previous work, the search for these
	cuts is restricted to the beginnings of beats or measures and only
	timbre and loudness are taken into account, while melodic expectations
	and instrument continuity are neglected. We instead aim to learn
	these features by training neural networks on a dataset of over 300
	popular Western songs to classify which note onsets are suitable
	entry or exit points for a cut. We investigate existing and novel
	architectures and different feature representations, and find that
	best performance is achieved using neural networks with two-dimensional
	convolutions applied to spectrogram input covering several seconds
	of audio with a high temporal resolution of 23 or 46 ms. Finally,
	we analyse our best model using saliency maps and find it attends
	to rhythmical structures and the presence of sounds at the onset
	position, suggesting instrument activity to be important for predicting
	cut quality.},
  doi = {10.1109/MLSP.2018.8516706},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Stoller, Akkermans, Dixon - Detection of cut-points for automatic music rearrangement.pdf:PDF},
  issn = {1551-2541},
  keywords = {Music;Feature extraction;Training;Neural networks;Adaptation models;Instruments;Task
	analysis},
  url = {https://doi.org/10.1109/MLSP.2018.8516706}
}

@INPROCEEDINGS{Stoller2016,
  author = {Stoller, Daniel and Dixon, Simon},
  title = {Analysis and classification of phonation modes in singing},
  booktitle = {Proceedings of the International Society for Music Information Retrieval
	Conference ({ISMIR})},
  year = {2016},
  volume = {17},
  pages = {80--86},
  abstract = {Phonation mode is an expressive aspect of the singing voice and can
	be described using the four categories neutral, breathy, pressed
	and flow. Previous attempts at automatically classifying the phonation
	mode on a dataset containing vowels sung by a female professional
	have been lacking in accuracy or have not sufficiently investigated
	the characteristic features of the different phonation modes which
	enable successful classification. In this paper, we extract a large
	range of features from this dataset, including specialised descriptors
	of pressedness and breathiness, to analyse their explanatory power
	and robustness against changes of pitch and vowel. We train and optimise
	a feed-forward neural network (NN) with one hidden layer on all features
	using cross validation to achieve a mean F-measure above 0.85 and
	an improved performance compared to previous work.
	
	Applying feature selection based on mutual information and retaining
	the nine highest ranked features as input to a NN results in a mean
	F-measure of 0.78, demonstrating the suitability of these features
	to discriminate between phonation modes. Training and pruning a decision
	tree yields a simple rule set based only on cepstral peak prominence
	(CPP), temporal flatness and average energy that correctly categorises
	78\% of the recordings.},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Stoller, Dixon - Analysis and classification of phonation modes in singing.pdf:PDF}
}

@INPROCEEDINGS{Stoller2018c,
  author = {Stoller, Daniel and Ewert, Sebastian and Dixon, Simon},
  title = {Jointly Detecting and Separating Singing Voice: A Multi-Task Approach},
  booktitle = {Latent Variable Analysis and Signal Separation},
  year = {2018},
  editor = {Deville, Yannick and Gannot, Sharon and Mason, Russell and Plumbley,
	Mark D. and Ward, Dominic},
  pages = {329--339},
  preprint = {https://arxiv.org/abs/1804.01650},
  url = {https://link.springer.com/chapter/10.1007/978-3-319-93764-9_31}
}

@INPROCEEDINGS{Stoller2018,
  author = {Stoller, Daniel and Ewert, Sebastian and Dixon, Simon},
  title = {Adversarial Semi-Supervised Audio Source Separation applied to Singing
	Voice Extraction},
  booktitle = {Proceedings of the IEEE International Conference on Acoustics, Speech,
	and Signal Processing ({ICASSP})},
  year = {2018},
  pages = {2391--2395},
  address = {Calgary, Canada},
  publisher = {IEEE},
  abstract = {The state of the art in music source separation employs neural networks
	trained in a supervised fashion on multi-track databases to estimate
	the sources from a given mixture. With only few datasets available,
	often extensive data augmentation is used to combat overfitting.
	Mixing random tracks, however, can even reduce separation performance
	as instruments in real music are strongly correlated. The key concept
	in our approach is that source estimates of an optimal separator
	should be indistinguishable from real source signals. Based on this
	idea, we drive the separator towards outputs deemed as realistic
	by discriminator networks that are trained to tell apart real from
	separator samples. This way, we can also use unpaired source and
	mixture recordings without the drawbacks of creating unrealistic
	music mixtures. Our framework is widely applicable as it does not
	assume a specific network architecture or number of sources. To our
	knowledge, this is the first adoption of adversarial training for
	music source separation. In a prototype experiment for singing voice
	separation, separation performance increases with our approach compared
	to purely supervised training.},
  preprint = {https://arxiv.org/abs/1711.00048}
}

@INPROCEEDINGS{Stoller2018a,
  author = {Stoller, Daniel and Ewert, Sebastian and Dixon, Simon},
  title = {{Wave-U-Net}: A Multi-Scale Neural Network for End-to-End Source
	Separation},
  booktitle = {Proceedings of the International Society for Music Information Retrieval
	Conference ({ISMIR})},
  year = {2018},
  volume = {19},
  pages = {334--340},
  abstract = {Models for audio source separation usually operate on the magnitude
	spectrum, which ignores phase information and makes separation performance
	dependant on hyper-parameters for the spectral front-end. Therefore,
	we investigate end-to-end source separation in the time-domain, which
	allows modelling phase information and avoids fixed spectral transformations.
	Due to high sampling rates for audio, employing a long temporal input
	context on the sample level is difficult, but required for high quality
	separation results because of long-range temporal correlations. In
	this context, we propose the Wave-U-Net, an adaptation of the U-Net
	to the one-dimensional time domain, which repeatedly resamples feature
	maps to compute and combine features at different time scales. We
	introduce further architectural improvements, including an output
	layer that enforces source additivity, an upsampling technique and
	a context-aware prediction framework to reduce output artifacts.
	Experiments for singing voice separation indicate that our architecture
	yields a performance comparable to a state-of-the-art spectrogram-based
	U-Net architecture, given the same data. Finally, we reveal a problem
	with outliers in the currently used SDR evaluation metrics and suggest
	reporting rank-based statistics to alleviate this problem.},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Stoller, Ewert, Dixon - Wave-u-net - A multi-scale neural network for end-to-end audio source separation.pdf:PDF}
}

@INPROCEEDINGS{Stoller2015a,
  author = {Stoller, Daniel and Mauch, Matthias and Vatolkin, Igor and Weihs,
	Claus},
  title = {Impact of Frame Size and Instrumentation on Chroma-Based Automatic
	Chord Recognition},
  booktitle = {Data Science, Learning by Latent Structures, and Knowledge Discovery},
  year = {2015},
  editor = {Lausen, Berthold and Krolak-Schwerdt, Sabine and B{\"o}hmer, Matthias},
  pages = {411--421},
  address = {Berlin, Heidelberg},
  publisher = {Springer Berlin Heidelberg},
  abstract = {This paper presents a comparative study of classification performance
	in automatic audio chord recognition based on three chroma feature
	implementations, with the aim of distinguishing effects of frame
	size, instrumentation, and choice of chroma feature. Until recently,
	research in automatic chord recognition has focused on the development
	of complete systems. While results have remarkably improved, the
	understanding of the error sources remains lacking. In order to isolate
	sources of chord recognition error, we create a corpus of artificial
	instrument mixtures and investigate (a) the influence of different
	chroma frame sizes and (b) the impact of instrumentation and pitch
	height. We show that recognition performance is significantly affected
	not only by the method used, but also by the nature of the audio
	input. We compare these results to those obtained from a corpus of
	more than 200 real-world pop songs from The Beatles and other artists
	for the case in which chord boundaries are known in advance.},
  isbn = {978-3-662-44983-7},
  url = {https://doi.org/10.1007/978-3-662-44983-7_36}
}

@ARTICLE{Stoller2018b,
  author = {Daniel Stoller and Igor Vatolkin and Heinrich M{\"u}ller},
  title = {Intuitive and efficient computer-aided music rearrangement with optimised
	processing of audio transitions},
  journal = {Journal of New Music Research},
  year = {2018},
  volume = {0},
  pages = {1-22},
  number = {0},
  abstract = {A promising approach to create new versions of existing music pieces
	automatically is to cut out and rearrange sections so that transitions
	are minimally perceptible and constraints regarding duration or structure
	are fulfilled. We evaluate previous work and improve on its limitations,
	particularly the disregard for loudness changes at cuts and the unintuitive
	control over the musical structure of the output. Our software provides
	a user-friendly interface, which we make more responsive by greatly
	accelerating the search for an optimal output track using the A*
	algorithm. Listening experiments demonstrate an improvement in perceived
	audio quality.},
  doi = {10.1080/09298215.2018.1473448},
  eprint = { https://doi.org/10.1080/09298215.2018.1473448 },
  publisher = {Routledge},
  url = { https://doi.org/10.1080/09298215.2018.1473448 
}
}

@BOOK{Stowell2010,
  title = {Making music through real-time voice timbre analysis: machine learning
	and timbral control},
  publisher = {Queen Mary, University of London},
  year = {2010},
  author = {Stowell, Dan},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\stowell-dan-making-music-through-real-time-voice-timbre-analysis-machine-learning-and-timbral-control.pdf:PDF}
}

@ARTICLE{Sturm2013,
  author = {Sturm, Bob L},
  title = {Classification accuracy is not enough},
  journal = {Journal of Intelligent Information Systems},
  year = {2013},
  volume = {41},
  pages = {371--406},
  number = {3},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Sturm - Classification accuracy is not enough.pdf:PDF},
  publisher = {Springer}
}

@INPROCEEDINGS{Sturm2012,
  author = {Sturm, Bob L},
  title = {A survey of evaluation in music genre recognition},
  booktitle = {International Workshop on Adaptive Multimedia Retrieval},
  year = {2012},
  pages = {29--66},
  organization = {Springer},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Sturm - A survey of evaluation in music genre recognition.pdf:PDF}
}

@INPROCEEDINGS{Stylianou2009,
  author = {Stylianou, Yannis},
  title = {Voice transformation: a survey},
  booktitle = {2009 IEEE International Conference on Acoustics, Speech and Signal
	Processing},
  year = {2009},
  pages = {3585--3588},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Stylianou - Voice transformation - a survey.pdf:PDF}
}

@ARTICLE{Stoter2018,
  author = {{St{\"o}ter}, F.-R. and {Liutkus}, A. and {Ito}, N.},
  title = {{The 2018 Signal Separation Evaluation Campaign}},
  journal = {ArXiv e-prints},
  year = {2018},
  archiveprefix = {arXiv},
  eprint = {1804.06267},
  keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing,
	Computer Science - Sound}
}

@INPROCEEDINGS{Sulyok2015,
  author = {Sulyok, Csaba and McPherson, Andrew and Harte, Christopher},
  title = {Corpus-taught Evolutionary Music Composition},
  booktitle = {Proceedings of the European Conference on Artificial Life 2015 (ECAL
	2015)},
  year = {2015},
  volume = {13},
  pages = {587--594},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Corpus-taught Evolutionary Music Composition.pdf:PDF}
}

@INPROCEEDINGS{Sun2013,
  author = {Sun, Dennis L and Mysore, Gautham J},
  title = {Universal speech models for speaker independent single channel source
	separation},
  booktitle = {2013 IEEE International Conference on Acoustics, Speech and Signal
	Processing},
  year = {2013},
  pages = {141--145},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Sun, Mysore - Universal speech models for speaker independent single channel source separation.pdf:PDF}
}

@ARTICLE{Sundberg1990,
  author = {Johan Sundberg},
  title = {What's so special about singers? },
  journal = {Journal of Voice },
  year = {1990},
  volume = {4},
  pages = {107 - 119},
  number = {2},
  abstract = {Summary Research on singers' breathing, phonation and articulation
	patterns during singing is reviewed and comparisons are made with
	typical speech patterns. It is found that singers' and nonsingers'
	use of the voice differ in several respects. The reasons for these
	differences are discussed and explanations are proposed referring
	to the special demands raised on singers with respect to economization
	of vocal effort and flexibility of phonation. },
  doi = {http://dx.doi.org/10.1016/S0892-1997(05)80135-3},
  issn = {0892-1997},
  url = {http://www.sciencedirect.com/science/article/pii/S0892199705801353}
}

@BOOK{Sundberg1987,
  title = {The science of the singing voice},
  publisher = {Illinois University Press},
  year = {1987},
  author = {Johan Sundberg},
  owner = {Daniel},
  timestamp = {2016.02.17}
}

@ARTICLE{Sundberg2004,
  author = {Sundberg, Johan and Thal{\'e}n, Margareta and Alku, Paavo and Vilkman,
	Erkki},
  title = {Estimating perceived phonatory pressedness in singing from flow glottograms},
  journal = {Journal of Voice},
  year = {2004},
  volume = {18},
  pages = {56--62},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Sundberg Thalen Alku Erkki - Estimating perceived phonatory pressedness in singing from flow glottograms.pdf:PDF},
  owner = {Daniel},
  publisher = {Elsevier},
  timestamp = {2016.03.03}
}

@ARTICLE{Sundberg2012,
  author = {Johan Sundberg and Margareta Thalén and Lisa Popeil},
  title = {Substyles of Belting: Phonatory and Resonatory Characteristics },
  journal = {Journal of Voice },
  year = {2012},
  volume = {26},
  pages = {44 - 50},
  number = {1},
  abstract = {Summary Belting has been described as speechlike, yell-like, or shouting
	voice production commonly used in contemporary commercial music genres
	and substantially differing from the esthetic of the Western classical
	voice tradition. This investigation attempts to describe phonation
	and resonance characteristics of different substyles of belting (heavy,
	brassy, ringy, nasal, and speechlike) and the classical style. A
	professional singer and voice teacher, skilled in these genres, served
	as the single subject. The recorded material was found representative
	according to a classification test performed by an expert panel.
	Subglottal pressure was measured as the oral pressure during the
	occlusion for the consonant /p/. The voice source and formant frequencies
	were analyzed by inverse filtering the audio signal. The subglottal
	pressure and measured flow glottogram parameters differed clearly
	between the styles heavy and classical assuming opposite extremes
	in most parameters. The formant frequencies, by contrast, showed
	fewer less systematic differences between the substyles but were
	clearly separated from the classical style with regard to the first
	formant. Thus, the differences between the belting substyles mainly
	concerned the voice source. },
  doi = {http://dx.doi.org/10.1016/j.jvoice.2010.10.007},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Sundberg Thalen Popeil - Substyles of Belting - Phonatory and Resonatory Characteristics.pdf:PDF},
  issn = {0892-1997},
  keywords = {Formant frequencies},
  url = {http://www.sciencedirect.com/science/article/pii/S0892199710001773}
}

@ARTICLE{Sutskever2015,
  author = {Sutskever, Ilya and Jozefowicz, Rafal and Gregor, Karol and Rezende,
	Danilo and Lillicrap, Tim and Vinyals, Oriol},
  title = {Towards Principled Unsupervised Learning},
  journal = {arXiv preprint arXiv:1511.06440},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Sutskever, Jozefowicz, Gregor, Rezende, Lillicrap, Vinyals - Towards principled unsupervised learning.pdf:PDF}
}

@ARTICLE{Szegedy2013,
  author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and
	Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  title = {Intriguing properties of neural networks},
  journal = {arXiv preprint arXiv:1312.6199},
  year = {2013},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Szgedy, Zaremba, Sutskeva, Bruna, Erhan, Goodfellow, Fergus - Intriguing properties of neural networks.pdf:PDF}
}

@ARTICLE{Subakan2017,
  author = {Y. Cem S{\"{u}}bakan and Paris Smaragdis},
  title = {Generative Adversarial Source Separation},
  journal = {CoRR},
  year = {2017},
  volume = {abs/1710.10779},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.org/rec/bib/journals/corr/abs-1710-10779},
  eprint = {1710.10779},
  timestamp = {Thu, 02 Nov 2017 14:25:36 +0100},
  url = {http://arxiv.org/abs/1710.10779}
}

@INPROCEEDINGS{Sonderby2017,
  author = {S{\o}nderby, Casper Kaae and Caballero, Jose and Theis, Lucas and
	Shi, Wenzhe and Husz{\'a}r, Ferenc},
  title = {Amortised map inference for image super-resolution},
  booktitle = {5th International Conference on Learning Representations (ICLR)},
  year = {2017},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Sonderby, Caballero, Theis, Shi, Huszar - Amortised MAP inference for image super-resolution.pdf:PDF}
}

@ARTICLE{Sonderby2016,
  author = {S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and
	S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  title = {How to train deep variational autoencoders and probabilistic ladder
	networks},
  journal = {arXiv preprint arXiv:1602.02282},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Sonderby, Casper, Raiko, Maaloe, Sonderby, Soren Kaae, Winther - How to train Deep Variational Autoencoders and Probabilistic Ladder Networks.pdf:PDF}
}

@ARTICLE{Sonderby2016a,
  author = {S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and
	S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  title = {Ladder Variational Autoencoders},
  journal = {arXiv preprint arXiv:1602.02282},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Sonderby, Raiko, Maaloe, Sonderby, Winther - Ladder Variational Autoencoders.pdf:PDF}
}

@ARTICLE{Tachibana2014,
  author = {Tachibana, Hideyuki and Ono, Nobutaka and Sagayama, Shigeki},
  title = {Singing voice enhancement in monaural music signals based on two-stage
	harmonic/percussive sound separation on multiple resolution spectrograms},
  journal = {IEEE/ACM transactions on audio, speech, and language processing},
  year = {2014},
  volume = {22},
  pages = {228--237},
  number = {1},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Tachiabana, Ono, Sagayama - Singing voice enhancement in monarual music signals based on two-stage harmonic-percussive sound separation on multiple resolution spectrograms.pdf:PDF},
  publisher = {IEEE}
}

@INPROCEEDINGS{Tauscher:2013,
  author = {Tauscher, J. and Wenger, S. and Magnor, M.},
  title = {Audio Resynthesis on the Dancefloor: {A} Music Structural Approach},
  booktitle = {Proceedings of the Vision, Modeling, and Visualization Workshop,
	Lugano, Switzerland},
  year = {2013},
  pages = {41--48},
  //month = {\#sep\#},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Audio resynthesis paper 2013.pdf:PDF}
}

@INPROCEEDINGS{Taylor2009,
  author = {Taylor, Graham W and Hinton, Geoffrey E},
  title = {Factored conditional restricted Boltzmann machines for modeling motion
	style},
  booktitle = {Proceedings of the 26th annual international conference on machine
	learning},
  year = {2009},
  pages = {1025--1032},
  organization = {ACM},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Taylor, Hinton - Factored conditional restricted boltzmann machines for modeling motion style.pdf:PDF}
}

@INPROCEEDINGS{Taylor2006,
  author = {Taylor, Graham W and Hinton, Geoffrey E and Roweis, Sam T},
  title = {Modeling human motion using binary latent variables},
  booktitle = {Advances in neural information processing systems},
  year = {2006},
  pages = {1345--1352},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Taylor, Hinton, Roweis - Modeling human motion using binary latent variables.pdf:PDF}
}

@ARTICLE{Terasawa2005,
  author = {Terasawa, Hiroko and Slaney, Malcolm and Berger, Jonathan},
  title = {Perceptual distance in timbre space},
  year = {2005},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Perceptual distance in timbre space.pdf:PDF},
  publisher = {Georgia Institute of Technology}
}

@ARTICLE{Theano2016,
  author = {{Theano Development Team}},
  title = {{Theano: A {Python} framework for fast computation of mathematical
	expressions}},
  journal = {arXiv e-prints},
  year = {2016},
  volume = {abs/1605.02688},
  month = {May},
  keywords = {Computer Science - Symbolic Computation, Computer Science - Learning,
	Computer Science - Mathematical Software},
  primaryclass = {cs.SC},
  url = {http://arxiv.org/abs/1605.02688}
}

@ARTICLE{Theis2015,
  author = {Theis, Lucas and Oord, A{\"a}ron van den and Bethge, Matthias},
  title = {A note on the evaluation of generative models},
  journal = {arXiv preprint arXiv:1511.01844},
  year = {2015},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Theis, Oord, Bethge - A note on the evaluation of generative models.pdf:PDF}
}

@ARTICLE{Tran2017,
  author = {Tran, Dustin and Ranganath, Rajesh and Blei, David M},
  title = {Deep and Hierarchical Implicit Models},
  journal = {arXiv preprint arXiv:1702.08896},
  year = {2017},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Tran, Ranganath, Blei - Deep and hierarchical implicit models.pdf:PDF}
}

@ARTICLE{Trehub1999,
  author = {Trehub, Sandra E and Schellenberg, E Glenn and Kamenetsky, Stuart
	B},
  title = {Infants' and adults' perception of scale structure.},
  journal = {Journal of experimental psychology: Human perception and performance},
  year = {1999},
  volume = {25},
  pages = {965},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Trehub, Schellenberg - Infants and Adults Perception of Scale Structure.pdf:PDF},
  publisher = {American Psychological Association}
}

@INPROCEEDINGS{Tsai2018,
  author = {Tsai, Che-Ping and Tuan, Yi-Lin and Lee, Lin-shan},
  title = {Transcribing Lyrics from Commercial Song Audio: the First Step Towards
	Singing Content Processing},
  booktitle = {Proceedings of the IEEE International Conference on Acoustics, Speech
	and Signal Processing (ICASSP)},
  year = {2018},
  pages = {5749-5753},
  doi = {10.1109/ICASSP.2018.8462247},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Tsai, Tuan, Lee - Transcribing lyrics from commercial song audio - the first step towards singing content processing.pdf:PDF},
  issn = {2379-190X},
  keywords = {Hidden Markov models;Adaptation models;Data models;Acoustics;Training;Testing;Human
	voice;Lyrics;Song Audio;Acoustic Model Adaptation;Genre;Prolonged
	Vowels}
}

@ARTICLE{Turner:2010,
  author = {Turner III, Daniel W},
  title = {Qualitative interview design: A practical guide for novice investigators},
  journal = {The qualitative report},
  year = {2010},
  volume = {15},
  pages = {754},
  number = {3},
  publisher = {The Qualitative Report}
}

@INPROCEEDINGS{Tzeng2015,
  author = {Tzeng, Eric and Hoffman, Judy and Darrell, Trevor and Saenko, Kate},
  title = {Simultaneous deep transfer across domains and tasks},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
  year = {2015},
  pages = {4068--4076},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Tzeng, Hoffmann, Darrell, Saenko - Simultaneous Deep Transfer Across Domains and Tasks.pdf:PDF}
}

@INPROCEEDINGS{Uhlich2015,
  author = {Uhlich, Stefan and Giron, Franck and Mitsufuji, Yuki},
  title = {Deep neural network based instrument extraction from music},
  booktitle = {2015 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2015},
  pages = {2135--2139},
  organization = {IEEE},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Uhlich, Giron, Mitsufuji - Deep neural network based instrument extraction from music.pdf:PDF}
}

@INPROCEEDINGS{Uhlich2017,
  author = {S. Uhlich and M. Porcu and F. Giron and M. Enenkl and T. Kemp and
	N. Takahashi and Y. Mitsufuji},
  title = {Improving music source separation based on deep neural networks through
	data augmentation and network blending},
  booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal
	Processing (ICASSP)},
  year = {2017},
  pages = {261-265},
  month = {March},
  doi = {10.1109/ICASSP.2017.7952158},
  keywords = {Wiener filters;mixture models;music;recurrent neural nets;speech processing;SiSEC
	DSD100 dataset;blending scheme yields;data augmentation;deep neural
	network architectures;multichannel Wiener filter post-processing;music
	source separation improvement;recurrent network;Context;Indexes;Instruments;Recurrent
	neural networks;Source separation;Training;Blending;Deep neural network
	(DNN);Long-short term memory (LSTM);Music source separation (MSS)}
}

@INPROCEEDINGS{Ullrich2014,
  author = {Karen Ullrich and Jan Schl{\"u}ter and Thomas Grill},
  title = {{Boundary Detection in Music Structure Analysis using Convolutional
	Neural Networks}},
  booktitle = {15th International Society for Music Information Retrieval Conference
	({ISMIR} 2014)},
  year = {2014},
  address = {Taipei, Taiwan},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Ullrich, Schlüter, Grill - Boundary detection in music structure analysis using convolutional neural networks.pdf:PDF}
}

@ARTICLE{VanDenBroeke2016,
  author = {Van Den Broeke, Gerben and others},
  title = {What auto-encoders could learn from brains-Generation as feedback
	in deep unsupervised learning and inference},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\van der Broeke - What auto-encoders could learn frombrains.pdf:PDF}
}

@ARTICLE{Venkataramani2017,
  author = {Shrikant Venkataramani and Paris Smaragdis},
  title = {End-to-end Source Separation with Adaptive Front-Ends},
  journal = {CoRR},
  year = {2017},
  volume = {abs/1705.02514},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/bib/journals/corr/VenkataramaniS17},
  eprint = {1705.02514},
  timestamp = {Wed, 07 Jun 2017 14:42:27 +0200},
  url = {http://arxiv.org/abs/1705.02514}
}

@ARTICLE{Verdolini1998,
  author = {Katherine Verdolini and David G. Druker and Phyllis M. Palmer and
	Hani Samawi},
  title = {Laryngeal adduction in resonant voice },
  journal = {Journal of Voice },
  year = {1998},
  volume = {12},
  pages = {315 - 327},
  number = {3},
  abstract = {Summary The primary question in this study was whether subjects with
	nodules and subjects with healthy larynges would produce “resonant
	voice�? with a similar laryngeal configuration. A second question
	regarded whether the electroglottographic closed quotient (EGG CQ)
	could be used to noninvasively distinguish resonant from other voice
	types. Twelve adult singers and actors served as subjects, including
	6 persons with healthy larynges and 6 persons with nodules. Performers
	were used as an attempt to maximize token validity and stability.
	Subjects produced repeated tokens of resonant, pressed, normal, and
	breathy voice during sustained vowels. Laryngeal adduction was directly
	estimated using blinded, ordinal, visual-perceptual ratings based
	on videoscopic views of the larynx. \{EGG\} \{CQs\} were further
	calculated based on separate trials. The perceptual ratings indicated
	that subjects in both groups produced resonant voice with a barely
	adducted or barely abducted laryngeal configuration that was distinct
	from configurations for pressed and breathy (but not normal) voice.
	Previous literature suggests that this configuration may be relevant
	in many cases of voice therapy (I). Average \{CQs\} distinguished
	resonant from pressed voice, but inconsistently distinguished resonant
	from breathy voice. Further \{CQs\} were reliably different across
	healthy subjects and subjects with nodules. Thus, the utility of
	this measure to noninvasively estimate resonant voice may be limited,
	particularly without ongoing subject-specific calibration procedures.
	},
  doi = {http://dx.doi.org/10.1016/S0892-1997(98)80021-0},
  issn = {0892-1997},
  keywords = {Resonant voice},
  url = {http://www.sciencedirect.com/science/article/pii/S0892199798800210}
}

@INPROCEEDINGS{Verfaille2005,
  author = {Verfaille, Vincent and Guastavino, Catherine},
  title = {Perceptual evaluation of vibrato models},
  booktitle = {Conference on Interdisciplinary Musicology},
  year = {2005},
  organization = {Citeseer},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Verfaille, Guastavino - Perceptual evaluation of vibrato models.pdf:PDF}
}

@INPROCEEDINGS{Verhelst1993,
  author = {Verhelst, W. and Roelands, M.},
  title = {An overlap-add technique based on waveform similarity ({WSOLA}) for
	high quality time-scale modification of speech},
  booktitle = {{IEEE} International Conference on Acoustics, Speech, and Signal
	Processing ({ICASSP})},
  year = {1993},
  pages = {554-557},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\An overlap-add technique based on waveform similarity for high quality time-scale modification of speech.pdf:PDF},
  issn = {1520-6149},
  keywords = {fast Fourier transforms;online operation;speech analysis and processing;time-varying
	systems;waveform analysis;online processing;short-time Fourier transform;synchronized
	overlap-add;time-scale modification of speech;waveform similarity}
}

@INPROCEEDINGS{Vincent2012,
  author = {Vincent, Emmanuel},
  title = {Improved Perceptual Metrics for the Evaluation of Audio Source Separation},
  booktitle = {Latent Variable Analysis and Signal Separation},
  year = {2012},
  pages = {430--437},
  publisher = {Springer},
  abstract = {We aim to predict the perceived quality of estimated source signals
	in the context of audio source separation. Recently, we proposed
	a set of metrics called PEASS that consist of three computation steps:
	decomposition of the estimation error into three components, measurement
	of the salience of each component via the PEMO-Q auditory-motivated
	measure, and combination of these saliences via a nonlinear mapping
	trained on subjective opinion scores. The parameters of the decomposition
	were shown to have little influence on the prediction performance.
	In this paper, we evaluate the impact of the parameters of PEMO-Q
	and the nonlinear mapping on the prediction performance. By selecting
	the optimal parameters, we improve the average correlation with mean
	opinion scores (MOS) from 0.738 to 0.909 in a cross-validation setting.
	The resulting improved metrics are used in the context of the 2011
	Signal Separation Evaluation Campaign (SiSEC).},
  file = {:/mnt/windaten/Seafile/PhD/Literature/Docea/Papers/Vincent - Improved perceptual metrics for the evaluation of audio source separation.pdf:PDF},
  isbn = {978-3-642-28551-6}
}

@ARTICLE{Vincent2006,
  author = {E. Vincent and R. Gribonval and C. Fevotte},
  title = {Performance measurement in blind audio source separation},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  year = {2006},
  volume = {14},
  pages = {1462-1469},
  number = {4},
  doi = {10.1109/TSA.2005.858005},
  issn = {1558-7916},
  keywords = {audio signal processing;blind source separation;distortion;time-varying
	filters;additive noise;algorithmic artifacts;blind audio source separation;distortions;interference;source
	estimation;time-invariant gains;time-varying filters;Additive noise;Data
	mining;Distortion measurement;Energy measurement;Filters;Image analysis;Independent
	component analysis;Interference;Microphones;Source separation;Audio
	source separation;evaluation;measure;performance;quality}
}

@OTHER{Vincent2016,
  author = {Vincent, E. and Gribonval, R. and Fevotte, C. and Nesbit, A. and
	Plumbley, M. D. and Davies, M. E. and Daudet, L.},
  owner = {Daniel},
  timestamp = {2016.10.06},
  title = {BASS-dB: the Blind Audio Source Separation evaluation database},
  url = {http://www.irisa.fr/metiss/BASS-dB/},
  year = {2016}
}

@ARTICLE{Vincent2010,
  author = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio,
	Yoshua and Manzagol, Pierre-Antoine},
  title = {Stacked denoising autoencoders: Learning useful representations in
	a deep network with a local denoising criterion},
  journal = {Journal of Machine Learning Research},
  year = {2010},
  volume = {11},
  pages = {3371--3408},
  number = {Dec},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Vincent, Larochelle, Lajoie, Bengio, Manzagol - Stacked Denoising Autoencoders - Learning Useful Representations.pdf:PDF}
}

@ARTICLE{Vinyals2015,
  author = {Vinyals, Oriol and Bengio, Samy and Kudlur, Manjunath},
  title = {Order matters: Sequence to sequence for sets},
  journal = {arXiv preprint arXiv:1511.06391},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Vinyals, Bengio, Kudlur - Order matters - sequence to sequence for sets.pdf:PDF}
}

@INPROCEEDINGS{Vinyals2016,
  author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Tim and Wierstra,
	Daan and others},
  title = {Matching networks for one shot learning},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2016},
  pages = {3630--3638},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Vinyals, Blundell, Lillicrap, Kavukcuoglu, Wierstra - Matching networks for one-shot learning.pdf:PDF}
}

@INPROCEEDINGS{Wang2004,
  author = {Wang, Ye and Kan, Min-Yen and Nwe, Tin Lay and Shenoy, Arun and Yin,
	Jun},
  title = {{LyricAlly}: automatic synchronization of acoustic musical signals
	and textual lyrics},
  booktitle = {Proceedings of the Annual ACM International Conference on Multimedia
	(ACMMM)},
  year = {2004},
  pages = {212--219},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Wang, Kan, Nwe, Shenoy, Yin - LyicAlly - Automatic synchronizatino of acoustic musical signals and textual lyrics.pdf:PDF}
}

@INPROCEEDINGS{Wang2015,
  author = {Wang, Zhiguang and Oates, Tim},
  title = {Encoding Time Series as Images for Visual Inspection and Classification
	Using Tiled Convolutional Neural Networks},
  booktitle = {Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Wang, Oates - Encoding Time Series as Images for Visual Inspection and Classification Using Tiled Convolutional Neural Networks.pdf:PDF}
}

@INCOLLECTION{WaschkaII2007,
  author = {Waschka II, Rodney},
  title = {Composing with Genetic Algorithms: GenDash},
  booktitle = {Evolutionary Computer Music},
  publisher = {Springer},
  year = {2007},
  pages = {117--136},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Waschka - Composing with genetic algorithms Gendash.pdf:PDF}
}

@ARTICLE{Watts2006,
  author = {Christopher Watts and Kathryn Barnes-Burroughs and Julie Estis and
	Debra Blanton},
  title = {The Singing Power Ratio as an Objective Measure of Singing Voice
	Quality in Untrained Talented and Nontalented Singers },
  journal = {Journal of Voice },
  year = {2006},
  volume = {20},
  pages = {82 - 88},
  number = {1},
  abstract = {Summary A growing body of contemporary research has investigated differences
	between trained and untrained singing voices. However, few studies
	have separated untrained singers into those who do and do not express
	abilities related to singing talent, including accurate pitch control
	and production of a pleasant timbre (voice quality). This investigation
	studied measures of the singing power ratio (SPR), which is a quantitative
	measure of the resonant quality of the singing voice. \{SPR\} reflects
	the amplification or suppression in the vocal tract of the harmonics
	produced by the sound source. This measure was acquired from the
	voices of untrained talented and nontalented singers as a means to
	objectively investigate voice quality differences. Measures of \{SPR\}
	were acquired from vocal samples with fast Fourier transform (FFT)
	power spectra to analyze the amplitude level of the partials in the
	acoustic spectrum. Long-term average spectra (LTAS) were also analyzed.
	Results indicated significant differences in \{SPR\} between groups,
	which suggest that vocal tract resonance, and its effect on perceived
	vocal timbre or quality, may be an important variable related to
	the perception of singing talent. \{LTAS\} confirmed group differences
	in the tuning of vocal tract harmonics. },
  doi = {http://dx.doi.org/10.1016/j.jvoice.2004.12.003},
  issn = {0892-1997},
  keywords = {Singing talent},
  url = {http://www.sciencedirect.com/science/article/pii/S0892199704001791}
}

@ARTICLE{Webster2014,
  author = {Webster, P. and Jiuicek, O.},
  title = {A Brief Comparison of Loudness Evaluation Methods},
  journal = {Acoustic Sheets, Czech Technical University in Prague},
  year = {2014},
  volume = {20},
  pages = {8--11},
  number = {2},
  /pages = {8--11},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\pw-article.pdf:PDF},
  publisher = {Department of Physics, Czech Technical University in Prague}
}

@INPROCEEDINGS{Wenger:2012,
  author = {Wenger, S. and Magnor, M.},
  title = {A Genetic Algorithm for Audio Retargeting},
  booktitle = {{ACM} Multimedia ({ACMMM})},
  year = {2012},
  pages = {705--708},
  //month = {\#jun\#},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\A Genetic Algorithm for Audio Retargeting 2012.pdf:PDF}
}

@INPROCEEDINGS{Wenger:2011,
  author = {Wenger, S. and Magnor, M.},
  title = {Constrained Example-Based Audio Synthesis},
  booktitle = {International Conference on Multimedia and Expo {(ICME)}},
  year = {2011},
  pages = {1--6},
  //month = {\#jul\#}
}

@ARTICLE{Weninger2011,
  author = {Weninger, Felix and W{\"o}llmer, Martin and Schuller, Bj{\"o}rn},
  title = {Automatic assessment of singer traits in popular music: Gender, age,
	height and race},
  journal = {young (y)},
  year = {2011},
  volume = {48},
  pages = {510},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Weninger, Wöllmer, Schuller - Automatic assessment of singer traits in popular music - gender, age, height and race.pdf:PDF}
}

@MASTERSTHESIS{Wenner:2012,
  author = {Wenner, S.},
  title = {Music Retargeting and Synthesis},
  school = {Swiss Federal Institute of Technology Zurich},
  year = {2012},
  //month = {April}
}

@ARTICLE{Wenner2013,
  author = {Simon Wenner and Jean-Charles Bazin and Alexander Sorkine-Hornung
	and Changil Kim and Markus Gross},
  title = {Scalable Music: Automatic Music Retargeting and Synthesis},
  journal = {Computer Graphics Forum (Proceedings of Eurographics 2013)},
  year = {2013},
  volume = {32},
  pages = {345-354},
  number = {2}
}

@MISC{FMA,
  author = {WFMU},
  title = {Free Music Archive},
  howpublished = {\url{http://freemusicarchive.org/}},
  year = {2009},
  note = {Accessed: 2018-01-21},
  url = {http://freemusicarchive.org/}
}

@INPROCEEDINGS{Yang2013,
  author = {Yang, Yi-Hsuan},
  title = {Low-Rank Representation of Both Singing Voice and Music Accompaniment
	Via Learned Dictionaries.},
  booktitle = {ISMIR},
  year = {2013},
  pages = {427--432},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Yang - Low-rank representation of both singing voice and music accompaniment via learned dictionaries.pdf:PDF}
}

@INCOLLECTION{Yoon2006,
  author = {Yoon, Jong-Chul and Lee, In-Kwon and Lee, Hyun-Chul},
  title = {Feature-based synchronization of video and background music},
  booktitle = {Advances in Machine Vision, Image Processing, and Pattern Analysis},
  publisher = {Springer},
  year = {2006},
  pages = {205--214},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Feature-based synchronization of video and background music.pdf:PDF}
}

@ARTICLE{Yosinski2015,
  author = {Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas
	and Lipson, Hod},
  title = {Understanding neural networks through deep visualization},
  journal = {arXiv preprint arXiv:1506.06579},
  year = {2015},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Yosinski, Clune, Nguyen, Fuchs, Lipson - Understanding neural networks through deep visualization.pdf:PDF}
}

@ARTICLE{Yu2015,
  author = {Yu, Fisher and Koltun, Vladlen},
  title = {Multi-scale context aggregation by dilated convolutions},
  journal = {arXiv preprint arXiv:1511.07122},
  year = {2015},
  file = {:/mnt/daten/Seafile/PhD/Literature/Docea/Papers/Yu, Koltun - Multi-scale context aggregation by dilated convolutions.pdf:PDF}
}

@INPROCEEDINGS{Yu2017,
  author = {Yu, Lantao and Zhang, Weinan and Wang, Jun and Yu, Yong},
  title = {SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient.},
  booktitle = {AAAI},
  year = {2017},
  pages = {2852--2858}
}

@INPROCEEDINGS{Yuan2012,
  author = {Yuan, Lei and Wang, Yalin and Thompson, Paul M and Narayan, Vaibhav
	A and Ye, Jieping},
  title = {Multi-source learning for joint analysis of incomplete multi-modality
	neuroimaging data},
  booktitle = {18th ACM SIGKDD international conference on Knowledge discovery and
	data mining},
  year = {2012},
  pages = {1149--1157},
  organization = {ACM},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Yuan, Wang, Thompson, Narayan, Ye - Multi-source learning for joint analysis fo incomplete multi-modality neuroimaging data.pdf:PDF}
}

@ARTICLE{Zacharakis2015,
  author = {Zacharakis, Asterios and Pastiadis, Konstantinos and Reiss, Joshua
	D},
  title = {An Interlanguage Unification of Musical Timbre},
  journal = {Music Perception: An Interdisciplinary Journal},
  year = {2015},
  volume = {32},
  pages = {394--412},
  number = {4},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Zacharakis Pastiadis Reiss - An Interlanguage Unification of Musical Timbre Bridging Semantic, Perceptual, and Acoustic Dimensions.pdf:PDF},
  publisher = {University of California Press Journals}
}

@ARTICLE{Zar:1972,
  author = {Zar, J. H},
  title = {Significance testing of the Spearman rank correlation coefficient},
  journal = {Journal of the American Statistical Association},
  year = {1972},
  volume = {67},
  pages = {578--580},
  number = {339},
  publisher = {Taylor \& Francis Group}
}

@INCOLLECTION{Zeiler2014,
  author = {Zeiler, Matthew D and Fergus, Rob},
  title = {Visualizing and understanding convolutional networks},
  booktitle = {Computer vision--ECCV 2014},
  publisher = {Springer},
  year = {2014},
  pages = {818--833},
  file = {:C\:\\Users\\Daniel\\Seafile\\PhD\\Literature\\Docea\\Papers\\Zeiler, Fergus - VIsualizing and understanding convolutional networks.pdf:PDF}
}

@INPROCEEDINGS{Zeiler2010,
  author = {Zeiler, Matthew D and Krishnan, Dilip and Taylor, Graham W and Fergus,
	Rob},
  title = {Deconvolutional networks},
  booktitle = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference
	on},
  year = {2010},
  pages = {2528--2535},
  organization = {IEEE},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Zeiler, Krishnan, Taylor, Fergus - Deconvolutional networks.pdf:PDF}
}

@ARTICLE{Zhang2017,
  author = {Ning Zhang and Junchi Yan and Yu Chen Zhou},
  title = {Unsupervised Audio Source Separation via Spectrum Energy Preserved
	Wasserstein Learning},
  journal = {CoRR},
  year = {2017},
  volume = {abs/1711.04121},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {http://dblp.org/rec/bib/journals/corr/abs-1711-04121},
  eprint = {1711.04121},
  timestamp = {Fri, 01 Dec 2017 14:22:24 +0100},
  url = {http://arxiv.org/abs/1711.04121}
}

@ARTICLE{Zhao2016,
  author = {Zhao, Junbo and Mathieu, Michael and LeCun, Yann},
  title = {Energy-based generative adversarial network},
  journal = {arXiv preprint arXiv:1609.03126},
  year = {2016},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\Zhao, Mathieu, LeCun - Energy-based generative adversarial networks.pdf:PDF}
}

@ARTICLE{Zhao2017,
  author = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  title = {Towards Deeper Understanding of Variational Autoencoding Models},
  journal = {arXiv preprint arXiv:1702.08658},
  year = {2017},
  file = {:/home/daniel/Seafile/PhD/Literature/Docea/Papers/Zhao, Song, Ermon - Towards a deeper undersatnding of variational autoencoding models.pdf:PDF}
}

@ARTICLE{Zheng2001,
  author = {Zheng, F. and Zhang, Gu. and Song, Z.},
  title = {Comparison of different implementations of MFCC},
  journal = {Journal of Computer Science and Technology},
  year = {2001},
  volume = {16},
  pages = {582-589},
  number = {6},
  doi = {10.1007/BF02943243},
  file = {:D\:\\Seafile\\PhD\\Literature\\Docea\\Papers\\MFCC implementations.pdf:PDF},
  issn = {1000-9000},
  keywords = {MFCC; frequency band energy; auto-regressive analysis; generalized
	initial/final},
  language = {English},
  publisher = {Science Press},
  url = {http://dx.doi.org/10.1007/BF02943243}
}

@ARTICLE{Zwicker:1991,
  author = {Zwicker, E. and Fastl, H. and Widmann, U. and Kurakata, K. and Kuwano,
	S. and Namba, S.},
  title = {Program for calculating loudness according to DIN 45631 (ISO 532B).},
  journal = {Journal of the Acoustical Society of Japan (E)},
  year = {1991},
  volume = {12},
  pages = {39--42},
  number = {1}
}

