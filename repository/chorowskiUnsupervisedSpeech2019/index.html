<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.12.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Unsupervised Speech Representation Learning Using WaveNet Autoencoders - Dans World</title>
<meta name="description" content="Machine learning, music information retrieval, and other things">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_GB">
<meta property="og:site_name" content="Dans World">
<meta property="og:title" content="Unsupervised Speech Representation Learning Using WaveNet Autoencoders">
<meta property="og:url" content="https://dans.world/repository/chorowskiUnsupervisedSpeech2019/">












  

  


<link rel="canonical" href="https://dans.world/repository/chorowskiUnsupervisedSpeech2019/">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Daniel Stoller",
      "url": "https://dans.world",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Dans World Feed">

<!-- 

 -->

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link rel="stylesheet" href="/assets/css/academicons.css">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    
  </head>

  <body class="layout--archive">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Dans World</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="https://dans.world/research/" >Research</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="https://dans.world/publications/" >Publications</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="https://dans.world/about/" >About</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="https://dans.world/posts/" >Blog</a>
            </li>
          
        </ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div class="initial-content">
      



<div id="main" role="main">
  

  <div class="archive">
    
      <h1 id="page-title" class="page__title">Unsupervised Speech Representation Learning Using WaveNet Autoencoders</h1>
    
    <div>
  <div>
    <h5>Venue</h5>
    <p> 
	IEEE/ACM Transactions on Audio, Speech, and Language Processing,
	vol. 27(12), pp. 2041–2053
	
</p>
    <h5>Publication Year</h5>
    <p>2019</p>
    <h5>Keywords</h5>
    <p>Computer Science - Machine Learning,Electrical Engineering and Systems Science - Audio and Speech Processing,Statistics - Machine Learning</p>
    <h5>Identifiers</h5>
    <ul>
      <li>DOI: <a href="http://dx.doi.org/10.1109/TASLP.2019.2938863"><i class="fas fa-li fa-external-link-square-alt"></i>http://dx.doi.org/10.1109/TASLP.2019.2938863</a> </li>
      
    </ul>
  </div>
</div>

<h3>Authors</h3>
<ul class="list-inline">



<li class="list-inline-item">Jan Chorowski</li>



<li class="list-inline-item">Ron J. Weiss</li>



<li class="list-inline-item">Samy Bengio</li>



<li class="list-inline-item">Aäron Oord</li>

</ul>



<h3>Abstract</h3>
<p>
We consider the task of unsupervised extraction of meaningful latent representations of speech by applying autoencoding neural networks to speech waveforms. The goal is to learn a representation able to capture high level semantic content from the signal, e.g. phoneme identities, while being invariant to confounding low level details in the signal such as the underlying pitch contour or background noise. Since the learned representation is tuned to contain only phonetic content, we resort to using a high capacity WaveNet decoder to infer information discarded by the encoder from previous samples. Moreover, the behavior of autoencoder models depends on the kind of constraint that is applied to the latent representation. We compare three variants: a simple dimensionality reduction bottleneck, a Gaussian Variational Autoencoder (VAE), and a discrete Vector Quantized VAE (VQ-VAE). We analyze the quality of learned representations in terms of speaker independence, the ability to predict phonetic content, and the ability to accurately reconstruct individual spectrogram frames. Moreover, for discrete encodings extracted using the VQ-VAE, we measure the ease of mapping them to phonemes. We introduce a regularization scheme that forces the representations to focus on the phonetic content of the utterance and report performance comparable with the top entries in the ZeroSpeech 2017 unsupervised acoustic unit discovery task.
</p>



<h3>Source Materials</h3>
<ul class="fa-ul">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  
  

  <li><a download="chorowskiUnsupervisedSpeech2019.bib" href="data:application/x-bibtex,%7B%25raw%25%7D@article%7BchorowskiUnsupervisedSpeech2019,%0A%20%20title%20=%20%7BUnsupervised%20Speech%20Representation%20Learning%20Using%20%7B%7BWaveNet%7D%7D%20Autoencoders%7D,%0A%20%20author%20=%20%7BChorowski,%20Jan%20and%20Weiss,%20Ron%20J.%20and%20Bengio,%20Samy%20and%20van%20den%20Oord,%20A%7B%5C%22a%7Dron%7D,%0A%20%20year%20=%20%7B2019%7D,%0A%20%20month%20=%20dec,%0A%20%20volume%20=%20%7B27%7D,%0A%20%20pages%20=%20%7B2041--2053%7D,%0A%20%20issn%20=%20%7B2329-9290,%202329-9304%7D,%0A%20%20doi%20=%20%7B10.1109/TASLP.2019.2938863%7D,%0A%20%20abstract%20=%20%7BWe%20consider%20the%20task%20of%20unsupervised%20extraction%20of%20meaningful%20latent%20representations%20of%20speech%20by%20applying%20autoencoding%20neural%20networks%20to%20speech%20waveforms.%20The%20goal%20is%20to%20learn%20a%20representation%20able%20to%20capture%20high%20level%20semantic%20content%20from%20the%20signal,%20e.g.%5Ctextbackslash%7B%7D%20phoneme%20identities,%20while%20being%20invariant%20to%20confounding%20low%20level%20details%20in%20the%20signal%20such%20as%20the%20underlying%20pitch%20contour%20or%20background%20noise.%20Since%20the%20learned%20representation%20is%20tuned%20to%20contain%20only%20phonetic%20content,%20we%20resort%20to%20using%20a%20high%20capacity%20WaveNet%20decoder%20to%20infer%20information%20discarded%20by%20the%20encoder%20from%20previous%20samples.%20Moreover,%20the%20behavior%20of%20autoencoder%20models%20depends%20on%20the%20kind%20of%20constraint%20that%20is%20applied%20to%20the%20latent%20representation.%20We%20compare%20three%20variants:%20a%20simple%20dimensionality%20reduction%20bottleneck,%20a%20Gaussian%20Variational%20Autoencoder%20(VAE),%20and%20a%20discrete%20Vector%20Quantized%20VAE%20(VQ-VAE).%20We%20analyze%20the%20quality%20of%20learned%20representations%20in%20terms%20of%20speaker%20independence,%20the%20ability%20to%20predict%20phonetic%20content,%20and%20the%20ability%20to%20accurately%20reconstruct%20individual%20spectrogram%20frames.%20Moreover,%20for%20discrete%20encodings%20extracted%20using%20the%20VQ-VAE,%20we%20measure%20the%20ease%20of%20mapping%20them%20to%20phonemes.%20We%20introduce%20a%20regularization%20scheme%20that%20forces%20the%20representations%20to%20focus%20on%20the%20phonetic%20content%20of%20the%20utterance%20and%20report%20performance%20comparable%20with%20the%20top%20entries%20in%20the%20ZeroSpeech%202017%20unsupervised%20acoustic%20unit%20discovery%20task.%7D,%0A%20%20archiveprefix%20=%20%7BarXiv%7D,%0A%20%20eprint%20=%20%7B1901.08810%7D,%0A%20%20eprinttype%20=%20%7Barxiv%7D,%0A%20%20journal%20=%20%7BIEEE/ACM%20Transactions%20on%20Audio,%20Speech,%20and%20Language%20Processing%7D,%0A%20%20keywords%20=%20%7BComputer%20Science%20-%20Machine%20Learning,Electrical%20Engineering%20and%20Systems%20Science%20-%20Audio%20and%20Speech%20Processing,Statistics%20-%20Machine%20Learning%7D,%0A%20%20number%20=%20%7B12%7D%0A%7D%0A%7B%25endraw%25%7D">
      <i class="fa fa-li fa-at"></i>BibTeX Citation</a></li>
</ul>


  </div>
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>
      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
    
    
    
      <li><a href="https://github.com/f90"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Daniel Stoller. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.1.0/js/all.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>





  </body>
</html>